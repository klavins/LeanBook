<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Foundations of Lean</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="A light introduction to the foundations of mathematics and proof checking with Lean">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="lean-book.css">

        <!-- MathJax -->
        <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "";
            const default_light_theme = "light";
            const default_dark_theme = "navy";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc.js"></script>
    </head>
    <body>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Foundations of Lean</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/klavins/LeanBook" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <div style='display:none'>
--  Copyright (C) 2025  Eric Klavins
--
--  This program is free software: you can redistribute it and/or modify
--  it under the terms of the GNU General Public License as published by
--  the Free Software Foundation, either version 3 of the License, or
--  (at your option) any later version.   
</div>
<p><span style='color: orange'><em><strong>UNDER CONSTRUCTION</strong></em></span><br>
<span style='color: lightgray; font-size: 10pt'><a href='https://github.com/klavins/LeanBook/blob/main/main/../LeanBook/Chapters/Introduction.lean'>Code</a> for this chapter</span></p>
<h1 id="foundations-in-lean"><a class="header" href="#foundations-in-lean">Foundations in Lean</a></h1>
<p>by Eric Klavins</p>
<p>The notes presented here were initially developed for a special topics graudate course on Lean I taught in the Winter of 2025. The course was taken mainly by Electrical and Computer Engineers with standard programming experience, some engineering mathematics background, and a variety of different application areas in mind. The main reading for the course included all the standard Lean references and books. These notes are merely a supplement for those excellent resources.</p>
<p>That said, I hope the material presented here presents a unique and useful perspective that arose over several decades of my periodically checking in on proof assistants, becoming enamored for a while, and then moving on to other projects. For me, the alure of theorem provers is the possibility of once and for all connecting the foundations of mathematics (Type Theory in the case of Lean) with the work of practicing mathematicians and engineers. Thus, my presentation focuses on foundations, whereas other resources may focus more on the use of Lean for particular applications.</p>
<p>Every new generation of proof assistant gets a bit closer to realizing the goal of making all of mathematics easily formalized. Of all of the tools available, from Agda to Rocq, none has captured my attention like Lean 4 has. I think it is the combination of tooling in VS Code, the self-boostrapping nature of Lean 4 being written in Lean 4, the simultaneous blossoming of machine learning, and the inspiring community of researchers exploring how to use Lean 4. These taken together seem to be giving Lean considerable momentum.</p>
<p>My hope is that these notes are useful for students wishing to understand the type theoretic foundations of Lean and similar tools. I think such an understanding is useful for a variety of reasons. First, I think learning a computer programming language is aided by an understanding of how the language is executed or intepreted. For a language like C, it is hard to imagine becoming a true expert without understanding assembly language, stacks, memory allocation, and compilation. Just using a C debugger like <code>gdb</code> requires a fair amount of knowledge about the underlying model of computation. For Lean, the model is the lambda calculus, type checking, and type inference. When Lean doesn't work, students can spend hours trying various incantations to make it do what they want. With some understanding of the underlying model of computation, getting unstuck becomes easier. Second, there is no reason to think that the development of proof checkers is somehow complete with Lean as the final solution to the problems that have plagued such tools for decades. Understanding how Lean works will hopefully inspire someone (perhaps even me) to write their own proof checker someday, using Lean and its foundations as a reference architecture.</p>
<p>Finally, the study of the foundations of mathematics is incredibly rich and interesting in its own right, like topology or number theory. I encourage the interested student to dig deeply into this material and then read the primary literature on Type Theory, to gain at least an appreciation if not a mastery of the wonders that underpin how Lean and its cohort of proof checkers work.</p>
<h2 id="acknowledgements"><a class="header" href="#acknowledgements">Acknowledgements</a></h2>
<p>I would like to acknowledge the students who took my special topics course offered the Winter of 2025 at the University of Washington. We all learned Lean together. At first, I was a few weeks ahead, and by the end of the course I was a few weeks behind. Much of the material here was developed in response to their questions and ideas.</p>
<div style='height=50px'>&nbsp;</div><hr>
Copyright © 2025 Eric Klavins
<div style="break-before: page; page-break-before: always;"></div><div style='display:none'>
--  Copyright (C) 2025  Eric Klavins
--
--  This program is free software: you can redistribute it and/or modify
--  it under the terms of the GNU General Public License as published by
--  the Free Software Foundation, either version 3 of the License, or
--  (at your option) any later version.   
</div>
<p><span style='color: orange'><em><strong>UNDER CONSTRUCTION</strong></em></span><br>
<span style='color: lightgray; font-size: 10pt'><a href='https://github.com/klavins/LeanBook/blob/main/main/../LeanBook/Chapters/Lean.lean'>Code</a> for this chapter</span></p>
<h1 id="a-tour-of-lean-4"><a class="header" href="#a-tour-of-lean-4">A Tour of Lean 4</a></h1>
<h2 id="installing-lean"><a class="header" href="#installing-lean">Installing Lean</a></h2>
<p>The easiest way to install Lean is to follow the quickstart guide at</p>
<ul>
<li><a href="https://lean-lang.org/lean4/doc/quickstart.html">Lean Quickstart</a></li>
</ul>
<p>You will need first install VS Code:</p>
<ul>
<li><a href="https://code.visualstudio.com/">VS Code</a></li>
</ul>
<p>Then go to <code>View &gt; Extensions</code> and search for "Lean 4" and install it.</p>
<p>This will put a <code>∀</code> in the upper right menu bar of VS Code. From there, you can create a new project, which should install Lean and all of the associated tools.</p>
<h2 id="lean-project-types"><a class="header" href="#lean-project-types">Lean "Project" Types</a></h2>
<p>With the VS Code Extension, you can install two types of projects:</p>
<ul>
<li>
<p><strong>Standalone</strong> project. Just the basics.</p>
</li>
<li>
<p><strong>Mathlib</strong> project. Includes a <em>huge</em> library of most basic and several advanced areas of mathematics. Choose this if in particular if you want to use real numbers, algebra, sets, matrices, etc.</p>
</li>
</ul>
<p>Despite its size, I recommend starting a <em>Mathlib</em> based project. You never know when you might need something from Mathlib.</p>
<p>Notes:</p>
<ul>
<li>Wait for the tool to completely finish before opening or changing anything.</li>
<li>I don't like the option where it creates a new workspace</li>
<li>Don't make a new project every time you want to try something out. You will use up all the space on your hard drive. Instead, create a single monolithic project and mkae subdirectores for ideas you want to explore.</li>
</ul>
<h2 id="directory-structure"><a class="header" href="#directory-structure">Directory Structure</a></h2>
<p>If you create a new project called <code>MyProject</code>, you will get a whole directory of stuff:</p>
<pre><code>   MyProject
     .github/
     .lake/
     MyProject/                    &lt;-- put your code here
       Basic.lean
     .gitignore
     MyProject.lean
     lake-manifest.json
     lakefile.toml
     lean-toolchain
     README.md
</code></pre>
<p>For now, you mainly need to know that the subdirectory with the same name as your project is where you can put your .lean files. It has one in it already, called <code>Basic.lean</code>. Open this and you can start playing with Lean.</p>
<h2 id="testing-an-installation"><a class="header" href="#testing-an-installation">Testing an Installation</a></h2>
<p>Try replacing the code in <code>Basic.lean</code> with the following:</p>
<pre><code class="language-lean">import Mathlib.Tactic.Linarith

#eval 1+2

example (x y z : ℚ)
        (h1 : 2*x &lt; 3*y)
        (h2 : -4*x + 2*z &lt; 0)
        (h3 : 12*y - 4* z &lt; 0) : False := by
  linarith
</code></pre>
<p>If it is not open already, open <code>Lean infoview</code> via the ∀ menu.</p>
<ul>
<li>Put your curor over <code>1+2</code>. You should see 3 in the messages.</li>
<li>Put your cursor just before <code>by</code> you will get some goals.</li>
<li>Rut it after <code>linarith</code> you will see "No Goals", since the theorem is proved.</li>
</ul>
<h2 id="fancy-characters"><a class="header" href="#fancy-characters">Fancy Characters</a></h2>
<p>You can enter fancy characters in Lean using escape sequences</p>
<pre><code>  →                   \to
  ↔                   \iff
  ∀                   \forall
  ∃                   \exists
  ℕ                   \N
  xᵢ                  x\_i
</code></pre>
<p>Go to</p>
<pre><code>  ∀ &gt; Documentation &gt; ... Unicode ...
</code></pre>
<p>for a complete list.</p>
<h2 id="type-checking"><a class="header" href="#type-checking">Type Checking</a></h2>
<p>Lean is based on type theory. This means that every term has a very well defined type. To find the type of an expression, use #check. The result will show up in the Infoview.</p>
<pre><code class="language-lean">#check 1
#check "1"
#check ∃ (x : Nat) , x &gt; 0
#check λ x =&gt; x+1
#check (4,5)
#check ℕ × ℕ
#check Type
</code></pre>
<h2 id="evaluation"><a class="header" href="#evaluation">Evaluation</a></h2>
<p>You can use Lean to evaluate expressions using the #eval command. The result will show up in the Infoview.</p>
<pre><code class="language-lean">#eval 1+1
#eval "hello".append " world"
#eval if 2 &gt; 2 then "the universe has a problem" else "everything is ok"
#eval Nat.Prime 741013183
</code></pre>
<h2 id="proofs"><a class="header" href="#proofs">Proofs</a></h2>
<p>We will go into proofs in great detail next week. For now, know that you can state theorems using the <code>theorem</code> keyword.</p>
<pre><code class="language-lean">theorem my_amazing_result (p : Prop) : p → p :=
  λ h =&gt; h
</code></pre>
<p>In this expression,</p>
<p>my_amazing_result is the name of the theorem
(p : Prop)        is an assumption that p is a proposition
(true or false statement)
p → p             is the actual theory
:=                delinates the statement of the theorem
from the proof
λ h =&gt; h          (the identity function) is the proof</p>
<p>You can use your theorems to prove other theorems:</p>
<pre><code class="language-lean">theorem a_less_amazing_result : True → True :=
  my_amazing_result True
</code></pre>
<h2 id="examples-vs-proofs"><a class="header" href="#examples-vs-proofs">Examples vs Proofs</a></h2>
<p>Results don't have to be named, which is useful for trying things out or when you don't need the result again.</p>
<pre><code class="language-lean">example (p : Prop) : p → p :=
  λ h =&gt; h

example (p q r : Prop) : (p → q) ∧ (q → r) → (p → r) :=
  λ ⟨ hpq, hqr ⟩ hp =&gt; hqr (hpq hp)
</code></pre>
<h2 id="the-tactic-language-and-sorry"><a class="header" href="#the-tactic-language-and-sorry">The Tactic Language and <code>sorry</code></a></h2>
<p>The examples above use fairly low level Lean expressions to prove statements. Lean provides a very powerful, higher level DSL (domain specific language) for proving. You enter the Tactic DSL using <code>by</code>.</p>
<p>Proving results uses the super <code>sorry</code> keyword. Here is an example of Tactics and sorry.</p>
<pre><code class="language-lean">example (p q r : Prop) : (p → q) ∧ (q → r) → (p → r) := by
  intro h hp
  have hpq := h.left
  have hqr := h.right
  exact hqr (hpq hp)
</code></pre>
<p>which can be built up part by part into</p>
<pre><code class="language-lean">example (p q r : Prop) : (p → q) ∧ (q → r) → (p → r) := by
  intro ⟨ hpq, hqr ⟩
  intro hp
  have hq : q := hpq hp
  have hr : r := hqr hq
  exact hr
</code></pre>
<p>Don't worry if none of this makes sense. We'll go into all the gory details later.</p>
<h2 id="programming"><a class="header" href="#programming">Programming</a></h2>
<p>Lean is also a full-fledged functional programming language. For example, much of Lean is programmed in Lean (and then compiled). That said, the Lean Programming Language is not really general purpose: You would probably lose your mind trying to build an operating system with Lean. Rather, Lean is a programming language designed first for programming Lean itself, and second for build mathematical data structures and algorithms.</p>
<p>If you are not familiar with functional programming: you will be by then end of this book.</p>
<p>Here is an example program:</p>
<pre><code class="language-lean">def remove_zeros (L : List ℕ) : List ℕ := match L with
  | [] =&gt; List.nil
  | x::Q =&gt; if x = 0 then remove_zeros Q else x::(remove_zeros Q)

#check remove_zeros

#eval remove_zeros [1,2,3,0,5,0,0]
</code></pre>
<p>Note the similarity between <code>def</code> and <code>theorem</code>. The latter is simply a special kind of definition.</p>
<h2 id="documentation"><a class="header" href="#documentation">Documentation</a></h2>
<ul>
<li>
<p><a href="https://loogle.lean-lang.org/">Loogle</a> - Google for Lean</p>
</li>
<li>
<p><a href="https://leanprover.zulipchat.com/">Zulip Chat</a></p>
</li>
<li>
<p><a href="https://lean-lang.org/theorem_proving_in_lean4/title_page.html">Lean Theorem Proving Book</a></p>
</li>
<li>
<p><a href="https://lean-lang.org/functional_programming_in_lean/title.html">Lean Functional Programming Book</a></p>
</li>
<li>
<p><a href="https://leanprover-community.github.io/lean4-metaprogramming-book/">Lean Metaprogramming</a> -- Advanced!</p>
</li>
<li>
<p><a href="https://leanprover-community.github.io/mathematics_in_lean">Mathematics in Lean</a></p>
</li>
<li>
<p><a href="https://github.com/haruhisa-enomoto/mathlib4-all-tactics/blob/main/all-tactics.md">Tactics</a></p>
</li>
<li>
<p><a href="https://github.com/leanprover/lean4/blob/ffac974dba799956a97d63ffcb13a774f700149c/src/Init/Prelude.lean">The Standard Library</a></p>
</li>
</ul>
<div style='height=50px'>&nbsp;</div><hr>
Copyright © 2025 Eric Klavins
<div style="break-before: page; page-break-before: always;"></div><div style='display:none'>
--  Copyright (C) 2025  Eric Klavins
--
--  This program is free software: you can redistribute it and/or modify
--  it under the terms of the GNU General Public License as published by
--  the Free Software Foundation, either version 3 of the License, or
--  (at your option) any later version.   
</div>
<p><span style='color: orange'><em><strong>UNDER CONSTRUCTION</strong></em></span><br>
<span style='color: lightgray; font-size: 10pt'><a href='https://github.com/klavins/LeanBook/blob/main/main/../LeanBook/Chapters/LambdaCalculus.lean'>Code</a> for this chapter</span></p>
<h1 id="the-simply-typed-λ-lambda-calculus"><a class="header" href="#the-simply-typed-λ-lambda-calculus">The Simply Typed λ-Lambda Calculus</a></h1>
<h2 id="background"><a class="header" href="#background">Background</a></h2>
<p>The <strong>λ-calculus</strong> was introduced in the 1930s by Alonzo Church as a way to represent how functions on natural numbers are calculated using symbols. The goal was to determine whether every function on the natural numbers had an effective means of being calculated.</p>
<p>Said differently, the question is: Does every function have an algorithm? Astonishingly, Church showed that the answer is "no". In fact, there are functions on the natural numbers for which there is no effective algorithm. Church's 1935 paper "An unsolvable problem in elementary number theory" proved this result.</p>
<p>The reasoning, roughly, is this:</p>
<ul>
<li>Devise a simple programming language, the λ-calculus</li>
<li>Define computation as rewriting operations on λ-calculus terms</li>
<li>Correspond to every term a natural number</li>
<li>Conclude that questions about terms are thus questions about numbers</li>
<li>Show there are more functions from terms into terms than there are terms.</li>
</ul>
<p>A specific problem that Church showed to be unsolvable is: Given λ-calculus terms M and N, show there does not exist a λ-calculus function that can determine whether M can be rewritten as N. Those who have studied theoretical computer science, may be familiar with Alan Turing's similar result which shows there is no Turing Machine that can determine whether a given Turing Machine eventually terminates. In fact, the λ-calculus can simulate Turing Machines and vice verse.</p>
<p>The Church-Turing Thesis is the observation that <em>all</em> formalizations of computation are in fact equivalent to the λ-calculus or, equivalently, Turing Machines. The former is more convenient for symbolic reasoning, while the latter is more akin to how electromechanical computers actually work.</p>
<h2 id="programming-languages"><a class="header" href="#programming-languages">Programming Languages</a></h2>
<p>Thus, the λ-calclus and the formal notion of computation has its roots in the foundations of mathematics. Later, around the 1960s, linguists and computer scientists realized that the λ-calculus was an useful framework for the theory and design of programming languages.</p>
<p>Simultaenously, logicians were becoming frustrated with Set Theory as a foundation for mathematics and started exploring Type Theory as an alternative. Around the 1990s many of these ideas came together, especially through the work of Thierry Coquand on the Calculus of Constructions. It was observed that typed programming languages were not only an ideal foundation for all of mathematics, they could be used to develop computational proof assistants and theoerm provers.</p>
<h2 id="currys-paradox"><a class="header" href="#currys-paradox">Curry's Paradox</a></h2>
<p>The original formulation of the λ-calculus allowed for infinite loops, as do most programming languages. This made the λ-calculus expressive enough for Church to prove his undecidability results, but it caused other problems when logicians wished to use formalisms like the λ-calculus as systems of logic.</p>
<p>Haskel Curry discovered that one could encode the following paradox:</p>
<ul>
<li>Consider the self-referential statement X = X → Y where Y is <em>any</em> statement.</li>
<li>Certainly X → X is true for any statement X.</li>
<li>Substituting X → Y for the second X gives X → (X → Y)</li>
<li>This statement is equivalent to X → Y, which is the same as X</li>
<li>Thus X is true</li>
<li>So Y is true since X → Y</li>
</ul>
<p>For example, X → Y could mean "If this sentence is true, then 1 &gt; 0." Any framework in which you can make this argument allows you to prove any statement Y, and so the framework is useless logically.</p>
<h2 id="types"><a class="header" href="#types">Types</a></h2>
<p>The solution was to give <em>types</em> to all terms in the λ-calculus. We will see below that certain self referential programs are impossible to assign types to. At the same time, infinite loops are no longer allowed, making the formalism not as powerful from a computational point of view.</p>
<p>Thus was born the <em>simply-typed λ-calculus</em>. Eventually, more complicated types were added, in which type definitions could depend on other types or on even terms. Most modern programming languages and some logical frameworks have these properties.</p>
<p>Church's paper on the subject is quite complicated, elucidating ideas that were fairly novel at the time. Since then, comptuer scientists have refined the ideas into a very simple framework, which is presented here, and which can be found in numerous textbooks. The notes in the first part of this section follow video lectures by students of Prof. Uwe Nestmann at the Technical University of Berlin, except that I have restated the formulas in Lean. A link to the videos can be found in the references at the end of this chapter. A Google search will yield hundreds of similar lectures, notes, books, and papers.</p>
<h3 id="basic-types"><a class="header" href="#basic-types">Basic Types</a></h3>
<p>The <code>simply typed λ-calculus</code> is an extremely simple programming language that nevertheless captures the essence of computation. It uses type expressions and terms that have those types. We start with the types. First, we assume a base type. In Lean the base type is called <code>Type</code>. You can ask lean what <code>Type</code> is using the <code>#check</code> directive (which stands for "Type Check").</p>
<pre><code class="language-lean">#check Type
</code></pre>
<p>Lean tells you <code>Type</code> has <code>Type 1</code>, which is a synonym for <code>Type</code>. Don't worry about this right now and just accept that <code>Type</code> is a type. One constructs new types using the arrow <code>→</code> as in the following examples:</p>
<pre><code class="language-lean">#check Type → Type
#check Type → (Type → Type)
#check (Type → Type) → Type
</code></pre>
<p>That is, whenevever τ is a type, so is τ → τ. Arrow types are supposed to denote function types. So τ → τ is the type of any function that takes objects in τ and returns objects in τ. Note that the arrow → associates to the right. So the second expression above is equivalent to <code>Type → Type → Type</code>.</p>
<h3 id="type-variables-and-applications"><a class="header" href="#type-variables-and-applications">Type Variables and Applications</a></h3>
<p>You can also define type variables using <code>def</code></p>
<pre><code class="language-lean">def A := Type
def B := Type → Type
</code></pre>
<p>Which looks a bit more like what you would see in a textbook on type theory. Now you can construct more types.</p>
<pre><code class="language-lean">#check A → B
</code></pre>
<h2 id="terms"><a class="header" href="#terms">Terms</a></h2>
<p>Next, we define the terms of the lambda calculus. These are the programs. We start with <strong>variables</strong>, for example <code>x</code> and <code>f</code>, which we declare in Lean as follows:</p>
<pre><code class="language-lean">variable (x : A)               -- declare a variable x of type a
variable (f : A → A)           -- declare a function f from A into A

#check x
#check f
</code></pre>
<p>What we've said here is that <code>x</code> is a simple object with type <code>A</code>, while <code>f</code> is an function type from <code>A</code> into <code>A</code>. Next we have <strong>applications</strong>. These have the form <code>e₁ e₁</code> where <code>e₁</code> and <code>e₂</code> are terms. For example,</p>
<pre><code class="language-lean">#check f x
#check f (f x)
#check f (f (f x))
</code></pre>
<p>are all applications of terms to terms.</p>
<h3 id="abstractions"><a class="header" href="#abstractions">Abstractions</a></h3>
<p>Finally, we have <strong>abstractions</strong>, which have the form <code>λ (x : τ) =&gt; e</code> where <code>τ</code> is a type and <code>e</code> is a term. The <code>x</code> in this expression is said to be <code>bound</code> to the abstraction. It is a dummy variable and could be renamed without any change in meaning. For example, the following are terms in the λ-calculus:</p>
<pre><code class="language-lean">#check λ (y : A) =&gt; y
#check λ (g : A → A) =&gt; λ (y : A) =&gt; g y
</code></pre>
<p>In the first example, the abstraction defines a function that simply returns its argument. In the second example, the abstraction defines a function that takes another function <code>g</code> and returns yet another abstraction that takes an object <code>y</code> and returns <code>g</code> applied to <code>y</code>.</p>
<p>Note that the parentheses group to the right, so the second example is equivalent to:</p>
<pre><code class="language-lean">#check λ (g : A → A) =&gt; ( λ (y : A) =&gt; g y )
</code></pre>
<p>In Lean, we can also abbreviate a chained lamdba abstractions by writing:</p>
<pre><code class="language-lean">#check λ (g : A → A) (y : A) =&gt; g y
</code></pre>
<h3 id="equivalence-with-def"><a class="header" href="#equivalence-with-def">Equivalence with <code>def</code></a></h3>
<p>A lambda abstraction is basically an unamed function. You could also give your functions names and use <code>def</code>.</p>
<pre><code class="language-lean">def inc₁ (x : Nat) : Nat := x + 1
def inc₂ := λ x =&gt; x + 1

#eval inc₁ 3
#eval inc₂ 3
#eval (λ x =&gt; x + 1) 3
</code></pre>
<h3 id="currying"><a class="header" href="#currying">Currying</a></h3>
<p>Consider the lambda abstraction</p>
<pre><code class="language-lean">variable (X : Type)
variable (a : X)

#check λ (g : X → X) =&gt; λ (x: X) =&gt; g x
</code></pre>
<p>If we apply the abstraction to particular function, then we get another function.</p>
<pre><code class="language-lean">#reduce (λ (g : X → X) =&gt; λ (x: X) =&gt; g x) (λ x =&gt; x)
</code></pre>
<p>This way this new function is obtained is called <em>Currying</em> after Haskel Curry. The function can then be applied again:</p>
<pre><code class="language-lean">#reduce (λ (g : X → X) =&gt; λ (x: X) =&gt; g x) (λ x =&gt; x) a
</code></pre>
<h2 id="type-derivation"><a class="header" href="#type-derivation">Type Derivation</a></h2>
<p>All <strong>terms have types</strong>. These can be found using type theory's <strong>derivation rules</strong>:</p>
<p><strong>VAR</strong>: Variables are declared either globally to have a given type (using Lean's variable command) or are bound in a λ-expression.</p>
<p><strong>ABST</strong>: The type of an abstraction is always of the form A → B where A is the type of the argument and B is the type of the result.</p>
<p><strong>APPL</strong>: If f : A → B and x : A, then the type of the application of f to x is B.</p>
<p>These derivation rules are applied automatically by Lean in the process of type checking using the #check directive. We can see the types Lean derives as follows.</p>
<pre><code class="language-lean">def h₁ := λ (y : A) =&gt; y
def h₂ := λ (g : A → A) =&gt; λ (y : A) =&gt; g y

#check x
#check h₁
#check h₂
#check h₁ x
#check h₂ h₁               --&gt; Example of currying
#check h₂ h₁ x
</code></pre>
<p>Note: Currying is named after the Logician Haskel Curry, who studied Electrical Engineering at MIT in the 1920s, although he eventually switched to Physics.</p>
<h2 id="type-errors"><a class="header" href="#type-errors">Type Errors</a></h2>
<p>The typed lambda calculus disallows expressions that do not follow typing rules. For example, the following expression produces a type error</p>
<pre><code class="language-lean">#check_failure λ (g : A) =&gt; λ (y : A) =&gt; g y
</code></pre>
<p>because g is not declared to be a function type and therefore cannot be applied to y.</p>
<p>Another example is</p>
<pre><code class="language-lean">#check_failure λ (y : A) =&gt; q
</code></pre>
<p>about which Lean complains because q has not been declared in the present context.</p>
<h2 id="judgements-and-contexts"><a class="header" href="#judgements-and-contexts">Judgements and Contexts</a></h2>
<p>When you hover over a #check directive, Lean shows the results of the type derivation as what is called a <strong>judgement</strong>. It is an expression in two parts separated by a <strong>turnstile</strong> ⊢. For example: <code>#check h₁ x</code> produces</p>
<pre><code>x : A
f : A → A
⊢ A
</code></pre>
<p>Before the turnstile is the <strong>context</strong>, a list of all the variables introduced so far. After the turnstile is the type of (h₁ x), which in this case is A. In the literature, this written:</p>
<pre><code>{ x : A, f : A → A }  ⊢  h₁ x : A
</code></pre>
<p>which reads: "If A has type A and f has type A → A, then we can derive h₁ x has type A". In an expression such as</p>
<pre><code>λ (y : A) =&gt; f y
</code></pre>
<p>the variable f is not bound to an enclosing lambda. In this case it is called <strong>free</strong>. The variable y on the other hand is <code>bound</code>. Free variables have to be declared in Lean for expressions to use them. And they have to have types consistent to how they are used. When this is done properly, you will see the free variable declarations in the context part of Lean's results.</p>
<h2 id="beta-reduction"><a class="header" href="#beta-reduction">Beta Reduction</a></h2>
<p>An abstraction can be <code>applied</code> to another term to produce a new term. This is called β-reduction. It is defined like this:</p>
<pre><code>(λ (x:α) =&gt; M) N   —β→   M[x:=N]
</code></pre>
<p>The notation <code>M[x:=N]</code> means: take all <strong>free</strong> occurances of <code>x</code> in <code>M</code> and replace them with the expression N. We have to be careful that <code>N</code> does not use the variable <code>x</code> freely. Lean does this internally for us The bound version of <code>x</code> above is, internally, a completely unique variable that is just displayed as <code>x</code> for our convenience.</p>
<p>To apply β-reduction in Lean, you can use the #reduce directive. For example, we can see that</p>
<pre><code>(λ (g : α → α) =&gt; λ (y : α) =&gt; g y) f   —β→   λ (y : α) =&gt; f y
</code></pre>
<p>This is obtained by replacing <code>g</code> in <code>g y</code> with <code>f</code>, as the rule describes. You can have Lean do this for you using the #reduce directive. The <code>#reduce</code> directive needs permission to be aggressive, which we can do using the <code>(types := true)</code> option.</p>
<pre><code class="language-lean">#reduce (types:=true) (λ (y : A) =&gt; y) x
#reduce (types:=true) (λ (g : A → A) =&gt; λ (y : A) =&gt; g y) (λ (y : A) =&gt; y)
#reduce (types:=true) (λ (g : A → A) =&gt; λ (y : A) =&gt; g y) (λ (y : A) =&gt; y) x
</code></pre>
<h2 id="properties-of-the-simply-typed-λ-calculus"><a class="header" href="#properties-of-the-simply-typed-λ-calculus">Properties of the Simply Typed λ-calculus</a></h2>
<p>Some interesting observations are in order. We won't prove these here, but they are good to know:</p>
<p><strong>Uniqueness of Types</strong>: Every term has exacly one type.</p>
<p><strong>Subject Reduction Lemma</strong>: If <code>M₁ : α and M₁ —β→ M₂</code> then <code>M₂ : α</code>. That is, beta reduction does't change the type of expressions. It just simplifies them.</p>
<p><strong>Church-Rosser Theorem</strong>: If <code>M —β→ N₁</code> and <code>M —β→ N₂</code> then there is some <code>N₃</code> such that <code>N₁ —β→ N₃</code> and <code>N₂ —β→ N₃</code>. That is, it doesn't matter what order you β-reduce an expression's sub-expressions in, you always end up with the same term.</p>
<p><strong>Strong Normalization</strong>: β-reduction eventually stops at an irreducible term. This is a very strong statement. In most programming languages, you can write infinite loops. But not in the simply typed λ-calculus!</p>
<h2 id="extended-example-church-numerals"><a class="header" href="#extended-example-church-numerals">Extended Example: Church Numerals</a></h2>
<p>Even though the simply typed λ-calculus looks simple, you can encode quite a bit of math with it. The goal of this next section is to show you how do do arithmetic with only what we have so far (simple arrow types and terms depending only on terms). We do this not because it is efficient -- it isn't! Instead, we want to show that the essence of arithmetic is captured by the simply typed λ-calculus.</p>
<p>First, we need a way to represent numbers. Church devised the following scheme, where c₀ is the <strong>Church Numeral</strong> for 0 and so on.</p>
<pre><code class="language-lean">def α := Type

def c₀ := λ ( f : α → α ) =&gt; λ ( x : α ) =&gt; x
def c₁ := λ ( f : α → α ) =&gt; λ ( x : α ) =&gt; f x
def c₂ := λ ( f : α → α ) =&gt; λ ( x : α ) =&gt; f (f x)
def c₃ := λ ( f : α → α ) =&gt; λ ( x : α ) =&gt; f (f (f x))
</code></pre>
<p>You can check the type of a Church numeral:</p>
<pre><code class="language-lean">#check c₂
</code></pre>
<p>For convenience, let's give this type a name:</p>
<pre><code class="language-lean">def N := (α → α) → α → α

#check N
</code></pre>
<h3 id="arithmetic"><a class="header" href="#arithmetic">Arithmetic</a></h3>
<p>We can define functions on numbers. For example, the successor function is defined below.</p>
<pre><code class="language-lean">def succ := λ (m : N) =&gt; λ (f : α → α) =&gt; λ (x: α) =&gt; f (m f x)
</code></pre>
<p>To see how this works, let's apply succ to c₀. We omit the types to make it easier to read. Note for clarity we use the dummy variables g and y in c₀ instead of f and x.</p>
<p>succ c₀ = ( λ m =&gt; λ f =&gt; λ x =&gt; f (m f x) )  ( λ g =&gt; λ y =&gt; y )
—β—&gt; λ f =&gt; λ x =&gt; f ( ( λ g =&gt; λ y =&gt; y ) f x )
[note, g is not used, so f x disappears]
—β—&gt; λ f =&gt; λ x =&gt; f ( ( λ y =&gt; y ) x )
—β—&gt; λ f =&gt; λ x =&gt; f x
= c₁</p>
<p>This is a lot of work, so let's let Lean do this for us:</p>
<pre><code class="language-lean">#reduce (types := true ) succ c₀
#reduce (types := true ) succ c₃
</code></pre>
<h3 id="other-operations"><a class="header" href="#other-operations">Other Operations</a></h3>
<p>We can also add two numbers together:</p>
<pre><code class="language-lean">def add := λ (m : N) =&gt; λ (n : N) =&gt; λ (f : α → α) =&gt; λ (x: α) =&gt; m f (n f x)

#reduce (types := true) add c₃ c₂
#reduce (types := true) add (succ c₃) (add c₁ c₂)
</code></pre>
<p>And here is multiplication:</p>
<pre><code class="language-lean">def mul :=  λ (m : N) =&gt; λ (n : N) =&gt; λ (f : α → α) =&gt; λ (x: α) =&gt; m (n f) x

#reduce (types := true) mul c₃ c₂
</code></pre>
<p>We can even do a sort of if-statement:</p>
<pre><code class="language-lean">def ifzero := λ (m : N) =&gt; λ (n : N) =&gt; λ (p : N) =&gt;
              λ (f : α → α) =&gt; λ (x: α) =&gt;
              n (λ ( y : _ ) =&gt; p f x) (m f x)

#reduce (types := true) ifzero c₂ c₀ c₃
#reduce (types := true) ifzero c₂ c₁ c₃
</code></pre>
<h3 id="lean-can-prove-11--2"><a class="header" href="#lean-can-prove-11--2">LEAN CAN PROVE 1+1 = 2</a></h3>
<pre><code class="language-lean">theorem one_plus_one_is_two : add c₁ c₁ = c₂ :=
  rfl
</code></pre>
<p>You can prove this by rfl because, as we will see, two lambda expressions that beta reduce to the same thing are considered <code>definitionally equal</code>. Although this is not scalable and in fact Lean has a much more expressive type system that we will harness soon.</p>
<h3 id="church-numerals-are-inconvenient"><a class="header" href="#church-numerals-are-inconvenient">Church Numerals are Inconvenient</a></h3>
<p>You can define other opertations on the natural numbers in a similar fashion. It is also fairly straightforward to define Booleans and Boolean Logic, as well as a number of other basic mathematical structures.</p>
<p>Building up from these basic ideas to more complex mathematics is the point of Lean. Eventually, we will arrive at cutting edge mathematics in Lean. Because it is defined in terms of thee basic building blocks, we always have a proof that goes from the high level mathematica statements to the low level meaning in terms of the typed λ-calculus: That is, a proof from first princples.</p>
<p>That said, it will ultimately be better to define a richer set of types. For example, we'll define the natural numbers and almost every other mathematical object in Lean using what are called <a href="InductiveTypes.html">Inductive Types</a>.</p>
<h2 id="type-theory-questions"><a class="header" href="#type-theory-questions">Type Theory Questions</a></h2>
<p>Now that we have a simple programming language and a way to assign types to terms in that language, we can explore a number of problems in type theory, each with its own purpose and challenges.</p>
<p><strong>TYPE CHECKING</strong>: In a given context, does a term M have a given type σ?</p>
<pre><code>Γ ⊢ M : σ
</code></pre>
<p><strong>WELL TYPEDNESS</strong>: Does there exist a context in which a type be assigned to a term M? Another way of saying this is "is M a legal term?"</p>
<pre><code>? ⊢ M : ?
</code></pre>
<p><strong>TYPE INFERENCE</strong>: Can M be assigned a type consistent with a given context?</p>
<pre><code>Γ ⊢ M : ?
</code></pre>
<p><strong>INHABITATION</strong>: Does there exist a term of a given type? If σ is a logical statement, then this is the question of whether σ has a proof.</p>
<pre><code>Γ ⊢ ? : σ
</code></pre>
<h1 id="type-inference"><a class="header" href="#type-inference">Type Inference</a></h1>
<p>Lean is good at type inference. We can go a step further with Lean and leave out types in expressions, letting Lean infer what they must be. For example, the Church numerals can be written more consicely, skipping some of the type declarations and using multi-argument lambdas, as follows:</p>
<pre><code class="language-lean">#check λ _ y =&gt; y
#check λ ( g : α → α ) y =&gt; g y
#check λ ( g : α → α ) y =&gt; g (g y)
</code></pre>
<p>We haven't said what the type of y is in these expressions. And we haven't even given the first bound variable in c₀ a name, since it isn't used in the the body of the abstraction. Lean infers that y must have type α because it is being acted upon by a function from α to α. We can also write the other operations, like multiplication, more concisely:</p>
<pre><code class="language-lean">#check λ (m n : N) f x =&gt; m (n f) x
</code></pre>
<p>We can't leave out all of the type information though. Consider:</p>
<pre><code class="language-lean">#check_failure λ g y =&gt; g y
</code></pre>
<p>In the above, there are any number of ways types could be assigned to g and y, so Lean complains that it can't assign types to them. So while the expression is typeable, Lean can't infer a type for it and you have to give it more information.</p>
<h3 id="self-application-is-untypeable"><a class="header" href="#self-application-is-untypeable">Self-application is Untypeable</a></h3>
<p>Dropping types for the moment, define the term</p>
<pre><code>Ω := λ x =&gt; x x
</code></pre>
<p>and consider <code>Ω</code> applied to itself <code>Ω</code>:</p>
<pre><code>(λ x =&gt; x x) (λ x =&gt; x x)       —β—&gt;       (λ x =&gt; x x) (λ x =&gt; x x)
</code></pre>
<p>producing an infinite loop. Suppose you could give <code>M M</code> a type:</p>
<pre><code>M M : σ
</code></pre>
<p>For this to work, <code>M</code> has to be a function:</p>
<pre><code>M : τ → σ
</code></pre>
<p>But since <code>M</code> is operating on itself, <code>M</code> has to be of type <code>τ</code>:</p>
<pre><code>M : τ
</code></pre>
<p>So <code>M</code> has two different types, which is not possible. Lean is not able to find a type for <code>x</code>. The placeholder symbol <code>_</code> is used by Lean as a way to ask the type checker to infer a type.</p>
<pre><code class="language-lean">#check_failure (λ (M:_) =&gt; M M)
</code></pre>
<h2 id="propositions"><a class="header" href="#propositions">Propositions</a></h2>
<p>Lean has a special type called <code>Prop</code> which stands for <code>Proposition</code>. It treats this type somewhat differently than all other types, but in most ways it ist just another type.</p>
<pre><code class="language-lean">variable (p : Prop)
#check Prop
#check p
</code></pre>
<p>If p is of type <code>Prop</code>, then an element <code>hp : p</code> is evidence that the type p is not empty. Alternatively, you can think of hp as a <code>proof</code> of p.</p>
<p>Furthermore, arrow types which above denoted functions, can be thought of as denoting <strong>implication</strong> if <code>Prop</code> is involved.</p>
<pre><code class="language-lean">#check p → p
</code></pre>
<p>Armed with the lambda calculus and we can now prove theorems involving implication:</p>
<pre><code class="language-lean">example (p : Prop) : p → p :=
  λ hp =&gt; hp

example (p q : Prop) : p → (p → q) → q :=
  λ hp =&gt; λ hpq =&gt; hpq hp
</code></pre>
<h2 id="why-is-it-called-simply-typed"><a class="header" href="#why-is-it-called-simply-typed">Why is it Called "Simply Typed"?</a></h2>
<p>You might be asking yourself, is there a non-simply typed λ-calculus? The answer is yes! We will get there eventually. Here's a preview:</p>
<p><strong>Simple types:</strong> Terms depend on other tems. This is what we've covered so far. For example, the body of a lambda abstraction (a term) depends on the bound variable (also a term).</p>
<pre><code class="language-lean">#check (λ x : Nat =&gt; x+1) --- the term x+1 depends on the term x.
</code></pre>
<p><strong>Polymorphism:</strong> Terms can depend on types. Polymorphism allows us to write functions that operate on a variety of types, instead of just a single type, by taking the type to be operated on as an argument. For example, the identity function <code>λ x : A =&gt; x</code> only operates on elements of type x. What if we wanted to define an arbitrary identity function for any type. Here is one way:</p>
<pre><code class="language-lean">#check (λ α : Type =&gt; λ x : α =&gt; x) -- a polymorphic identity function.
</code></pre>
<p>A better way would be:</p>
<pre><code class="language-lean">universe u
def my_id {α : Type u} (x : α) := x

#check my_id 1
#check my_id "one"
#check my_id my_id
</code></pre>
<p>Note the curly braces around <code>α : Type u</code> specify that the argument <code>α</code> is <em>implicit</em>. That is, that Lean should try to infer what it is. In the the examples <code>#check</code> statements above, Lean figures out which type the argument is, and therefor which type the overall expression is, by inspection.</p>
<p><strong>Parameterized Types:</strong> Types can depend on types. The idea here is to build a type from other types. For example, a List type is fine, but it would nice to avoid having two make a separate data type for lists of different types of objects. In fact, Lean's standard library defines <code>List</code> as a parameterized type. You can see in the first <code>#check</code> below that making a list requires a type as an argument</p>
<pre><code class="language-lean">#check List            -- Requires a type as an argument
#check List Nat        -- The type of a list of natural numbers
#check List (List Nat) -- The type of a a list of list of natural numbers
</code></pre>
<p>Lean is also good at figuring out what kind of list you are talking about in most contexts, as the following examples show.</p>
<pre><code class="language-lean">#check [1,2,3]
#check ["one","two","three"]
</code></pre>
<p><strong>Dependent types:</strong> Types can depend on terms. Finally, we can have types that depend on terms. For example, the type of vectors (from Lean's standard library) of natural numbers of length 10 depends on the term 10.</p>
<pre><code class="language-lean">#check Vector Nat 10 -- Vectors of 10 Nats
</code></pre>
<p><strong>Calculus of Constructions:</strong> If we allow all of the above in type theory, we get what is called the Calculus of Constructions, or CoC. This theory was first described by Thierry Coqrand and emboded in the Coq proof assistant, now called Rocq. Lean and other proof assistants are also based on CoC.</p>
<p><strong>Inductive Types</strong>: Types can be defined inductively. For example, the natural numbers are defined by a base case (zero) and a successor function (succ), from which all other natural numbers can be constructed. This is discussed in more detail in the chapter on <a href="./InductiveTypes.html">Inductive Types</a>.</p>
<p><strong>Quotients</strong>: Quotients of types via equivalence relations. For example, a real number is defined to be the set of all Cauchy sequences of rational numbers that converge to it. That is, the reals are the quotient of the set of Cauchy Sequences by Cauchy equivalence. This is discussed in more detail in the chapter on <a href="./Quotients.html">Quotients</a>.</p>
<h2 id="looking-ahead-the-curry-howard-correspondence"><a class="header" href="#looking-ahead-the-curry-howard-correspondence">Looking ahead: the Curry-Howard Correspondence</a></h2>
<p>The most important problem in using type theory for proofs is INHABITATION, followed by TYPE CHECKING. To motivate why, we will see later the following remarkable fact, called the Curry-Howard corresponence, which says that in the judgement Γ ⊢ M : σ,</p>
<ul>
<li>Γ can be considered a set of givens or assumptions</li>
<li>σ can be considered a mathematical statement like a theorem or lemma</li>
<li>M can be considered a proof of the theorem assuming the statements in Γ.</li>
</ul>
<p>Thus, type checking amounts to checking that M is a proof of σ, which is a relatively straightfoward problem and we have seen that Lean is quite good at it. This is why tools like Lean are called <code>proof assistants</code>. They check to make sure your proofs are correct.</p>
<p>On the other hand, type inhabitation amounts to finding a proof of σ. This is a very difficult problem, essentially the job of the working mathematician. From a computational point of view, finding a proof means searching over terms M until one finds one that has type σ. Depending on how expressive the programming language for terms is, this can either be a computationally intractable problem (meaning search is the best you can do) or it can be a computationally unsolvable problem (meaning there may not be an algorithm that is guaranteed to find an M of type σ). Both of these observations are job security for mathematicians!</p>
<p>Going a step further, we'll see that an abstraction</p>
<pre><code>λ p : σ =&gt; q
</code></pre>
<p>which may have type</p>
<pre><code>σ → τ
</code></pre>
<p>is the general form of a proof of the statement σ → τ where → means "implies". It can be thought of as a transformation taking a proof of σ, which one assumes is available, and returning a proof of τ, which is thought of as a goal to be proved. Writing the details of what q is amounts to programming.</p>
<p>As a computer scientist myself it is very satisfying to know that programming functions with given type specifications is <em>the same thing as</em> proving theorems!</p>
<p>This idea is not merely cute. By building on it, as Lean and similar tools do, one can enocde an astonishingly large set of all of mathematics, and presumably knowledge in general. We'll learn how to take advantage of the Curry-Howard corresponence soon.</p>
<h2 id="exercises"><a class="header" href="#exercises">Exercises</a></h2>
<p><span></span> 1) Define a lambda abstraction, called double, that takes a Church numeral and doubles it. Evaluate it on a few examples.</p>
<p><span></span> 2) The following lamdba calculus expressions do not type check in Lean.</p>
<pre><code class="language-lean">#check_failure λ x y =&gt; x y
#check_failure λ x y z =&gt; x y z
#check_failure λ x y =&gt; y (y (y x))
#check_failure λ x y z =&gt; (y x) z
</code></pre>
<p>Rewrite them by giving them variables types. Use #check to make sure they work.</p>
<p><span></span> 3) Prove the following example using only lambda calculus expressions</p>
<pre><code class="language-lean">example (p q : Prop) : p → q → p → q → p := sorry
</code></pre>
<p><span></span> 4) Show two different lambda calculus proofs of the following example. Hint, compare the form of the proposition to the Church numerals.</p>
<pre><code class="language-lean">example (p : Prop) : (p → p) → p → p := sorry
</code></pre>
<h2 id="references"><a class="header" href="#references">References</a></h2>
<p>Alonzo Church
<a href="https://www.jstor.org/stable/2371045">An Unsolvable Problem of Elementary Number Theory</a>.
American Journal of Mathematics, 1936.</p>
<p>Haskell B Curry
<a href="https://www.cambridge.org/core/journals/journal-of-symbolic-logic/article/abs/inconsistency-of-certain-formal-logics/FF38B653569E479408EC4DDD26DD7918">The Inconsistency of Certain Formal Logics</a>.
The Journal of Symbolic Logic, 1942.</p>
<p>Alonzo Church
<a href="http://www.classes.cs.uchicago.edu/archive/2007/spring/32001-1/papers/church-1940.pdf">A formulation of the simple theory of types</a>.
Journal of Symbolic Logic, 1940</p>
<p>Uwe Nestmann and Students
<a href="https://www.youtube.com/playlist?list=PLNwzBl6BGLwOKBFVbvp-GFjAA_ESZ--q4">The Lambda Cube Unboxed</a>.
YouTube, 2020</p>
<div style='height=50px'>&nbsp;</div><hr>
Copyright © 2025 Eric Klavins
<div style="break-before: page; page-break-before: always;"></div><div style='display:none'>
--  Copyright (C) 2025  Eric Klavins
--
--  This program is free software: you can redistribute it and/or modify
--  it under the terms of the GNU General Public License as published by
--  the Free Software Foundation, either version 3 of the License, or
--  (at your option) any later version.   
</div>
<p><span style='color: orange'><em><strong>UNDER CONSTRUCTION</strong></em></span><br>
<span style='color: lightgray; font-size: 10pt'><a href='https://github.com/klavins/LeanBook/blob/main/main/../LeanBook/Chapters/PropositionalLogic.lean'>Code</a> for this chapter</span></p>
<h1 id="propositional-logic"><a class="header" href="#propositional-logic">Propositional Logic</a></h1>
<h2 id="propositions-1"><a class="header" href="#propositions-1">Propositions</a></h2>
<p>A <strong>proposition</strong> is a statement that is either true or false. The following are examples:</p>
<ul>
<li>It is raining outside.</li>
<li>All cats are animals.</li>
<li>Darth Vader is Luke's Father.</li>
<li>Four is greater than five.</li>
</ul>
<p>In propositional logic, we assign <strong>propositional variables</strong> to represent the value of these statments. So we might make the assignments:</p>
<ul>
<li>p := It is raining outside.</li>
<li>q := All cats are animals.</li>
<li>r := Darth Vader is Luke's Father.</li>
<li>s := Four is greater than five.</li>
</ul>
<p>In Lean, we declare propositional variables as follows:</p>
<pre><code class="language-lean">variable (p q r s : Prop)
</code></pre>
<p>Note that we are not saying p is the English language sentence "It is raining outside". We are not doing natural language processing here. Rather, we are saying that <code>p</code> is a <strong>propositional variable</strong> that is true when it actually is raining outside, and false otherwise. To determine the truth value of <code>p</code>, we would need some way to check whether it is raining outside (as well as some specifics like outside <em>where</em> and <em>when</em>? For now, we'll just be informal about such things).</p>
<h2 id="atomic-vs-compound-propositions"><a class="header" href="#atomic-vs-compound-propositions">Atomic vs Compound Propositions</a></h2>
<p>A propsition that corresponds to a direct measurement or other basic truth is called <strong>atomic</strong>. It cannot be sub-divided into more basic propositions. Otherwise it is called compound. For example, the proposition</p>
<ul>
<li>It is raining outside or all cats are animals.</li>
</ul>
<p>is a compound proposition that uses the <em>connective</em> "or", written as <code>∨</code> to connect two atomic propositions. Symbolically, we write</p>
<pre><code class="language-lean">#check p ∨ q
</code></pre>
<p>to check that the compound <code>p ∨ q</code> is a proposition.</p>
<p>Students used to digital logic will wonder why we are using ∨ instead of the symbol +. The main reason is that + will usually mean actual addition when things get more complicated. Thus, mathematicans have invented new symbols for logical connectives. Here are the most important for our current purposes:</p>
<pre><code class="language-lean">#check ¬p               -- not p
#check p ∨ q            -- p or q
#check p ∧ q            -- p and q
#check p → q            -- p implies q
#check p ↔ q            -- p if and only if q
#check True
#check False
</code></pre>
<p>We also have the propositional <code>False</code> which denotes <strong>absurdity</strong>. In intuitionistic logic, <code>¬p</code> is just shorthand for</p>
<pre><code>p → False
</code></pre>
<pre><code class="language-lean">#check False
#check p → False
</code></pre>
<p>Also note that ↔ is just shorthand for → in both directions</p>
<pre><code>p ↔ q  ≡  p → q ∧ q → p
</code></pre>
<h2 id="constructive-proofs"><a class="header" href="#constructive-proofs">Constructive Proofs</a></h2>
<p>The goal is this chapter is to define a mathematical framework in which we prove statements by constructing proofs. In particular,</p>
<ul>
<li>To prove p ∧ q we construct a proof of p and another proof of q.</li>
<li>To prove p ∨ q we construct a proof of p or we construct a proof of q.</li>
<li>To prove p → q we supply a method for converting a proof of p into a proof of q</li>
<li>To prove ¬p (which is p → ⊥) we supply a method to convert a proof of p to ⊥</li>
</ul>
<h3 id="example-a-constructive-proof-in-lean"><a class="header" href="#example-a-constructive-proof-in-lean">Example: A Constructive Proof in Lean</a></h3>
<pre><code class="language-lean">example (p q r : Prop) : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) :=
  Iff.intro
    (λ h : p ∧ (q ∨ r) =&gt;
      have hp : p := h.left
      have hqr : q ∨ r := h.right
      Or.elim hqr
        (λ hq : q =&gt; Or.inl (And.intro hp hq))
        (λ hr : r =&gt; Or.inr (And.intro hp hr))
    )
    (λ h : (p ∧ q) ∨ (p ∧ r) =&gt;
      Or.elim h
        (λ hpq : p ∧ q =&gt; And.intro hpq.left (Or.inl hpq.right))
        (λ hpr : p ∧ r =&gt; And.intro hpr.left (Or.inr hpr.right))
    )
</code></pre>
<p>Don't worry if this doesn't make sense right now. It will soon.</p>
<h2 id="comparison-to-classical-logic"><a class="header" href="#comparison-to-classical-logic">Comparison to Classical Logic</a></h2>
<p>We have defined <strong>intuitionistic</strong> logic or <strong>constructive logic</strong>, different from <strong>classical logic</strong>. In classical logic, the truth of a statement like</p>
<pre><code>p ∨ ¬p
</code></pre>
<p>is guaranteed by the <strong>law of the exluded middle</strong>. You know one of them must be true. In constructive mathematics, you have to either construct a proof of <code>p</code> or construct a proof of <code>¬p</code>. As an example, consider the proposition:</p>
<blockquote>
<p>The universe is infinite or the universe is finite.</p>
</blockquote>
<p>Neither part of this compound proposition currently has a proof. Classically, we would still conclude it is true, but constructively we are just stuck. Similar issues arise with famous mathematical conjectures such as</p>
<blockquote>
<p>P = NP or P ≠ NP</p>
</blockquote>
<p>and</p>
<blockquote>
<p>There are either a finite number of twin primes, or an infinite number of twin primes.</p>
</blockquote>
<p>These statements may be proved some day, but for now, we cannot conclude they are true using constructive mathematics.</p>
<h3 id="double-negation"><a class="header" href="#double-negation">Double Negation</a></h3>
<p>Similar to the law of the excluded middle is double negation:</p>
<pre><code>¬¬p ↔ p
</code></pre>
<p>Classically, this is a tautology (a proposition that is always true). But constructively, from a proof of "it is not the case that p is not true" one cannot necessarily construct a proof that <code>p</code> is true.</p>
<p>As a result, <code>proof by contradiction</code> is not valid constructively, because in proof by contradition one follows the procedure:</p>
<pre><code>To prove `p`, assume `¬p` and derive `False`.
</code></pre>
<p>Just because we have a way to transform a proof of <code>¬p</code> into <code>False</code> does not mean we can have a construction of a proof of <code>p</code>.</p>
<h3 id="classical-logic"><a class="header" href="#classical-logic">Classical Logic</a></h3>
<p>TODO</p>
<h2 id="contexts"><a class="header" href="#contexts">Contexts</a></h2>
<p>We now begin to build a framework for proving theorems in propositional logic. The first thing we need is a way to keep track of what propositions we currently know in the course of proving something.</p>
<p>To this end we define a <strong>context</strong> to be a finite set of propositions. Given two contexts <code>Γ</code> and <code>Δ</code> we can take their union <code>Γ ∪ Δ</code> to make a new context. The notation is a bit cumbersome, so we write <code>Γ,Δ</code> instead. In particular, if <code>φ ∈ Φ</code> then <code>Γ,φ</code> is shorthand for <code>Γ ∪ {φ}</code>.</p>
<p>If we can show that a proposition <code>φ</code> is true whenever all the propositions in a context <code>Γ</code> are true, we write</p>
<pre><code>Γ ⊢ φ
</code></pre>
<p>which reads gamma <code>entails</code> <code>φ</code>. Furthermore, if a proposition <code>φ</code> is tautology (meaning it is always true like <code>p ↔ p</code>) then it is true independent of any context. That is, the empty context entials any tautology. Thus, we write</p>
<pre><code>⊢ φ
</code></pre>
<p>to mean <code>∅ ⊢ φ</code>. We will define precisely what the entails relationship means next.</p>
<h2 id="rules-of-inference"><a class="header" href="#rules-of-inference">Rules of Inference</a></h2>
<p>A <strong>rule of inference</strong> is set of <strong>premises</strong> and a <strong>conclusion</strong> that can be drawn from those premises. The propositional logic we define has only a handful of rules of inference from which all proofs can be constructed. They are presented with a name followed by what looks like a fraction with the premises listed on top and the conslusion on the bottom.</p>
<pre><code>                Γ₁ ⊢ A    Γ₂ ⊢ B    Γ₃ ⊢ C
  RULE NAME    ————————————————————————————
                          Γ ⊢ D
</code></pre>
<p>In this schemantic, the rule has three premises, each of which describe an assumption that a particular context entails a particular proposition. And the rule has one conclusion, stating the entailment you are allowed to conclude. Usually, the contexts listed and the propositions are related in some way. - #</p>
<h2 id="axioms"><a class="header" href="#axioms">Axioms</a></h2>
<p>The first rule has no premises and simply states that <code>φ</code> can be concluded from any context containing φ. Said constructively, if we have a proof of <code>φ</code>, then obviously we can construct a proof of <code>φ</code>.</p>
<pre><code>  AX  ——————————
       Γ,φ ⊢ φ
</code></pre>
<p>Here is a simple proof that <code>{hp:p} ⊢ p</code> in Lean using the Axiom rule:</p>
<pre><code class="language-lean">example (hp : p) : p :=
  hp
</code></pre>
<p>If you look at this proof in the infoview, putting your cursor at the beginning of the second like, you will see</p>
<pre><code>hp : p
⊢ p
</code></pre>
<p>Which says, give we have a proof <code>hp</code> of <code>p</code>, we need show <code>p</code>. This is easy, we jsut use <code>hp</code> itself.</p>
<h2 id="implies-rules"><a class="header" href="#implies-rules">Implies Rules</a></h2>
<p>We have two rules for the → connective:</p>
<pre><code>              Γ,φ ⊢ ψ
  →-Intro   ————————————
             Γ ⊢ φ → ψ

            Γ ⊢ φ → ψ    Γ ⊢ φ
  →-Elim   —————————————————————
                 Γ ⊢ ψ
</code></pre>
<p>The <strong>Implies Introduction</strong> rule allows us to introduce <code>φ → ψ</code> whenever we have <code>Γ</code> and <code>φ</code> together entailing <code>ψ</code>. The <strong>Implies Elimination</strong> rule is also know as <strong>Modus Ponens</strong>. It states that if we know <code>φ</code> implies <code>ψ</code> and we know <code>φ</code>, then we know <code>ψ</code>.</p>
<p>Notice that implies is written with an arrow <code>→</code> just like function abstraction in the λ-calculus. This is because one way to think about a proof of <code>φ→ψ</code> is to require it to have the form of a function that converts proofs of <code>φ</code> into proofs of <code>ψ</code>. This suggests that the way to prove statements with implications is to use  λ-calculus expressions. Here are a couple of examples.</p>
<p>First we show and example of →-Intro. The context includes a proof of <code>p</code>. Thus we can <em>introduce</em> <code>q→p</code> for any <code>q</code>. We do this with a lambda expression taking a proof of <code>q</code> (and in this case ignoring it) and returning the proof <code>hp</code> of <code>p</code> available in the context.</p>
<pre><code class="language-lean">example {hp : p} : q → p :=
  λ hq =&gt; hp
</code></pre>
<p>Next, here is an example of →-elim. We have a context with a proof of <code>p→q</code> and a proof of <code>p</code>. We know the proof <code>hp</code> of <code>p→q</code> is a lambda abstraction. So we can apply it to a proof <code>hp</code> of <code>p</code> to get a proof of <code>q</code>.</p>
<pre><code class="language-lean">example {hpq: p → q} {hp: p} :=
  hpq hp
</code></pre>
<p>A complete description of how →-introduction works works is in the chapter on the <a href="./CurryHoward.html">Curry-Howard Isomorphism</a></p>
<h2 id="and-rules"><a class="header" href="#and-rules">And Rules</a></h2>
<p>Next we have three rules for the ∧ connective:</p>
<pre><code>              Γ ⊢ φ   Γ ⊢ ψ
  ∧-Intro  ———————————————————
               Γ ⊢ φ ∧ ψ

                  Γ ⊢ φ ∧ ψ
  ∧-Elim-Left   ——————————————
                    Γ ⊢ φ

                  Γ ⊢ φ ∧ ψ
  ∧-Elim-Right  —————————————
                    Γ ⊢ ψ
</code></pre>
<p>Whenever we see "Intro" that means we are introducing a connective (in this case <code>∧</code>) into our conclusion. Whenever we see "Elim" that means we are eliminating part of a compound statement in our conclusion. Here, the <strong>And Introduction</strong> rule shows that we can construct a proof of <code>φ ∧ ψ</code> whenever the context contains a proof of <code>φ</code> and a proof of <code>ψ</code>. The <strong>And Elimination</strong> rules allow us to "eliminate" half of the proposition <code>φ ∧ ψ</code> to conclude the weaker statement <code>φ</code> or to conclude the weaker statement <code>ψ</code>. Said differently, if we have a proof of <code>φ∧ψ</code> then we can construct a proof of <code>φ</code> by just eliminating the part of the proof of <code>φ∧ψ</code> that shows <code>ψ</code>.</p>
<p>Unlike the somewhat cryptic rules for implies, the And rules just have functions (like <code>And.intro</code>) already defined for them. Here are examples of all of these rules in Lean.</p>
<pre><code class="language-lean">#check And.intro
#check And.left
#check And.right

example (hp : p) (hq : q) : p ∧ q :=
  And.intro hp hq

example (hpq : p ∧ q) : p :=
  And.left hpq

example (hpq : p ∧ q) : q :=
  And.right hpq
</code></pre>
<h2 id="or-rules"><a class="header" href="#or-rules">Or Rules</a></h2>
<p>Then we have three rules for the ∨ connective:</p>
<pre><code>                   Γ ⊢ φ
 ∨-Intro-Left   ———————————
                 Γ ⊢ φ ∨ ψ

                    Γ ⊢ ψ
 ∨-Intro-Right   ————————————
                  Γ ⊢ φ ∨ ψ

            Γ ⊢ φ ∨ ψ    Γ ⊢ φ → ρ    Γ ⊢ ψ → ρ
 ∨-Elim   ———————————————————————————————————————
                         Γ ⊢ ρ
</code></pre>
<p>The <strong>Or Introduction</strong> rules allow us to conclude <code>φ ∨ ψ</code> from one of its parts. The <strong>Or Elimination</strong> rule looks complicated, but it is straightforward. It says that if we know <code>Γ ⊢ φ ∨ ψ</code> then we know that <code>Γ</code> must entail either <code>φ</code> or <code>ψ</code>. If we also know that both <code>φ</code> and <code>ψ</code> separately entail <code>ρ</code>, then we know that <code>Γ</code> must entail <code>ρ</code>.</p>
<p>Here are examples of the OR rules in Lean.</p>
<pre><code class="language-lean">#check Or.inl
#check Or.inr
#check Or.elim

example (hp : p) : p ∨ q :=
  Or.inl hp

example (hq : q) : p ∨ q :=
  Or.inr hq

example (hpq : p ∨ q) : q ∨ p :=
  Or.elim
    hpq
    (λ hp =&gt; Or.inr hp)
    (λ hq =&gt; Or.inl hq)
</code></pre>
<h2 id="ex-falso"><a class="header" href="#ex-falso">Ex Falso</a></h2>
<p>Finally, we have the a rule for the ¬ connective:</p>
<pre><code>                Γ ⊢ False
  False -Elim ————————————
                  Γ ⊢ φ
</code></pre>
<p>which states that you can conclude anything if you have a proof of ⊥. This rule is also know as <code>ex falso sequitur quodlibet</code> or just <code>ex falso</code> or the <code>principle of explosion</code>! Here's an example:</p>
<pre><code class="language-lean">#check False.elim

example { hf : False } : p :=
  False.elim hf
</code></pre>
<h2 id="proofs-1"><a class="header" href="#proofs-1">Proofs</a></h2>
<p>A <strong>proof</strong> that <code>Γ ⊢ φ</code> is sequence of statements of the form <code>Γ' ⊢ φ'</code> each of which is either (a) an axiom or (b) obtained from previous statements in the sequence by one of the inference rules.</p>
<h3 id="example-1"><a class="header" href="#example-1">Example 1</a></h3>
<p>As an example, we will prove the statement</p>
<pre><code>∅ ⊢ (p∧q)→p
</code></pre>
<p>Working backwards from this goal, we see that <code>→-Intro</code> can be applied to produce this statement where <code>φ</code> is <code>p∧q</code> and <code>ψ</code> is <code>p</code>. Thus, we get an instance of →-Intro of the form</p>
<pre><code>  p∧q ⊢ p
———————————          (Instantiation of →-Intro)
 ⊢ (p∧q)→p
</code></pre>
<p>We have now a simpler problem, which is to show <code>p∧q ⊢ p</code>. The ∧-Elim-Left rule applies here with <code>φ=p∧q</code>, <code>ψ=p</code>, and <code>Γ={p∧q}</code> giving us the instance</p>
<pre><code>  p∧q ⊢ p∧q
——————————————       (Instantiation of ∧-Elim-Left)
   p∧q ⊢ p
</code></pre>
<p>And now we have an even simpler problem, which is to show that p∧q ⊢ p∧q. But this matches the axiom rule with <code>Γ={p∧q}</code> and <code>φ = p∧q</code>. Putting all this together into a proof gives us the following:</p>
<pre><code>  1) p∧q ⊢ p∧q          axiomatically
  2) p∧q ⊢ p            from (1) via ∧-Elim-Left
  3) ⊢ (p∧q)→p          from (2) via →-Intro
</code></pre>
<p>And that's it. Our first proof!</p>
<p>Here is the same proof in Lean:</p>
<pre><code class="language-lean">example : p∧q → p :=
  λ hpq =&gt; And.left hpq
</code></pre>
<p>The lambda expression encodes →-Intro, and <code>And.left</code> encodes ∧-Left.</p>
<p>What you can take away from this is the idea that constructing this proof is a purely syntactic endeavor. One can easily imagine an algorithm that does this automatically by pattern matching a given sub-goal against the <code>Γ</code>, <code>φ</code> and <code>ψ</code> in the description of a inference rule. The challenge is, of course, as we introduce more expressibility into our logic, and more inference rules, finding the right rules to apply at the right time amounts to a brute force search of all possible inference rules and all possible ways of instantiating those inference rools.</p>
<p>The other thing to notice is that the proof itself looks a lot like a program. In Lean and similar construction-based theorem provers, this observation is made precise. And it will turn out that writing proofs and writing programs amount to the same thing!</p>
<h3 id="example-2"><a class="header" href="#example-2">Example 2</a></h3>
<p>Here is a slightly more complicated example. Let's prove</p>
<pre><code>⊢ ¬p→(p→q)
</code></pre>
<p>Recall <code>¬p</code> is just shorthand for <code>p→⊥</code>. So we're actually trying to prove</p>
<pre><code>⊢ (p→⊥)→(p→q)
</code></pre>
<p>Once again, working backwards, we can apply →-Intro to get</p>
<pre><code>p→⊥ ⊢ p→q
</code></pre>
<p>and then apply →-Intro again to get</p>
<pre><code>p→⊥,p ⊢ q
</code></pre>
<p>Our context now contains both <code>¬p</code> and <code>p</code>. Using ⊥-elim we get</p>
<pre><code>p→⊥,p ⊢ ⊥
</code></pre>
<p>This subgoal matches the form of →-Elim with <code>φ=p</code> and <code>ψ=⊥</code>. Using this rule, we get two further subgoals that are just axioms:</p>
<pre><code>p→⊥,p ⊢ p→⊥      and      p→⊥,p ⊢ p
</code></pre>
<p>Putting this all together, we get the following proof:</p>
<pre><code>  1) p→⊥,p ⊢ p→⊥        axiomatically
  2) p→⊥,p ⊢ p          axiomatically
  3) p→⊥,p ⊢ ⊥          from (1) and (2) via →-Elim
  4) p→⊥,p ⊢ q          from (3) via ⊥-elim
  5) p→⊥ ⊢ p→q          from (4) via →-Intro
  6) ⊢ (p→⊥)→(p→q)      from (5) via →-Intro
</code></pre>
<p>And we're done! This is complicated though. Clearly we need a proof assistant to help us! In Lean this proof looks like:</p>
<pre><code class="language-lean">theorem t : ¬p→(p→q) :=
  λ hnp =&gt; λ hp =&gt; False.elim (hnp hp)
</code></pre>
<h2 id="the-law-of-the-excluded-middle"><a class="header" href="#the-law-of-the-excluded-middle">The Law of the Excluded Middle</a></h2>
<p>As we said, the law of the excluded middle states that</p>
<p>⊢ φ ∨ ¬φ</p>
<p>for all propositions φ. However, this statement is not provable using the inference rules above. To prove this meta-mathematical observation is beyond the scope of this lecture and requires an argument about the formal <code>semantics</code> of intuitionist propositional logic. For now, accept the fact that φ ∨ ¬φ cannot be proved rom the inference rules given, despite its seeming obviousness.</p>
<p>For this reason, intutionistic logic is weaker than classical logic. However, we can obtain classical logic by adding the above as a new axiom. When we get to proving statements in Lean, we'll see that we can add this axiom into our proofs if we would like to, so it is not big problem. However, it is also remarkable how much of mathematics we can do without this axiom.</p>
<h2 id="exercises-1"><a class="header" href="#exercises-1">Exercises</a></h2>
<ol>
<li>Prove <code>∅ ⊢ p → (p ∨ q)</code></li>
<li>Prove <code>∅ ⊢ (p ∨ q) → (q ∨ p)</code></li>
</ol>
<h1 id="references-1"><a class="header" href="#references-1">REFERENCES</a></h1>
<p>Morten Heine Sørensen, Pawel Urzyczyn
"Lectures on the Curry-Howard Isomorphism"
Elsevier. 1st Edition, Volume 149 - July 4, 2006.</p>
<ul>
<li>Chapter 2 describes Intuitionistic Propositional Logic</li>
</ul>
<div style='height=50px'>&nbsp;</div><hr>
Copyright © 2025 Eric Klavins
<div style="break-before: page; page-break-before: always;"></div><div style='display:none'>
--  Copyright (C) 2025  Eric Klavins
--
--  This program is free software: you can redistribute it and/or modify
--  it under the terms of the GNU General Public License as published by
--  the Free Software Foundation, either version 3 of the License, or
--  (at your option) any later version.   
</div>
<p><span style='color: orange'><em><strong>UNDER CONSTRUCTION</strong></em></span><br>
<span style='color: lightgray; font-size: 10pt'><a href='https://github.com/klavins/LeanBook/blob/main/main/../LeanBook/Chapters/CurryHoward.lean'>Code</a> for this chapter</span></p>
<h1 id="the-curry-howard-isomorphism"><a class="header" href="#the-curry-howard-isomorphism">The Curry-Howard Isomorphism</a></h1>
<p>Much of this chapter is an adaptation of the section of the book <em>Lectures on the Curry-Howard Isomorphism</em> by Morten Heine Sørensen and Pawel Urzyczyn. In particular, Chapter 4 of that book describes Intuitionistic Propositional Logic.</p>
<h1 id="statements-contexts-and-judgements"><a class="header" href="#statements-contexts-and-judgements">Statements, Contexts, and Judgements</a></h1>
<p>When we introduced the Simply Typed Lambda Calculus, we informally defined the type rules VAR, ABST and APPL. Here we define the typing system formally.</p>
<ul>
<li>
<p>A <strong>type statement</strong> is a pair x : σ where x is a type variable and σ is a type. We say "x is of type σ".</p>
</li>
<li>
<p>A <strong>typing context</strong> Γ is a finite set of type state statements.</p>
</li>
<li>
<p>A <strong>judgement</strong> is an expression of the form Γ ⊢ M : σ where Γ is a typing context, M is a simply typed λ-calculus statement, and σ is a type.</p>
</li>
</ul>
<p>For example, here is a judgment that states: "When f is a function from α to β and x is of type α, then f x is of type β. "</p>
<pre><code>  { f : α → β, x : α }  ⊢ f x : β
</code></pre>
<h2 id="typing-rules"><a class="header" href="#typing-rules">Typing Rules</a></h2>
<p>Typing rules are written the same way as the inference rules in propositional logic.</p>
<pre><code>  VAR   ————————————————
          Γ,x:τ ⊢ x:τ

               Γ,x:σ ⊢ M : τ
  ABST  ——————————————————————————
           Γ ⊢ (λ x:σ =&gt; M) : σ→τ

           Γ ⊢ M : σ→τ    Γ ⊢ N : σ
  APPL  ——————————————————————————————
                   M N : τ
</code></pre>
<p>The first rule says that if a context defines x to have type τ then (somewhat obviously) we can conclude x has type τ.</p>
<p>The second rule says that if our context defines x : σ and entails that M : τ, then we can form an abstraction from x and M that has type σ to τ.</p>
<p>The third rule says that if Γ entails both that M : σ→τ and N : σ, then the application of M to N has type τ.</p>
<h3 id="example"><a class="header" href="#example">Example</a></h3>
<p>Q: Find the type of</p>
<pre><code>λ x : A =&gt; x
</code></pre>
<p>A: Working backwards from this goal we use ABST with τ=A and M=x to get</p>
<pre><code>x:A ⊢ x:A
</code></pre>
<p>Then we use VAR. So the expression has type A→A and a proof of this is:</p>
<pre><code>1) x:A ⊢ x:A                  axiomatically
2) (λ x : A =&gt; x) : A→A       by ABST
</code></pre>
<p>As we have seen, Lean figures this out automatically.</p>
<pre><code class="language-lean">#check λ x : _ =&gt; x
</code></pre>
<h1 id="example-1"><a class="header" href="#example-1">EXAMPLE</a></h1>
<p>Q: Find the types of x and y in</p>
<pre><code>λ x =&gt; λ y =&gt; x y
</code></pre>
<p>A: Using the ABST rule gives</p>
<pre><code>x : B   ⊢  λ y =&gt; x y : A
</code></pre>
<p>for some types A and B. Using ABST again gives</p>
<pre><code>x : B, y : C   ⊢  x y : A
</code></pre>
<p>for some type C. Next we use the APPL rule with M = x, N = y, σ = C, τ = A</p>
<pre><code>x : B, y : C  ⊢  x : C → A
x : B, y : C  ⊢  y : C
</code></pre>
<p>These judgements would hold if B we equal to C→A. So we make that substitution so the above axioms hold to get:</p>
<pre><code>λ x : C → A =&gt; λ y : C =&gt; x y
</code></pre>
<p>for some types C and A. Generally speaking, type inference involves applying typing rules, accumulating type equations, and then solving the equations, all of which is done very efficiently in Lean's kernel.</p>
<h1 id="example-2"><a class="header" href="#example-2">Example</a></h1>
<p>Q: Find the overall type of the previous expression.</p>
<p>A: Following the derivation above in reverse gives the following type inference proof tree:</p>
<pre><code>    ————————————————————————————— VAR    ————————————————————————————— VAR
     x : C → A, y : C  ⊢  x : C → A       x : C → A, y : C  ⊢  y : C
    ———————————————————————————————————————————————————————————————————— APPL
                      x : C → A, y : C   ⊢  x y : A
                 ————————————————————————————————————————— ABST
                    x : C → A  ⊢  λ y : C =&gt; x y : C → A
            ————————————————————————————————————————————————————— ABST
             ⊢  λ x : C → A =&gt; λ y : C =&gt; x y : (C → A) → C → A
</code></pre>
<p>Thus, the type of <code>λ x =&gt; λ y =&gt; x y</code> is <code>(C → A) → C → A</code>. Note that with a little help, Lean can figure this out for us, but we do need to tell it that <code>x</code> is a function type of some kind.</p>
<pre><code class="language-lean">#check λ x : _ → _ =&gt; λ y : _ =&gt; x y
</code></pre>
<h2 id="curry-howard-isomorphism-intuition"><a class="header" href="#curry-howard-isomorphism-intuition">Curry-Howard Isomorphism Intuition</a></h2>
<p>Consider the two types we just found:</p>
<pre><code>A → A
(C → A) → C → A
</code></pre>
<p>The first one is the type of a function on. The second one is the type of a function that takes a function on <code>C → A</code>.</p>
<p>Wwe can also read these as propositional formulas which state</p>
<pre><code>A implies A
(C implies A) implies C implies A
</code></pre>
<p>It is not a coincidence that these are both tautologies.</p>
<p>The Curry-Howard Isomorphism emerges from the observation that the λ expressions that have the above types look a lot like the proofs that the above implications are tautologies!</p>
<p>With this observation, the statement x : A reads "x is a proof of A".</p>
<pre><code>λ x : A =&gt; x
</code></pre>
<p>is a method that takes a proof of A and returns a proof of A, proving the implication A → A.</p>
<h2 id="curry-howard-types--propositions"><a class="header" href="#curry-howard-types--propositions">Curry-Howard: Types → Propositions</a></h2>
<p>To state the CHI exacly, we will restrict ourselves to showing that Propositional Logic with only implication (→) is isomorphic to the simply typed λ-calculus. We will need one definition.</p>
<p><strong>Def:</strong> Given a context Γ = { x₁: φ₁, x₂ : φ₂, ..., xₙ : φₙ }, the <em>range</em> of Γ, denoted |Γ|, is { φ₁, φ₂, ..., φₙ }.</p>
<p><strong>Theorem:</strong> If Γ ⊢ M : φ then |Γ| ⊢ φ.</p>
<p><strong>Proof Sketch:</strong> We convert any type derivation tree into a propositional proof by replacing VAR with AX, ABST with →-Intro, and APPL with →-Elim. This is done by induction on the proof tree. Here we just show an example which should be easily generalized. The type proof tree in the previous section can be re-written be removing all "x : "</p>
<pre><code>    ————————————————————— AX       ———————————————————— AX
     C → A, C  ⊢  C → A               C → A, C  ⊢  C
  ——————————————————————————————————————————————————————————— →Elim
                      C → A, C   ⊢  A
                    ——————————————————— →-Intro
                      C → A  ⊢  C → A
                   —————————————————————— →-Intro
                    ⊢  (C → A) → C → A
</code></pre>
<h2 id="curry-howard-propositions--types"><a class="header" href="#curry-howard-propositions--types">Curry-Howard: Propositions → Types</a></h2>
<p>The opposite direction of the CHI is more technical. We have to show how to produce a λ-calculus term M from a proof of <code>φ</code> so that <code>M : φ</code>. For example, suppose we started with the propositional proof tree in the previous section. How would we produce the type derivation from it? Here we will outline how this is done in general.</p>
<p>First we need a way to produce a type context from a propositional context. Suppose that</p>
<pre><code>Γ = { φ₁, φ₂, ..., φₙ }
</code></pre>
<p>and define</p>
<pre><code>Δ = { x₁ : φ₁, x₂ : φ₂, ..., xₙ : φₙ }
</code></pre>
<p>where the <code>xᵢ</code> are introduced as new type variables. The object <code>Δ</code> is a function of <code>Γ</code> of course, but we just don't write it this way.</p>
<p><strong>Theorem:</strong> If <code>Γ ⊢ φ</code> then there exists a λ-calculus term <code>M</code> such that <code>∆ ⊢ M:φ</code>.</p>
<p>The proof of this theorem uses induction on the proof tree that shows <code>Γ ⊢ φ</code>. Since there are three rules (AX, →Intro, and →-Elim), we have three cases, which we handle one by one.</p>
<p><em>Case:</em> The proof ends with <code>Γ,φ ⊢ φ</code> by the VAR rule</p>
<p><em>Subcase 1</em>: If <code>φ ∈ Γ</code> then there is some type variable <code>x</code> such that <code>x : φ ∈ Δ</code>. By the VAR rule we can conclude</p>
<pre><code>Δ  ⊢  x : φ
</code></pre>
<p><em>Subcase 2</em>: If <code>φ ∉ Γ</code> then we introduce a new variable <code>x</code> such that <code>x : φ</code>. Once again by the VAR rule</p>
<pre><code>Δ, x : φ  ⊢  x : φ
</code></pre>
<p>(Why do we need two sub-cases? It's because of how we defined <code>Δ</code> on the previous as related to <code>Γ</code> and not to <code>Γ ∪ { x : φ }</code>).</p>
<p><em>Case:</em> The proof ends with →Elim</p>
<p>Suppose the proof that <code>Γ ⊢ φ</code> ends with</p>
<pre><code>    Γ ⊢ ρ → φ      Γ ⊢ ρ
  ——————————————————————————
           Γ ⊢ φ
</code></pre>
<p>We need to find a λ-term that has type <code>φ</code>. Here the premises of the above rule instance allow us to assume the induction hypothesis that there exists <code>M</code> and <code>N</code> such that</p>
<pre><code>Δ ⊢ M : ρ → φ
Δ ⊢ N : ρ
</code></pre>
<p>By the ABST rule, we can conclude</p>
<pre><code>Δ ⊢ M N : φ
</code></pre>
<p><em>Case:</em>: The proof ends with →Intro</p>
<p>Suppose the proposition <code>φ</code> has the form the <code>ρ → ψ</code> and the proof <code>Γ ⊢ ρ → ψ</code> ends with</p>
<pre><code>     Γ, ρ ⊢ ψ
  ——————————————
    Γ ⊢ ρ → ψ
</code></pre>
<p>Subcase 1: <code>ψ ∈ Γ</code>. By the induction hypothesis, there is a term <code>M</code> such that <code>Δ ⊢ M : ψ</code>. Introduce a variable <code>x</code> (not used in <code>Δ</code>) such that <code>x : ρ</code>. Then we can conclude</p>
<pre><code>Δ, x : ρ  ⊢  M : ψ
</code></pre>
<p>and by the ABST rule</p>
<pre><code>Δ ⊢ λ x : ρ =&gt; M : ρ →  ψ
</code></pre>
<p>Subcase 2: <code>ψ ∉ Γ</code>. Then by the induction hypothesis, there is a term <code>M</code> such that</p>
<pre><code>Δ, x : ρ ⊢ M : ψ
</code></pre>
<p>from which we may also conclude</p>
<pre><code>Δ ⊢ λ x : ρ =&gt; M : ρ →  ψ
</code></pre>
<h2 id="propositions-theorems-and-proofs-in-lean"><a class="header" href="#propositions-theorems-and-proofs-in-lean">Propositions, Theorems, and Proofs in Lean</a></h2>
<p>The Curry-Howard approach is exactly how proofs of theorems are done in Lean. We show that the proposition to be proved is inhabited. In the examples below, we use the type Prop, from Lean's standard library.</p>
<p>We will start by declaring two variables of type Prop. We use curly braces here instead of parentheses for reasons we will explain later.</p>
<pre><code class="language-lean">variable { A C : Prop }
</code></pre>
<p>To prove a proposition like A → A, we define the identity function from A into A, showing the proposition considered as a type is occupied. We have called the bound variable in the lambda expression <em>proof</em>, but you could call the bound variable anything you like.</p>
<pre><code class="language-lean">def my_theorem : A → A :=
  λ proof : A =&gt; proof
</code></pre>
<p>Lean provides the keyword <em>theorem</em> for definitions intended to be results, which is like def but does requires the type of the theorem being defined to be Prop. The theorem keyword also gives Lean and the user an indication of the intended use of the definition.</p>
<pre><code class="language-lean">theorem my_lean_theorem : A → A :=
  λ proof : A =&gt; proof
</code></pre>
<h3 id="applying-theorems-to-prove-other-theorems"><a class="header" href="#applying-theorems-to-prove-other-theorems">APPLYING THEOREMS TO PROVE OTHER THEOREMS</a></h3>
<p>As another example, we prove the other proposition we encountered above. Here we call the bound variables pca for "proof of c → a" and pc for "proof of c".</p>
<pre><code class="language-lean">theorem another_theorem : (C → A) → C → A :=
  λ pca : C → A =&gt;
  λ pc : C =&gt;
  pca pc
</code></pre>
<p>Or even better, we can use our first theorem to prove the second theorem:</p>
<pre><code class="language-lean">theorem another_theorem_v2 : (C → A) → C → A :=
  λ h : C → A =&gt; my_lean_theorem h
</code></pre>
<h3 id="more-examples"><a class="header" href="#more-examples">More Examples</a></h3>
<pre><code class="language-lean">theorem t1 : A → C → A :=
  λ pa : A =&gt;
  λ pc : C =&gt;                                -- Notice that pc is not used
  pa

theorem t2 : A → C → A :=
  λ pa pc  =&gt; pa                             -- We can use λ with two arguments

theorem t3 : A → C → A :=
  λ pa _ =&gt; pa                               -- We can tell Lean we know pc is not used

example : A → C → A :=                       -- We can state and prove an unnamed theorem
  λ pa _ =&gt; pa                               -- using the `example` keyword
</code></pre>
<h3 id="negation"><a class="header" href="#negation">NEGATION</a></h3>
<p>There are, of course, only so many theorems we can state using only implication. In the next chapter we will show how the λ-calculus can be extended to include <code>∧</code>, <code>∨</code>, and <code>False</code>. To give a sense of how this looks, here is an example using <code>¬p</code>, which as you will recall is the same as <code>p → False</code>.</p>
<pre><code class="language-lean">variable (p q: Prop)

example : p → ¬p → q :=
  λ pa pna =&gt; absurd pa pna

example : (p → q) → (¬q → ¬p) :=
  fun hpq nq hp =&gt; absurd (hpq hp) nq
</code></pre>
<p>Here, absurd is a theorem from the Lean standard library that we will discuss when we get to Lean's <code>inductive type</code> system.</p>
<h3 id="a-note-about-variable-declarations"><a class="header" href="#a-note-about-variable-declarations">A Note About Variable Declarations</a></h3>
<p>If we had used</p>
<pre><code class="language-hs">variable (A C : Prop)
</code></pre>
<p>above, then my_lean_theorem would have (A : Prop) as a non-implicit argument, so it would have to be applied as</p>
<pre><code class="language-hs">my_lean_theorem hca h
</code></pre>
<p>which is ugly.</p>
<p>The way Lean uses variables is by putting them silently into all definitions and theorems that use them. So my_theorem internally looks like:</p>
<pre><code class="language-hs">theorem my_lean_theorem (A : Prop) : A → A :=
  λ proof : A =&gt; proof
</code></pre>
<p>On the other hand, if we use curly braces in the variable declaration, as we did in the previous examples, then we get</p>
<pre><code class="language-hs">theorem my_lean_theorem {A : Prop} : A → A :=
  λ proof : A =&gt; proof
</code></pre>
<p>so that the type of A is an implicit argument to my_lean_theorem.</p>
<h2 id="references-2"><a class="header" href="#references-2">References</a></h2>
<p>Morten Heine Sørensen, Pawel Urzyczyn
"Lectures on the Curry-Howard Isomorphism"
Elsevier. 1st Edition, Volume 149 - July 4, 2006.</p>
<ul>
<li>Chapter 4 describes Intuitionistic Propositional Logic</li>
</ul>
<div style='height=50px'>&nbsp;</div><hr>
Copyright © 2025 Eric Klavins
<div style="break-before: page; page-break-before: always;"></div><div style='display:none'>
--  Copyright (C) 2025  Eric Klavins
--
--  This program is free software: you can redistribute it and/or modify
--  it under the terms of the GNU General Public License as published by
--  the Free Software Foundation, either version 3 of the License, or
--  (at your option) any later version.   
</div>
<p><span style='color: orange'><em><strong>UNDER CONSTRUCTION</strong></em></span><br>
<span style='color: lightgray; font-size: 10pt'><a href='https://github.com/klavins/LeanBook/blob/main/main/../LeanBook/Chapters/InductiveTypes.lean'>Code</a> for this chapter</span></p>
<h1 id="inductive-types"><a class="header" href="#inductive-types">Inductive Types</a></h1>
<p>As we saw in the chapter on the <a href="LambdaCalculus.html">λ-Calculus</a>, we can encode fairly sophisticated objects like the natural numbers using just abstractions and applications. However, such encodings are a best clunky and hard to read. Additionally, encoding complex data types as λ-Calculus expressions has other problems:</p>
<p><strong>Noncanonical terms:</strong> The types of such encodings are not guaranteed to result in <em>canonical</em> terms. For example, Church numerals were defined to have type</p>
<pre><code class="language-lean">def α := Type
def N := (α → α) → α → α
</code></pre>
<p>But we can define expressions that have this type but that do not correspond to natural numbers. For example,</p>
<pre><code class="language-lean">def nc : N := λ (f : α  → α) (x : α) =&gt; x
</code></pre>
<p>It would be vastly preferable if (a) every object of a given type was a legitimate representative of that type and every object also had exactly one representative.</p>
<p><strong>Pattern Matching and Induction:</strong> To prove properties above objects of a given type, it is useful to apply induction on the structure of the object. For example, a natural number is either zero, or it is the successor of some other natural number. To prove a statement about natural numbers one would like support for pattern matching on the way the number was constructed.</p>
<p><strong>Termination:</strong> As we have seem, operations on terms of a given type in the pure lambda calculus are not guaranteed to terminate. However, we will see that all terms of a given inductive type support <em>structural recursion</em>: We can define functions on that break the term into smaller pieces which eventually lead to indivisible elements, at which point the function terminates.</p>
<p>Thus, Lean and other type theoretic languages include a way to define types inductively. One lists all the ways to construct objects of a given type. Lean then provides a powerful pattern matching capability that can be used in definitions and theorems when operating or reasoning on an object defined inductively.</p>
<h3 id="namespaces"><a class="header" href="#namespaces">Namespaces</a></h3>
<p>In this chapter we will be redefining several fundamental types in Lean, such as the natural numbers <code>ℕ</code> and the propositional connectives <code>And</code> and <code>Or</code>. Since these are part of Lean's standard library (included by default), if we do not take appropriate measures, we will get naming collisions. The easiest way to avoid this is to open a temporary namespace.</p>
<pre><code class="language-lean">namespace Temp
</code></pre>
<p>Now, when we define a new symbol, such as</p>
<pre><code class="language-lean">def Thing := Type
</code></pre>
<p>we are actually defining Temp.Thing. If Thing is defined in some inluded library, our new definition will not collide with it.</p>
<h2 id="leans-inductive-types"><a class="header" href="#leans-inductive-types">Lean's Inductive Types</a></h2>
<p>So far we have introduced only simple <strong>arrow types</strong> composed Lean's basic type (called Type) and functions from those types into types. We now introduce a powerful way to make new types, which covers almost all of mathematics, called <strong>inductive types</strong>.</p>
<p>An inductive type is <strong>generated</strong> by <strong>constructors</strong> that may refer to the type itself. They say how to make objects of the given type.</p>
<p><strong>Example:</strong> A type with only two elements is defined by:</p>
<pre><code class="language-lean">inductive Two where
  | a : Two
  | b : Two

#check Two.a
#check Two.b

def t := Two.a
#eval t
</code></pre>
<p><strong>Example:</strong> The simplest inductive type has <em>no</em> constructors, meaning it specifies the empty type.</p>
<pre><code class="language-lean">inductive Empty
</code></pre>
<h2 id="constructors-with-arguments"><a class="header" href="#constructors-with-arguments">Constructors With Arguments</a></h2>
<p>You can also have constructors that take arguments and transform them into objects of the given type.</p>
<p><strong>Example:</strong> The type Nat of <strong>Natural Numbers</strong> is defined by two constructors:</p>
<pre><code class="language-lean">inductive Nat where
  | zero : Nat
  | succ : Nat → Nat           -- succ stands for `successor`

open Nat
#check succ (succ (succ zero)) -- 3
</code></pre>
<p>All the constructors in an inductively defined type live in a namespace with the same name as the type. The open command allows us to write succ instead of Nat.succ. We can also write</p>
<pre><code class="language-lean">#check zero.succ.succ.succ
</code></pre>
<p>using so-called dot-notation.</p>
<p>Objects of type <code>Nat</code> thus either have the form <code>zero</code> or they consist of some finite number of applications of <code>succ</code> to the element <code>zero</code>. With more types, we can define even more complicated objects.</p>
<p><strong>Example:</strong> A simple grammar for arithmetic expressions can be defined by the type:</p>
<pre><code class="language-lean">inductive Expr where
  | var : String → Expr
  | add : Expr → Expr → Expr
  | mul : Expr → Expr → Expr
  | neg : Expr → Expr

open Expr
</code></pre>
<p>Some example terms include</p>
<pre><code class="language-lean">#check add (var "x") (var "y")                          -- x+y
#check add (var "x") (mul (neg (var "y")) (var "z"))    -- x-yz
</code></pre>
<h2 id="functions-of-inductive-types"><a class="header" href="#functions-of-inductive-types">Functions of Inductive Types</a></h2>
<p>To work with objects of inductive types, we usually need to know how the object was constructed. Lean uses the keyword <code>match</code> for that.</p>
<p><strong>Example:</strong> Toggling a Two</p>
<pre><code class="language-lean">def Two.toggle ( x : Two ) := match x with
  | a =&gt; b
  | b =&gt; a
</code></pre>
<p>Lean also knows how to reduce expressions involving match.</p>
<pre><code class="language-lean">open Two

#reduce toggle (toggle a)
#reduce a.toggle.toggle
</code></pre>
<p><strong>Example:</strong> 1+1 = 2</p>
<pre><code class="language-lean">def Nat.plus (n m : Nat) := match n with
  | zero =&gt; m
  | succ x =&gt; succ (plus x m)

open Nat

#reduce plus (succ zero) (succ zero)  -- zero.succ.succ
</code></pre>
<p><strong>Example:</strong> Swap Adds and Muls</p>
<pre><code class="language-lean">def Expr.swap (e : Expr) := match e with
  | var s =&gt; var s
  | add x y =&gt; add y x
  | mul x y =&gt; mul y x
  | neg x =&gt; neg x


def e := add (var "x") (mul (neg (var "y")) (var "z"))

#reduce e.swap -- -zy+x
</code></pre>
<h2 id="inductive-types-may-depend-on-other-types"><a class="header" href="#inductive-types-may-depend-on-other-types">Inductive Types May Depend on Other Types</a></h2>
<p>The types we have defined so far do not interact with other types. Here's an example that does: Lists of Nats.</p>
<pre><code class="language-lean">inductive NatList where
  | empty : NatList
  | cons : Nat → NatList → NatList

namespace NatList

#check cons zero (cons zero empty)              -- [0, 0]
#check (empty.cons zero).cons zero              -- [0, 0]

end NatList

#check [1,2]
</code></pre>
<p>Or we can define a List of elements of any type. In the the next bit of code, we implicitly state (using curly braced instead of parens) that List depends on an arbitrary type α.</p>
<pre><code class="language-lean">inductive List {α : Type} where
  | empty : List
  | cons : α → List → List

namespace List
#check cons "lean" (cons "is cool" empty)       -- ["lean", "is cool"]
#check cons 3.4 (cons 1.21 empty)               -- [3.14, 1.21]

end List
</code></pre>
<div style='height=50px'>&nbsp;</div><hr>
Copyright © 2025 Eric Klavins
<div style="break-before: page; page-break-before: always;"></div><div style='display:none'>
--  Copyright (C) 2025  Eric Klavins
--
--  This program is free software: you can redistribute it and/or modify
--  it under the terms of the GNU General Public License as published by
--  the Free Software Foundation, either version 3 of the License, or
--  (at your option) any later version.   
</div>
<p><span style='color: orange'><em><strong>UNDER CONSTRUCTION</strong></em></span><br>
<span style='color: lightgray; font-size: 10pt'><a href='https://github.com/klavins/LeanBook/blob/main/main/../LeanBook/Chapters/Connectives.lean'>Code</a> for this chapter</span></p>
<h1 id="propositional-logic-connectives"><a class="header" href="#propositional-logic-connectives">Propositional Logic Connectives</a></h1>
<p>One of the remarkable things about inductive types is that they capture all of propositional logic, first order logic, and more. Thus, instead of defining <em>and</em>, <em>or</em> and the other logical connectives as built-in operators in the Lean language, they are just defined in the standard library in terms of more primitive inductive types.</p>
<pre><code class="language-lean">namespace Temp
</code></pre>
<h2 id="and-is-an-inductive-type"><a class="header" href="#and-is-an-inductive-type"><em>And</em> is an Inductive Type</a></h2>
<p>Recall the inference rule</p>
<pre><code>                 Γ ⊢ φ   Γ ⊢ ψ
    ∧-Intro ———————————————————
                  Γ ⊢ φ ∧ ψ
</code></pre>
<p>It states that whenever we know propositions φ and ψ, then we know φ ∧ ψ. From the point of view of types, it says that if φ and ψ are of type Prop, then so is φ ∧ ψ. In Lean we can write this as an inductive type definition as follows.</p>
<pre><code class="language-lean">inductive And (φ ψ : Prop) : Prop where
  | intro : φ → ψ → And φ ψ
</code></pre>
<p>You can think of <code>h : And p q</code> as</p>
<ul>
<li>h has type And p q</li>
<li>h is evidence that the type And p q is not empty</li>
<li>h is a proof of the proposition And p q.</li>
</ul>
<h2 id="a-proof-of-a-simple-proposition"><a class="header" href="#a-proof-of-a-simple-proposition">A Proof of a Simple Proposition</a></h2>
<p>Consider the proposition</p>
<pre><code>p → q → And p q
</code></pre>
<p>As a type, this proposition is a function from p to q to And p q. Thus, we know that an element of this type has the form</p>
<pre><code>λ hp =&gt; λ hq =&gt; sorry
</code></pre>
<p>For the body of this lambda abstraction, we need to <code>introduce</code> an And type, which requires proofs of p and q respectively. Using the inductive definition of And we get</p>
<pre><code>λ hp hq =&gt; And.intro hp hq
</code></pre>
<pre><code class="language-lean">example (p q : Prop) : p → q → And p q :=
  λ hp =&gt; λ hq =&gt; And.intro hp hq
</code></pre>
<h2 id="and-eliminiation"><a class="header" href="#and-eliminiation">And Eliminiation</a></h2>
<p>The elimination rules for And are</p>
<pre><code>                Γ ⊢ φ ∧ ψ                          Γ ⊢ φ ∧ ψ
  ∧-Elim-Left ——————————————         ∧-Elim-Right —————————————
                  Γ ⊢ φ                              Γ ⊢ ψ
</code></pre>
<p>which we can write in Lean as</p>
<pre><code class="language-lean">def And.left {p q : Prop} (hpq : And p q) :=
  match hpq with
  | And.intro hp _ =&gt; hp

def And.right {p q : Prop} (hpq : And p q) :=
  match hpq with
  | And.intro _ hq =&gt; hq
</code></pre>
<h3 id="proofs-with-and-elimination"><a class="header" href="#proofs-with-and-elimination">Proofs with And-Elimination</a></h3>
<p>With these inference rules, we can do even more proofs:</p>
<pre><code class="language-lean">example (p q : Prop) : (And p q) → p :=
  λ hpq =&gt; And.left hpq

example (p q : Prop) : (And p q) → (And q p) :=
  λ hpq =&gt; And.intro hpq.right hpq.left
</code></pre>
<h3 id="match-is-enough"><a class="header" href="#match-is-enough">Match is Enough</a></h3>
<p>Note that the elimination rules above are a <em>convenience</em> we defined to make the proof look more like propositional logic. We could also have written:</p>
<pre><code class="language-lean">example (p q : Prop) : (And p q) → p :=
  λ hpq =&gt; match hpq with
    | And.intro hp _ =&gt; hp
</code></pre>
<p>This pattern illustrates how with inductive types we can think of <code>match</code> as a generic elimination rule.</p>
<h2 id="or-is-inductive"><a class="header" href="#or-is-inductive">Or is Inductive</a></h2>
<p>To introduce new OR propositions, we use the two introduction rules</p>
<pre><code>                 Γ ⊢ φ                              Γ ⊢ ψ
 ∨-Intro-Left ———————————          ∨-Intro-Right ————————————
               Γ ⊢ φ ∨ ψ                          Γ ⊢ φ ∨ ψ
</code></pre>
<p>In Lean, we have</p>
<pre><code class="language-lean">inductive Or (φ ψ : Prop) : Prop where
  | inl (h : φ) : Or φ ψ
  | inr (h : ψ) : Or φ ψ
</code></pre>
<p>And we can use this inference rule in proofs as well.</p>
<pre><code class="language-lean">example (p q : Prop) : And p q → Or p q :=
  λ hpq =&gt; Or.inr hpq.right
</code></pre>
<h3 id="or-elimination"><a class="header" href="#or-elimination">Or Elimination</a></h3>
<p>Recall the inference rule</p>
<pre><code>           Γ,p ⊢ r    Γ,q ⊢ r    Γ ⊢ p ∨ q
  ∨-Elim ————————————————————————————————————
                       Γ ⊢ r
</code></pre>
<p>It allows us to prove r given proofs that <code>p → r</code>, <code>q → r</code> and <code>p ∨ q</code>. We can define this rule in Lean with:</p>
<pre><code class="language-lean">def Or.elim {p q r : Prop} (hpq : Or p q) (hpr : p → r) (hqr : q → r) :=
  match hpq with
  | Or.inl hp =&gt; hpr hp
  | Or.inr hq =&gt; hqr hq
</code></pre>
<h3 id="example-of-and-or-elim-proof"><a class="header" href="#example-of-and-or-elim-proof">Example of and Or-Elim Proof</a></h3>
<p>Here is an example proof using introduction and elimination.</p>
<pre><code class="language-lean">example (p q : Prop): Or p q → Or q p :=
  λ hpq =&gt; Or.elim
    hpq                               -- p ∨ q
    (λ hp =&gt; Or.inr hp)               -- p → (q ∨ p)
    (λ hq =&gt; Or.inl hq)               -- q → (q ∨ p)
</code></pre>
<p>Once again, the elimination rule is just a convenience and the proof could have been written with <code>match</code>.</p>
<h2 id="false-is-inductive"><a class="header" href="#false-is-inductive">False is Inductive</a></h2>
<p>Finally, we have <code>False</code>, which has no introduction rule, kind of like <code>Empty</code>, except we add the requirement that <code>False</code> is also type of <code>Prop</code>.</p>
<pre><code class="language-lean">inductive False : Prop
</code></pre>
<p>From False we get the <code>Not</code> connective, which is just "syntactic sugar".</p>
<pre><code class="language-lean">def Not (p : Prop) : Prop := p → False
</code></pre>
<p>Here is an example proof:</p>
<pre><code class="language-lean">example (p q : Prop): (p → q) → (Not q → Not p) :=
  λ hpq hq =&gt; λ hp =&gt; hq (hpq hp)
</code></pre>
<h3 id="false-elimination"><a class="header" href="#false-elimination">False Elimination</a></h3>
<p>To define the elimination rule for false</p>
<pre><code>           Γ ⊢ ⊥
  ⊥-Elim ——————————
           Γ ⊢ p
</code></pre>
<p>we take advantage of the fact that False was defined inductively.</p>
<pre><code class="language-lean">def False.elim { p : Prop } (h : False) : p :=
  nomatch h
</code></pre>
<p>Here is an example proof that from False you can conclude anything:</p>
<pre><code class="language-lean">example (p q : Prop): And p (Not p) → q :=
  λ h =&gt; False.elim (h.right h.left)
</code></pre>
<p>By the way, this elimination rule provides another way to prove the example:</p>
<pre><code class="language-lean">example : False → True :=
  False.elim
</code></pre>
<h2 id="notation"><a class="header" href="#notation">Notation</a></h2>
<p>The main difference between what we have defined here and Lean is that Lean defines notation like <code>∨</code> and <code>∧</code>. We won't redo that entire infrastructure here. But to give a sense of it, here is how Lean defines infix notation for Or, And, and Not notation.</p>
<pre><code class="language-hs">infixr:30 " ∨ "  =&gt; Temp.Or
infixr:35 " ∧ "   =&gt; Temp.And
notation:max "¬" p:40 =&gt; Temp.Not p
</code></pre>
<p>The numbers define the precedence of the operations. So <code>v</code> has lower precedence than <code>∧</code>, which has lower precedence than <code>¬</code>.</p>
<p>Now we can write</p>
<pre><code class="language-lean">end Temp -- start using Lean's propositions

example (p q : Prop): (p ∧ (¬p)) → q :=
  λ h =&gt; False.elim (h.right h.left)
</code></pre>
<h2 id="exercises-2"><a class="header" href="#exercises-2">Exercises</a></h2>
<p><span></span> 1) Try to do as many of these as possible. These are borrowed from the <a href="https://lean-lang.org/theorem_proving_in_lean4/title_page.html">Theorem Proving in Lean Book</a>.</p>
<pre><code class="language-lean">variable (p q r : Prop)

example (h : p ∨ q) : q ∨ p := sorry
example : p ∧ q ↔ q ∧ p := sorry
example : p ∨ q ↔ q ∨ p := sorry
example : (p ∨ q) ∨ r ↔ p ∨ (q ∨ r) := sorry
example : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) := sorry
example : p ∨ (q ∧ r) ↔ (p ∨ q) ∧ (p ∨ r) := sorry
example : (p → (q → r)) ↔ (p ∧ q → r) := sorry
example : ((p ∨ q) → r) ↔ (p → r) ∧ (q → r) := sorry
example : ¬(p ∨ q) ↔ ¬p ∧ ¬q := sorry
example : ¬p ∨ ¬q → ¬(p ∧ q) := sorry
example : ¬(p ∧ ¬p) := sorry
example : p ∧ ¬q → ¬(p → q) := sorry
example : ¬p → (p → q) := sorry
example : (¬p ∨ q) → (p → q) := sorry
example : p ∨ False ↔ p := sorry
example : p ∧ False ↔ False := sorry
example : (p → q) → (¬q → ¬p) := sorry
example : (p → q) → (¬q → ¬p) := sorry
</code></pre>
<p><span></span> 2) Consider the Not-Or operation also known as Nor. It has the following inference rules:</p>
<pre><code>                 Γ ⊢ ¬p   Γ ⊢ ¬q
  `Nor-Intro` ———————————————————
                  Γ ⊢ Nor p q


                    Γ ⊢ Nor p q                            Γ ⊢ Nor p q
  `Nor-Elim-Left` ——————————————         `Nor-Elim-Right` —————————————
                      Γ ⊢ ¬p                                 Γ ⊢ ¬q

</code></pre>
<p>Define these in Lean. Here is a start:</p>
<pre><code class="language-lean">inductive Nor (p q : Prop) : Prop where
  | intro : ¬p → ¬q → Nor p q

def Nor.elim_left {p q : Prop} (hnpq : Nor p q) := sorry

def Nor.elim_right {p q : Prop} (hnpq : Nor p q) := sorry
</code></pre>
<p><span></span> 3) Use the above Nor inference rules, and the regular inference rules from Lean's propopsitional logic, to prove the following examples. Note, <em>do not</em> use the Classical logic option for these. It isn't needed.</p>
<pre><code class="language-lean">example (p : Prop) : ¬p → (Nor p p) := sorry
example (p q : Prop) : (Nor p q) → ¬(p ∨ q) := sorry
example (p q : Prop) : ¬(p ∨ q) → (Nor p q) := sorry

6) Using the definition of natural numbers below, define functions that perform multiplication and exponentiation similarly to how addition was defined in the Lecture on Inductive Types. Do *not* use Lean's built in natural numbers to do this. Evaluate your functions on a few examples to show they work. -/

namespace Temp

inductive Nat where
  | zero : Nat
  | succ : Nat → Nat           -- succ stand for `successor`

open Nat

def mult (m n : Nat) : Nat := sorry
def exp (m n : Nat) : Nat := sorry
</code></pre>
<p><span></span>
4) Using Lean's built in Integer class, we can define a new inductive type <code>GaussianInt</code> as follows:</p>
<pre><code class="language-lean">inductive GaussianInt where
  | gint : Int → Int → GaussianInt

open GaussianInt
</code></pre>
<p>For example, we can represent the complex number 1 + 2 i with</p>
<pre><code class="language-lean">#check gint 1 2
</code></pre>
<p>Define real, imaginary, addition, subtraction, complex conjugate, and multiplication operations for GaussianInt:</p>
<pre><code class="language-lean">def re (x : GaussianInt) : Int := sorry
def im (x : GaussianInt) : Int := sorry
def cadd (x y : GaussianInt) : GaussianInt := sorry
def csub (x y : GaussianInt) : GaussianInt := sorry
def conjugate (x : GaussianInt) : GaussianInt := sorry
def cmul (x y : GaussianInt) : GaussianInt := sorry
</code></pre>
<p>Test all of these with eval to make sure they work.</p>
<h2 id="references-3"><a class="header" href="#references-3">References</a></h2>
<ul>
<li>
<p>https://lean-lang.org/theorem_proving_in_lean4/inductive_types.html</p>
</li>
<li>
<p>Homotypy Type Theory Book
https://homotopytypetheory.org/book/
Chapter 5 covers inductive types</p>
</li>
</ul>
<div style='height=50px'>&nbsp;</div><hr>
Copyright © 2025 Eric Klavins
<div style="break-before: page; page-break-before: always;"></div><div style='display:none'>
--  Copyright (C) 2025  Eric Klavins
--
--  This program is free software: you can redistribute it and/or modify
--  it under the terms of the GNU General Public License as published by
--  the Free Software Foundation, either version 3 of the License, or
--  (at your option) any later version.   
</div>
<p><span style='color: orange'><em><strong>UNDER CONSTRUCTION</strong></em></span><br>
<span style='color: lightgray; font-size: 10pt'><a href='https://github.com/klavins/LeanBook/blob/main/main/../LeanBook/Chapters/FirstOrderLogic.lean'>Code</a> for this chapter</span></p>
<h1 id="first-order-logic"><a class="header" href="#first-order-logic">First Order Logic</a></h1>
<h2 id="limitations-of-propositional-logic"><a class="header" href="#limitations-of-propositional-logic">Limitations of Propositional Logic</a></h2>
<p>The main thing missing from propositional logic is objects. For example, suppose we wanted reason about statements like:</p>
<ul>
<li>Every person who lives in Seattle lives in Washington.</li>
<li>There exists a person who does not live in Seattle.</li>
</ul>
<p>These statements would be difficult in propositional logic, although given that there are only a finite number of people in the world we could say things like:</p>
<ul>
<li>lives_in_seattle_eric → lives_in_washington_eric</li>
<li>lives_in_seattle_fred → lives_in_washington_fred</li>
<li>...</li>
</ul>
<p>where we create new propositions for every person and every statement we would like to say about that person. However, what if we wanted to reason about an infinite domain like ℕ and say things like the following?</p>
<ul>
<li>every natural number is either odd or even</li>
</ul>
<p>Since there are an infinite number of natural numbers, we need an infinite number of propositions</p>
<ul>
<li>odd_0, even_0, odd_1, even_1, ...</li>
</ul>
<h2 id="first-order-logic-1"><a class="header" href="#first-order-logic-1">First Order Logic</a></h2>
<p>First order logic (FOL) enriches propositional logic with the following elements:</p>
<ul>
<li><strong>Objects</strong>: such as numbers, names, people, places, etc.</li>
<li><strong>Functions</strong>: that transform objects into other objects -- See next set of notes</li>
<li><strong>Predicates</strong>: that relate objects to objects</li>
<li><strong>Quantifiers</strong>: ∀ and ∃ that allow us to say:
<ul>
<li>∀: For all objects ___</li>
<li>∃: There exists an object such that ___</li>
</ul>
</li>
<li>All the connectives we have encountered so far: ∨, ∧, →, ¬, ...</li>
<li><strong>Types</strong>: Traditional FOL does not have types, but we will use them anyway)</li>
</ul>
<p>For example, in the following proposition built from these elements:</p>
<pre><code>∀ x ∃ y , f x &gt; y
</code></pre>
<p>is read "For all x, there exists a y such that f(x) is greater than y". In this example,</p>
<ul>
<li>The objects x and y are presumbly numbers</li>
<li>The symbol f is a function that maps numbers to numbers</li>
<li>The symbol &gt; is predicate taking two arguments and return true or false</li>
</ul>
<p>All of this can be done easily in Lean.</p>
<pre><code class="language-lean">variable (f : Nat → Nat)
#check ∀ x : Nat , ∃ y : Nat , f x &gt; y
</code></pre>
<h3 id="objects"><a class="header" href="#objects">Objects</a></h3>
<p><strong>Objects</strong> in FOL can come from any agreed upon universe. Since we will be using Lean to work with first order logic, you can just assume that objects are any basic terms: numbers, strings, lists, and so on. FOL does not allow us to quantify over functions and types, only basic objects.</p>
<h4 id="example-a-finite-universe-of-people"><a class="header" href="#example-a-finite-universe-of-people">Example: A Finite Universe of People</a></h4>
<p>For example, suppose we wanted to reason about a finite number of people. In Lean we can enumerate them with a new type:</p>
<pre><code class="language-lean">inductive Person where | mary | steve | ed | jolin

open Person

#check ed
</code></pre>
<h4 id="example--natural-numbers-strings-booleans-etc"><a class="header" href="#example--natural-numbers-strings-booleans-etc">Example : Natural Numbers, Strings, Booleans, etc</a></h4>
<p>Lean has a number of built inn types we can use, such as numbers, strings, and Booleans.</p>
<pre><code class="language-lean">#check 1234
#check "uwece"
#check true
</code></pre>
<h2 id="predicates"><a class="header" href="#predicates">Predicates</a></h2>
<p>A <strong>predicate</strong> is a <code>Prop</code> valued function.</p>
<h4 id="example-a-predicate-on-people"><a class="header" href="#example-a-predicate-on-people">Example: A Predicate on People</a></h4>
<p>A predicate on Person is a function from Person into Prop, such as one which might specify whether the person lives in Seattle:</p>
<pre><code class="language-lean">def InSeattle (x : Person) : Prop := match x with
  | mary  | ed    =&gt; True
  | steve | jolin =&gt; False

#check InSeattle

example : InSeattle steve ∨ ¬InSeattle steve :=
  Or.inr (λ h =&gt; h)
</code></pre>
<h4 id="example-a-predicate-on-ℕ"><a class="header" href="#example-a-predicate-on-ℕ">Example: A Predicate on ℕ</a></h4>
<p>Or we might define a predicate inductively on the natural numbers.</p>
<pre><code class="language-lean">def is_zero(n : Nat) : Prop := match n with
  | Nat.zero =&gt; True
  | Nat.succ _ =&gt; False

#check is_zero

example : ¬is_zero 91 :=  -- is_zero 91 → False
  λ h =&gt; h

theorem t : is_zero 0 := True.intro

theorem t1 : True := True.intro
</code></pre>
<h2 id="predicates-with-multiple-arguments"><a class="header" href="#predicates-with-multiple-arguments">Predicates with Multiple Arguments</a></h2>
<p>We may define predicates to take any number or arguments, including no arguments at all.</p>
<pre><code class="language-lean">-- No argument predicates are just normal propositions
variable (P : Prop)
#check P

-- A one-argument predicate
variable (InWashington : Person → Prop)
#check InWashington steve

-- A two-argument predicate
variable (Age : Person → Nat → Prop)
#check Age jolin 27
</code></pre>
<h3 id="relations"><a class="header" href="#relations">Relations</a></h3>
<p>A two-argument predicate is called a relation.</p>
<p>Example: We might define a predicate on pairs of people such as</p>
<pre><code class="language-lean">def on_right (p q : Person) : Prop := match p with
  | mary =&gt; q = steve
  | steve =&gt; q = ed
  | ed =&gt; q = jolin
  | jolin =&gt; q = mary
</code></pre>
<p>We can define other predicates in terms of existing predicates.</p>
<pre><code class="language-lean">def next_to (p q : Person) := on_right p q ∨ on_right q p

example : next_to mary steve :=
  Or.inl (Eq.refl steve)
</code></pre>
<h4 id="greater-than-is-a-relation"><a class="header" href="#greater-than-is-a-relation">Greater Than is a Relation</a></h4>
<p>Relations are usually represented with infix notation, but they are still just predicates. For example, in Lean, the greater-than relation on natural numbers is:</p>
<pre><code class="language-lean">#check @GT.gt Nat
#eval GT.gt 2 3
</code></pre>
<p>This doesn't look very nice, so Lean defines notation:</p>
<p>infix:50 " &gt; "  =&gt; GT.gt</p>
<p>and we can write:</p>
<pre><code class="language-lean">#eval 2 &gt; 3
</code></pre>
<p>Similarly, &gt;=, &lt;, &lt;=, != are all relations available in Lean.</p>
<h2 id="universal-quantification"><a class="header" href="#universal-quantification">Universal Quantification</a></h2>
<p>In FOL, we use the symbol ∀ to denote universal quantification. You can think of univeral quantifiaction like a potentially infinte AND:</p>
<pre><code>∀ x P(x)   ≡    P(x₁) ∧ P(x₂) ∧ P(x₃) ∧ ...
</code></pre>
<p>Example: Here's how you say "All people who live in Seattle also live in Washington":</p>
<pre><code>∀ x : Person , InSeattle(x) → InWashington(x)
</code></pre>
<p>Example: In Lean, let's say we wanted to prove that every person either lives in Seattle or does not live in Seattle. A proof of this fact has the form of a function that takes an arbtrary person x and returns a proof that that person either lives in Seattle or does not. Thus, we can say:</p>
<pre><code class="language-lean">example : ∀ (x : Person) , (InSeattle x) ∨ ¬(InSeattle x) :=
  λ x =&gt; match x with
  | steve =&gt; Or.inr (λ h =&gt; h)
  | mary =&gt; sorry
  | ed =&gt; sorry
  | jolin =&gt; sorry
</code></pre>
<p>∀ is just syntactic sugar for polymorphism. The above FOL statement can be equally well written as:</p>
<pre><code class="language-lean">#check (x : Person) → (InSeattle x) ∨ ¬(InSeattle x)
</code></pre>
<p>Which highlights why we can just use a lambda to dispatch a forall.</p>
<h2 id="forall-introduction-and-elimination"><a class="header" href="#forall-introduction-and-elimination">Forall Introduction and Elimination</a></h2>
<p>The universal quantifer has the introduction rule:</p>
<pre><code>                   Γ ⊢ P
  ∀-intro ————————————————————————
               Γ ⊢ ∀ x : α, P
</code></pre>
<p>Where x is not in the free variables of <code>Γ</code>. The rule states that if we can prove <code>P</code> in context <code>Γ</code> assuming <code>x</code> not mentioned elsewhere in <code>Γ</code>, then we can prove <code>∀ x : α, P</code>.</p>
<p>We also have the elimination rule:</p>
<pre><code>             Γ ⊢ ∀ x , P x
  ∃-elim ————————————————————————
                  P t
</code></pre>
<p>where <code>t</code> is any term. This rule states that if we know <code>P x</code> holds for every <code>x</code>, then it must hold for any particular <code>t</code>.</p>
<h3 id="proving-statements-with-"><a class="header" href="#proving-statements-with-">Proving Statements with ∀</a></h3>
<p>The Curry-Howard Isomorphism works for universal quantification too. We could do as we did with proposotional logic and rewrite the FOL rules as type inference. However, here we just say what it means in Lean (which amounts to the same thing).</p>
<ul>
<li>
<p><strong>∀-intro</strong>: To prove <code>∀ x , P x</code> we construction a function that takes any <code>x</code> and returns proof of <code>P x</code>. This is an extension of the λ-abstraction rule.</p>
</li>
<li>
<p><strong>∀-elim</strong>: Given a proof <code>h</code> of <code>∀ x , P x</code> (which we recall is a λ-abstractionn) and a particular <code>y</code> of type <code>α</code>, we can prove <code>P y</code> by simply applying <code>h</code> to <code>y</code>. This is an extension of the λ-application rule.</p>
</li>
</ul>
<p>For example, here is a proof that uses both of these rules:</p>
<pre><code class="language-lean">variable (α : Type) (P Q : α → Prop)

example : (∀ x : α, P x ∧ Q x) → ∀ y : α, P y :=
  λ h q =&gt; (h q).left
</code></pre>
<h2 id="exists"><a class="header" href="#exists">Exists</a></h2>
<p>The <code>∃</code> quantifer is like an OR over a lot of propositions:</p>
<pre><code>∃ x , P(x)  ≡   P(x₁) ∨ P(x₂) ∨ ....
</code></pre>
<p>and it has similar introduction and elimination rules:</p>
<pre><code>             Γ ⊢ φ[x:=t]                Γ ⊢ ∃ x , φ     Γ, φ ⊢ ψ
  ∃-intro: ———————————————     ∃-elim: ———————————————————————————
             Γ ⊢ ∃ x, φ                        Γ ⊢ ψ
</code></pre>
<p>Constructively, the first rule says that if we have a proof of <code>φ</code> with <code>x</code> some term <code>t</code> substituted in for <code>x</code>, then we have a proof of <code>∃ x, φ</code>.</p>
<p>The second says that if we have a proof of <code>∃ x, φ</code> and also a proof of <code>ψ</code> assuming <code>φ</code>, then we have a proof of ψ.</p>
<h3 id="leans-implementation-of-exists"><a class="header" href="#leans-implementation-of-exists">Lean's Implementation of Exists</a></h3>
<p>In FOL, ∃ is usally just an abbreviation for as <code>¬∀¬</code>. However, from a constructive point of view:</p>
<blockquote>
<p>knowing that it is not the case that every <code>x</code> satisfies<code>¬p</code> is not the same as having a particular <code>x</code> that satisfies p. (Lean manual)</p>
</blockquote>
<p>So in Lean, <code>∃</code> is defined inductively and constructively:</p>
<pre><code class="language-lean">namespace temp

inductive Exists {α : Type} (p : α → Prop) : Prop where
  | intro (x : α) (h : p x) : Exists p

end temp
</code></pre>
<p>All we need to introduce an existentially quantified statement with predicate <code>P</code> is an element and a proof that <code>P</code> holds for that element.</p>
<p>An example use of the introduction rule is the following. Note the assumption that <code>α has at least one element q</code> is necessary.</p>
<pre><code class="language-lean">example (q : α) : (∀ x , P x) → (∃ x , P x) :=
  λ hp =&gt; Exists.intro q (hp q)
</code></pre>
<h3 id="exists-elimination"><a class="header" href="#exists-elimination">Exists Elimination</a></h3>
<p>The ∃-elim rule is defined in Lean as follows:</p>
<pre><code class="language-lean">namespace temp

theorem Exists.elim {α : Type} {P : α → Prop} {b : Prop}
   (h₁ : Exists (λ x =&gt; P x)) (h₂ : ∀ (a : α), P a → b) : b :=
  match h₁ with
  | intro a h =&gt; h₂ a h

end temp
</code></pre>
<p>In this rule</p>
<p>b is an arbitrary proposition
h₁ is a proof of ∃ x , p x
h₂ is a proof that ∀ a , p a → b</p>
<p>which allow us to conclude b</p>
<h3 id="exists-elimination-example"><a class="header" href="#exists-elimination-example">Exists Elimination Example</a></h3>
<p>For example, in</p>
<pre><code class="language-lean">example (h₁ : ∃ x, P x ∧ Q x) : ∃ x, Q x ∧ P x :=
  Exists.elim h₁
  (λ c h =&gt; Exists.intro c (And.intro h.right h.left))
</code></pre>
<h2 id="example-proofs"><a class="header" href="#example-proofs">Example Proofs</a></h2>
<pre><code class="language-lean">variable (p: Type → Prop)
variable (r : Prop)

example : (∃ x, p x ∧ r) ↔ (∃ x, p x) ∧ r :=
  Iff.intro
  (λ h =&gt; Exists.elim h (λ c h =&gt; And.intro (Exists.intro c h.left) h.right))
  (λ h =&gt; Exists.elim h.left (λ c h1 =&gt; Exists.intro c (And.intro h1 h.right)))

example : (¬ ∃ x, p x) ↔ (∀ x, ¬ p x) :=
  Iff.intro
  (λ h x hp =&gt; h (Exists.intro x hp))
  (λ h he =&gt; Exists.elim he (λ y hy =&gt; h y hy))

example : ∀ (x : Person) , (InSeattle x) ∨ ¬(InSeattle x) :=
  λ x =&gt; match x with
    | mary  | ed    =&gt; Or.inl trivial
    | steve | jolin =&gt; Or.inr (λ h =&gt; False.elim h)

example : (∀ x : α, P x ∧ Q x) → ∀ y : α, P y :=
  λ h : ∀ x : α, P x ∧ Q x =&gt;
  λ y : α =&gt;
  (h y).left

example (q : α) : (∀ x , P x) → (∃ x , P x) :=
  λ h =&gt; Exists.intro q (h q)

example (h₁ : ∃ x, P x ∧ Q x) : ∃ x, Q x ∧ P x :=
  have h₂ := λ w : α =&gt;                                            -- proof of ∀
             λ hpq : P w ∧ Q w  =&gt;                                 -- proof of →
             (Exists.intro w (And.intro hpq.right hpq.left))
  Exists.elim h₁ h₂
</code></pre>
<h2 id="exercises-3"><a class="header" href="#exercises-3">Exercises</a></h2>
<p><span></span></p>
<ol>
<li>Prove the following FOL examples using introduction, elimination, etc using either direct proofs or tactics. Do not use the built in theorems from the standard library that match these, that's too easy.</li>
</ol>
<pre><code class="language-lean">variable (p q : Type → Prop)
variable (r : Prop)

example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) :=
  sorry

example : (∀ x, p x → r) ↔ (∃ x, p x) → r :=
  sorry
</code></pre>
<p><span></span> 2) Consider the following definition of the sum of the first n squares.</p>
<pre><code class="language-lean">def S (n : Nat) : Nat := match n with
  | Nat.zero =&gt; 0
  | Nat.succ x =&gt; n*n + S x
</code></pre>
<p>Show the following result using induction.</p>
<pre><code class="language-lean">example (n : Nat) : 6 * (S n) = (n * (n+1)) * (2*n+1) :=
  sorry
</code></pre>
<p><span></span> 3) Given the definitions of Person, on_right, and next_to:</p>
<pre><code class="language-lean">inductive Person where | mary | steve | ed | jolin
open Person

def on_right (p : Person) := match p with
  | mary =&gt; steve
  | steve =&gt; ed
  | ed =&gt; jolin
  | jolin =&gt; mary

def next_to (p q : Person) := on_right p = q ∨ on_right q = p
</code></pre>
<p>Prove the following examples:</p>
<pre><code class="language-lean">example : ∀ p , ∀ q , on_right p = q → next_to p q :=
  sorry

example : ∀ p : Person, ∃ q : Person, next_to p q :=
  sorry

example : ∀ p : Person, ∃ q : Person, ¬next_to p q :=
  sorry
</code></pre>
<p><span></span> 4) Besides ∀ and ∃, there are other quantifiers we can define. For example, the "Exists Exactly One" quantifer allows you to state that there is only one of something. We usually written ∃! as in</p>
<pre><code class="language-hs">    ∃! x, P x
</code></pre>
<p>which states there is exactly one <code>x</code> such that <code>P x</code> is true.</p>
<p>We can define this quantifer inductively, just as we did for Exists:</p>
<pre><code class="language-lean">inductive Exists1 {α : Type} (p : α → Prop) : Prop where
  | intro (x : α) (h : p x ∧ ∀ y : α, p y → x = y) : Exists1 p
</code></pre>
<p>However, it is a pain to define the notation E!. So we will just have to write</p>
<pre><code class="language-hs">    Exists1 (λ x =&gt; P x)
</code></pre>
<p>instead of the above.</p>
<p>a) <span></span> Prove the elimination theorem for Exists1</p>
<pre><code class="language-lean">theorem Exists1.elim {α : Type} {P : α → Prop} {b : Prop}
   (h₁ : Exists1 (λ x =&gt; P x)) (h₂ : ∀ (a : α), P a → b) : b := sorry
</code></pre>
<p><span></span> b) Prove the following examples:</p>
<pre><code class="language-lean">example : ∀ x, Exists1 (λ y : Person =&gt; x ≠ y ∧ ¬next_to y x ) :=  by
  sorry

example (α : Type) (P : α → Prop) : Exists1 ( λ x =&gt; P x ) → ¬ ∀ x, ¬ P x  := sorry

example : Exists1 (λ x =&gt; x=0) := sorry

example : ¬Exists1 (λ x =&gt; x ≠ 0) := sorry
</code></pre>
<div style='height=50px'>&nbsp;</div><hr>
Copyright © 2025 Eric Klavins
<div style="break-before: page; page-break-before: always;"></div><div style='display:none'>
--  Copyright (C) 2025  Eric Klavins
--
--  This program is free software: you can redistribute it and/or modify
--  it under the terms of the GNU General Public License as published by
--  the Free Software Foundation, either version 3 of the License, or
--  (at your option) any later version.   
</div>
<p><span style='color: orange'><em><strong>UNDER CONSTRUCTION</strong></em></span><br>
<span style='color: lightgray; font-size: 10pt'><a href='https://github.com/klavins/LeanBook/blob/main/main/../LeanBook/Chapters/Tactics.lean'>Code</a> for this chapter</span></p>
<h1 id="tactics"><a class="header" href="#tactics">Tactics</a></h1>
<p>Tactic mode is entered in a proof using the keyword <code>by</code></p>
<pre><code class="language-lean">variable (p : Type → Prop)

example : (¬ ∃ x, p x) ↔ (∀ x, ¬ p x) := by
  sorry
</code></pre>
<h2 id="the-intro-tactic"><a class="header" href="#the-intro-tactic">The <code>intro</code> Tactic</a></h2>
<p>Introducion applies to implications and forall statements, introducing either a new hypothesis or a new object. It takes the place of <code>λ h₁ h₂ ... =&gt; ...</code></p>
<p>Note also that by using <code>.</code> and indentation, you can visually break up your proof to it is more readable.</p>
<pre><code class="language-lean">example : (¬ ∃ x, p x) ↔ (∀ x, ¬ p x) := by
  apply Iff.intro
  . intro hnep x
    sorry
  . intro hanp
    sorry
</code></pre>
<h2 id="the-apply-and-exact-tactics"><a class="header" href="#the-apply-and-exact-tactics">The <code>apply</code> and <code>exact</code> Tactics</a></h2>
<p>The <code>apply</code> tactic applies a function, forall statement, or another theorem. It looks for arguments that match its type signature in the context and automatically uses them if possible.</p>
<pre><code class="language-lean">example : (¬ ∃ x, p x) ↔ (∀ x, ¬ p x) := by
  apply Iff.intro
  . intro h x hp
    exact h (Exists.intro x hp)
  . intro h hepx
    apply Exists.elim hepx
    intro x hpa
    exact (h x) hpa

example (p : Nat → Prop) (h : ∀ (x : Nat) , p x) : p 14 := by
  apply h

theorem my_thm (q : Prop) : q → q := id

example (q : Nat → Prop) : (∀ x, q x) → ∀ x, q x := by
  apply my_thm
</code></pre>
<p><code>exact</code> is a variant of apply that requires you to fill in the arguments you are using. It essentially pops you out of tactic mode. It is used at the end of proofs to make things more clear and robust to changes in how other tactics in the proof are applied.</p>
<pre><code class="language-lean">example (p : Nat → Prop) (h : ∀ (x : Nat) , p x) : p 14 := by
  exact h 14
</code></pre>
<h2 id="the-assumption-tactic"><a class="header" href="#the-assumption-tactic">The <code>assumption</code> Tactic</a></h2>
<p>This tactic looks through the context to find an assumption that applies, and applies it. It is like apply but where you don't even say what to apply.</p>
<pre><code class="language-lean">example (c : Type) (h : p c) : ∃ x, p x := by
  apply Exists.intro c
  assumption
</code></pre>
<h2 id="structures"><a class="header" href="#structures">Structures</a></h2>
<p>Structures in Lean are a way to package data. They are a kind of inductive type, but presented differently. For example,</p>
<pre><code class="language-lean">structure Point where
  x : Int
  y : Int
</code></pre>
<p>You can make new points in a variety of ways</p>
<pre><code class="language-lean">def p₁ := Point.mk 1 2
def p₂ : Point := { x := 1, y := 2 }
def p₃ : Point := ⟨ 1,2 ⟩
</code></pre>
<h2 id="packaging-and-exists"><a class="header" href="#packaging-and-exists">Packaging and Exists</a></h2>
<p>In Lean, And is a structure (not a simple inductive type, like I originally described).</p>
<pre><code class="language-lean">#print And

example (p : Prop): p → (p ∧ p) :=
  λ hp =&gt; ⟨ hp, hp ⟩
</code></pre>
<p>This notation also works with inductive types though, as with Exists.</p>
<pre><code class="language-lean">#print Exists

example (p : Type → Prop) (c : Type) : (∀ x, p x) → ∃ x, p x :=
  λ h =&gt; ⟨ c, h c ⟩

example : ∃ (p : Point) , p.x = 0 :=  by
  exact ⟨ ⟨ 0, 0 ⟩, rfl ⟩
</code></pre>
<h3 id="tactics-produce-low-level-proofs"><a class="header" href="#tactics-produce-low-level-proofs">Tactics Produce Low Level Proofs</a></h3>
<pre><code class="language-lean">theorem t (p : Type → Prop) (c : Type) : (∀ x, p x) → ∃ x, p x := by
  intro h
  exact ⟨ c, h c ⟩

#print t
</code></pre>
<h2 id="pattern-matching"><a class="header" href="#pattern-matching">Pattern Matching</a></h2>
<p>You can match constructors with intro to more easily break up expressions.</p>
<pre><code class="language-lean">example (p q : Prop) : p ∧ q → q := by
  intro ⟨ _, hq ⟩
  exact hq

example : (∃ x , ¬p x) → ¬ ∀ x, p x := by
  intro ⟨ x, hnp ⟩ hnap
  exact hnp (hnap x)

example (P Q : Type → Prop): (∃ x, P x ∧ Q x) → ∃ x, Q x ∧ P x := by
  intro ⟨ x, ⟨ hp, hq ⟩ ⟩
  exact ⟨ x, ⟨ hq, hp ⟩ ⟩
</code></pre>
<h2 id="getting-help-with-apply"><a class="header" href="#getting-help-with-apply">Getting Help with Apply?</a></h2>
<p>You can ask Lean to try to find someting to apply with <code>apply?</code></p>
<pre><code class="language-lean">example : (∃ x , ¬p x) → ¬ ∀ x, p x := by
  intro ⟨ x, hnp ⟩ hnap
  apply?
</code></pre>
<p>It doesn't always work though.</p>
<h2 id="fol-examples-revisited"><a class="header" href="#fol-examples-revisited">FOL Examples Revisited</a></h2>
<p>Now that we can use tactics, our First Order Logic Proofs can be made to look a little cleaner, although one might argue the use of angled brackets is harder to read.</p>
<pre><code class="language-lean">variable (p: Type → Prop)
variable (r : Prop)

theorem asd : (¬ ∃ x, p x) ↔ (∀ x, ¬ p x) := by
  apply Iff.intro
  . intro h x hp
    exact h (Exists.intro x hp)
  . intro hp ⟨ x, hnp ⟩
    exact hp x hnp

example : (∃ x, p x ∧ r) ↔ (∃ x, p x) ∧ r := by
  apply Iff.intro
  . intro ⟨ x, ⟨ hx, hr ⟩ ⟩
    exact ⟨ ⟨ x, hx ⟩ , hr ⟩
  . intro ⟨ ⟨ x, hx ⟩ , hr ⟩
    exact ⟨ x, ⟨ hx, hr ⟩ ⟩

example : (¬ ∃ x, p x) ↔ (∀ x, ¬ p x) := by
  apply Iff.intro
  . intro h x hp
    exact h ⟨ x, hp ⟩
  . intro h ⟨ x, hp ⟩
    exact h x hp
</code></pre>
<h2 id="the-have-and-let-tactics"><a class="header" href="#the-have-and-let-tactics">The <code>have</code> and <code>let</code> Tactics</a></h2>
<p>You can use <code>have</code> to record intermediate results</p>
<pre><code class="language-lean">example (p q : Prop) : p ∧ q → p ∨ q := by
  intro ⟨ h1, h2 ⟩
  have hp : p := h1
  exact Or.inl hp
</code></pre>
<p>If you need an intermediate value, you should use <code>let</code>.</p>
<pre><code class="language-lean">example : ∃ n , n &gt; 0 := by
  let m := 1
  exact ⟨ m, Nat.one_pos ⟩
</code></pre>
<h2 id="cases"><a class="header" href="#cases">Cases</a></h2>
<p>The cases tactic wraps around Or.elim to make proofs easier to read.</p>
<pre><code class="language-lean">example (p q : Prop) : (p ∨ q) → q ∨ p  := by
  intro h
  cases h with
  | inl hp =&gt; exact Or.inr hp
  | inr hq =&gt; exact Or.symm (Or.inr hq)

-- Cases doesn't always buy you much. You can just apply Or.elim.
example (p q : Prop) : (p ∨ q) → q ∨ p  := by
  intro h
  apply Or.elim h
  . intro hp
    exact Or.symm h
  . intro hq
    exact Or.symm h
</code></pre>
<h2 id="cases-works-with-any-inductive-ttype"><a class="header" href="#cases-works-with-any-inductive-ttype">Cases Works With any Inductive Ttype</a></h2>
<p>Here's are some somewhat longwinded ways to prove some simple results</p>
<pre><code class="language-lean">variable (P Q : Type → Prop)

example : (∃ x, P x ∧ Q x) → ∃ x, Q x ∧ P x := by
  intro h
  cases h with
  | intro x h =&gt; exact ⟨ x, And.symm h ⟩

example (p q : Prop) : (p ∧ q) → (p ∨ q) :=  by
  intro h
  cases h with
  | intro hp hq =&gt; exact Or.inl hp
</code></pre>
<h2 id="the-by_cases-tactic"><a class="header" href="#the-by_cases-tactic">The <code>by_cases</code> Tactic</a></h2>
<p>The cases tactic is not to be confused with the <code>by_cases</code> tactic, which uses <code>classical reasoning</code>.</p>
<pre><code class="language-lean">example (p : Prop): p ∨ ¬p := by
  by_cases h : p
  . exact Classical.em p -- assuming h : p
  . exact Classical.em p -- assuming h : ¬p
</code></pre>
<h1 id="the-induction-tactic"><a class="header" href="#the-induction-tactic">The <code>induction</code> Tactic</a></h1>
<p>Proof by induction works for all inductive types. It is similar to using cases, but it adds an <code>inductive hypothesis</code> where needed.</p>
<p>As an example, consider the natural numbers and suppose P : Nat → Prop is a property. To prove P with induction, you do :</p>
<ul>
<li><strong>BASE CASE</strong>: P(0)</li>
<li><strong>INDUCTIVE STEP</strong>: ∀ n, P(n) → P(n+1)</li>
</ul>
<pre><code class="language-lean">def E (n : Nat) : Prop := match n with
  | Nat.zero =&gt; True
  | Nat.succ x =&gt; ¬E x

example : ∀ n : Nat, E n ∨ E n.succ := by
  intro n
  induction n with
  | zero =&gt; exact Or.inl trivial
  | succ k ih =&gt;
    apply Or.elim ih
    . intro h1
      exact Or.inr (by exact fun a ↦ a h1)
    . intro h3
      exact Or.inl h3
</code></pre>
<h2 id="tactic-documentation"><a class="header" href="#tactic-documentation">Tactic Documentation</a></h2>
<p>There are a lot of tactics:</p>
<p>https://github.com/haruhisa-enomoto/mathlib4-all-tactics/blob/main/all-tactics.md</p>
<div style='height=50px'>&nbsp;</div><hr>
Copyright © 2025 Eric Klavins
<div style="break-before: page; page-break-before: always;"></div><div style='display:none'>
--  Copyright (C) 2025  Eric Klavins
--
--  This program is free software: you can redistribute it and/or modify
--  it under the terms of the GNU General Public License as published by
--  the Free Software Foundation, either version 3 of the License, or
--  (at your option) any later version.   
</div>
<p><span style='color: orange'><em><strong>UNDER CONSTRUCTION</strong></em></span><br>
<span style='color: lightgray; font-size: 10pt'><a href='https://github.com/klavins/LeanBook/blob/main/main/../LeanBook/Chapters/Equality.lean'>Code</a> for this chapter</span></p>
<h1 id="objects-functions-and-equality"><a class="header" href="#objects-functions-and-equality">Objects, Functions and Equality</a></h1>
<p>In this chapter we extend the first order logic discussed in the last chapter to deal with functions of objects in our universe. On one of the critical components is a notion of equality between objects. Astonishingly, Lean's equality is not a built in type, but is defined in the standard library. Once we have equality, we can start working with statements about functions and their relationships in earnest.</p>
<h2 id="equality-is-a-binary-relation-defined-inductively"><a class="header" href="#equality-is-a-binary-relation-defined-inductively">Equality is a Binary Relation Defined Inductively</a></h2>
<pre><code class="language-lean">universe u

inductive MyEq {α : Sort u} : α → α → Prop where
  | refl a : MyEq a a

#check MyEq 1 2

example : MyEq 1 1 :=
  MyEq.refl 1
</code></pre>
<p>We can define some notation</p>
<pre><code class="language-lean">infix:50 " ~ "  =&gt; MyEq

#check 1 ~ 1
</code></pre>
<h3 id="refl-is-powerful"><a class="header" href="#refl-is-powerful">Refl is Powerful</a></h3>
<p>In Lean, terms that are beta-reducable to each other are considered definitionally equal. You can show a lot of equalities automatically</p>
<pre><code class="language-lean">example : 1 ~ 1 :=
  MyEq.refl 1

example : 2 ~ (1+1) := by
  apply MyEq.refl

example : 9 ~ (3*(2+1)) := by
  apply MyEq.refl
</code></pre>
<h3 id="substitution"><a class="header" href="#substitution">Substitution</a></h3>
<p>Substition is the second most critical property of the equality. It allows us to conclude, for example, that if x = y then p x is equal to p y.</p>
<pre><code class="language-lean">theorem MyEq.subst {α : Sort u} {P : α → Prop} {a b : α}
                   (h₁ : a ~ b) (h₂ : P a) : P b := by
  cases h₁ with
  | refl =&gt; exact h₂
</code></pre>
<p>You can use this theorem to show the standard properties we know and love about equality.</p>
<pre><code class="language-lean">theorem my_symmetry (a b : Type): a ~ b → b ~ a := by
  intro h
  apply MyEq.subst h
  exact MyEq.refl a

theorem my_transitivity (a b c : Type) : a ~ b → b ~ c → a ~ c := by
  intro hab hbc
  exact MyEq.subst hbc hab

theorem my_congr_arg (a b : Type) (f : Type → Type) : a ~ b → f a ~ f b := by
  intro hab
  apply MyEq.subst hab
  exact MyEq.refl (f a)
</code></pre>
<h2 id="leans-equality"><a class="header" href="#leans-equality">Lean's Equality</a></h2>
<p>Lean's equality relation is called <code>Eq</code> and its notation is <code>=</code>, as we have been using. Lean also defines <code>rfl</code> to be <code>Eq.refl _</code></p>
<pre><code class="language-lean">#print rfl
example : 9 = 3*(2+1) := Eq.refl 9
example : 9 = 3*(2+1) := rfl
</code></pre>
<p>Lean provides a long list of theorems about equality, such as</p>
<pre><code class="language-lean">#check Eq.symm
#check Eq.subst
#check Eq.substr
#check Eq.trans
#check Eq.to_iff
#check Eq.mp
#check Eq.mpr

#check congrArg
#check congrFun
#check congr
</code></pre>
<h3 id="tactics-for-equality"><a class="header" href="#tactics-for-equality">Tactics for Equality</a></h3>
<p>rw[h]: Rewrites the current goal using the equality h.</p>
<pre><code class="language-lean">theorem t1 (a b : Nat) : a = b → a + 1 = b + 1 := by
  intro hab
  rw[hab]

#print t1
</code></pre>
<p>To use an equality backwards, use ← (written \left)</p>
<pre><code class="language-lean">theorem t2 (a b c : Nat) : a = b ∧ a = c → b + 1 = c + 1 := by
  intro ⟨ h1, h2 ⟩
  rw[←h1, ←h2]

#print t2
</code></pre>
<p>You can also rewrite assumptions using <code>at</code>.</p>
<pre><code class="language-lean">example (a b c : Nat) : a = b ∧ a = c → b + 1 = c + 1 := by
  intro ⟨ h1, h2 ⟩
  rw[h1] at h2
  rw[h2]
</code></pre>
<h2 id="the-simplifier"><a class="header" href="#the-simplifier">The Simplifier</a></h2>
<p>The simplifier uses equations and lemmas to simplify expressions</p>
<pre><code class="language-lean">theorem t3 (a b : Nat) : a = b → a + 1 = b + 1 := by
  simp

#print t3
</code></pre>
<p>Sometimes you have to tell the simplifer what equations to use.</p>
<pre><code class="language-lean">theorem t4 (a b c d e : Nat)
 (h1 : a = b)
 (h2 : b = c + 1)
 (h3 : c = d)
 (h4 : e = 1 + d)
 : a = e := by
   simp only[h1,h2,h3,h4,Nat.add_comm]


#check Nat.add_comm

#print t4
</code></pre>
<h2 id="the-linarith-tactic"><a class="header" href="#the-linarith-tactic">The <code>linarith</code> Tactic</a></h2>
<p>By importing Mathlib.Tactic.Linarith (see top of this file), you get an even more powerful simplifier.</p>
<pre><code class="language-lean">example (a b c d e : Nat)
 (h1 : a = b)
 (h2 : b = c + 1)
 (h3 : c = d)
 (h4 : e = 1 + d)
 : a = e := by linarith

example (x y z : ℚ)
 (h1 : 2*x - y + 3*z = 9)
 (h2 : x - 3*y - 2*z = 0)
 (h3 : 3*x + 2*y -z = -1)
 : x = 1 ∧ y = -1 ∧ z = 2 := by
 apply And.intro
 . linarith
 . apply And.intro
   . linarith
   . linarith
</code></pre>
<h3 id="example--induction-on-nat"><a class="header" href="#example--induction-on-nat">Example : Induction on Nat</a></h3>
<p>As an example the brings many of these ideas together, consider the sum of the first <code>n</code> natural numbers, which is <code>n(n+1)/2</code>. A proof by induction would be:</p>
<ul>
<li><strong>BASE CASE</strong>: <code>0 = 0*1/2</code></li>
<li><strong>NDUCTIVE STEP</strong>: <code>∀ k, Sum k = k(k+1)/2 → Sum (k+1) = (k+1)(k+2)/2</code></li>
</ul>
<p>We can do this in lean with the <code>induction</code> tactic.</p>
<pre><code class="language-lean">def S (n : Nat) : Nat := match n with
  | Nat.zero =&gt; 0
  | Nat.succ x =&gt; n + S x

#eval S 3

example : ∀ n, 2 * S n = n*(n+1) := by
  intro n
  induction n with
  | zero =&gt; simp[S]
  | succ k ih =&gt;
    simp[S,ih]
    linarith
</code></pre>
<h2 id="inequality"><a class="header" href="#inequality">Inequality</a></h2>
<p>Every inductive type comes with a theorem called noConfusion that states that different constructors give different objects.</p>
<pre><code class="language-lean">inductive Person where | mary | steve | ed | jolin
open Person

example : mary ≠ steve := by
  intro h
  exact noConfusion h

inductive MyNat where
  | zero : MyNat
  | succ : MyNat → MyNat

example : MyNat.zero ≠ MyNat.zero.succ := by
  intro h
  exact MyNat.noConfusion h
</code></pre>
<p>Continuing the above example, suppose we want to specify who is on who's right side.</p>
<pre><code class="language-lean">def on_right (p : Person) := match p with
  | mary =&gt; steve
  | steve =&gt; ed
  | ed =&gt; jolin
  | jolin =&gt; mary

def next_to (p q : Person) := on_right p = q ∨ on_right q = p

example : ¬next_to mary ed := by
  intro h
  cases h with
  | inl hme =&gt; exact noConfusion hme
  | inr hem =&gt; exact noConfusion hem

example : ∀ p , p ≠ on_right p := by
  sorry
</code></pre>
<p>Note: The <code>trivial</code> tactic actually figures out when to apply noConfusion</p>
<pre><code class="language-lean">theorem t10 : ed ≠ steve := by
  intro h
  trivial

#print t10

#help tactic trivial
</code></pre>
<div style='height=50px'>&nbsp;</div><hr>
Copyright © 2025 Eric Klavins
<div style="break-before: page; page-break-before: always;"></div><div style='display:none'>
--  Copyright (C) 2025  Eric Klavins
--
--  This program is free software: you can redistribute it and/or modify
--  it under the terms of the GNU General Public License as published by
--  the Free Software Foundation, either version 3 of the License, or
--  (at your option) any later version.   
</div>
<p><span style='color: orange'><em><strong>UNDER CONSTRUCTION</strong></em></span><br>
<span style='color: lightgray; font-size: 10pt'><a href='https://github.com/klavins/LeanBook/blob/main/main/../LeanBook/Chapters/Relations.lean'>Code</a> for this chapter</span></p>
<h1 id="relations-1"><a class="header" href="#relations-1">Relations</a></h1>
<p>As described previously, a relation is a propositionally valued predicate of two arguments. Generally speaking, that is about all you can say about predicates. However, when we restrict our attention to predicates having specific properties, we can say much more.</p>
<p>In this chapter we will build up some of the theory behind relations and give several examples of each type of relation.</p>
<p>Note that Mathlib has many definitions involving relations. In particular, <code>Rel</code> is the general type of relations. We will not use that infrastructure in this chapter, as our goal is to build up the theory from scratch for the purposes of understanding it better, which in turn should make Mathlib more comprehensible.</p>
<h1 id="definitions"><a class="header" href="#definitions">Definitions</a></h1>
<p>First, we define a general type for relations:</p>
<pre><code class="language-lean">abbrev Relation (A : Type u) (B : Type v) := A → B → Prop
</code></pre>
<h2 id="types-of-relation"><a class="header" href="#types-of-relation">Types of Relation</a></h2>
<pre><code class="language-lean">abbrev Refl {A : Type u} (r : Relation A A) {x : A} := r x x
abbrev Symm {A : Type u} (r : Relation A A) {x y : A} := r x y → r y x
abbrev AntiSym {A : Type u} (r : Relation A A) {x y : A}:= r x y → r y x → x = y
abbrev Trans {A : Type u} (r : Relation A A) {x y z : A} := r x y → r y z → r x z
</code></pre>
<div style='height=50px'>&nbsp;</div><hr>
Copyright © 2025 Eric Klavins
<div style="break-before: page; page-break-before: always;"></div><div style='display:none'>
--  Copyright (C) 2025  Eric Klavins
--
--  This program is free software: you can redistribute it and/or modify
--  it under the terms of the GNU General Public License as published by
--  the Free Software Foundation, either version 3 of the License, or
--  (at your option) any later version.   
</div>
<p><span style='color: orange'><em><strong>UNDER CONSTRUCTION</strong></em></span><br>
<span style='color: lightgray; font-size: 10pt'><a href='https://github.com/klavins/LeanBook/blob/main/main/../LeanBook/Chapters/Naturals/Intro.lean'>Code</a> for this chapter</span></p>
<h1 id="todo"><a class="header" href="#todo">TODO</a></h1>
<div style='height=50px'>&nbsp;</div><hr>
Copyright © 2025 Eric Klavins
<div style="break-before: page; page-break-before: always;"></div><div style='display:none'>
--  Copyright (C) 2025  Eric Klavins
--
--  This program is free software: you can redistribute it and/or modify
--  it under the terms of the GNU General Public License as published by
--  the Free Software Foundation, either version 3 of the License, or
--  (at your option) any later version.   
</div>
<p><span style='color: orange'><em><strong>UNDER CONSTRUCTION</strong></em></span><br>
<span style='color: lightgray; font-size: 10pt'><a href='https://github.com/klavins/LeanBook/blob/main/main/../LeanBook/Chapters/Naturals/Definition.lean'>Code</a> for this chapter</span></p>
<h1 id="the-natural-numbers-and-hierarchies"><a class="header" href="#the-natural-numbers-and-hierarchies">The Natural Numbers and Hierarchies</a></h1>
<p>In the chapter on inductive types, we encountered the natural numbers. So to some extent, we are done defining them. But the natural numbers have many, many properties that are incredibly useful over a huge range of mathematics. In fact, defining them is the easy part. Understanding their structure is much more interesting.</p>
<p>In this chapter, we will define the natural numbers and develop some of their algebraic and ordering structure. Along the way, we show how Lean's <strong>hierarchy</strong> system works. Hierarchies are useful for proving general theorems about algebreic structures that can be reused in specific instances. For example, consider associative property: <code>(x+y)+z = x+(y+z)</code>. This property holds for natural numbers, integers, rationals, reals, matrices, polynomials, and many more objects. And it leads to many auxilliary theorems, such as <code>(w+x)+(y+z) = (w+(x+y))+z</code> and so on. Rather than proving all all these theorems for a new type, we just prove a few basic theorems, like associativity and a few others, and then do some book-keeping to connect our new type to the hige list of theorems that hold for similar objects.</p>
<h2 id="the-inductive-definition-of-the-natural-numbers"><a class="header" href="#the-inductive-definition-of-the-natural-numbers">The Inductive Definition of the Natural Numbers</a></h2>
<p>As we've seen, the Natural Numbers are defined inductively. We open the a temporary namespace, <code>Temp</code> to avoid naming conflicts with Lean's standard <code>Nat</code> type. So, in the below, every time you see <code>Nat</code>, it means <code>Temp.Nat</code>.</p>
<pre><code class="language-lean">#check Nat.succ_add

theorem succ_add_eq_add_succ' (a b : Nat) : Nat.succ a + b = a + Nat.succ b := by
  apply Nat.succ_add

example (j k: Nat) : j.succ + k = j + k.succ := by exact Nat.succ_add_eq_add_succ j k

#check Nat.succ_add_eq_add_succ

namespace Temp

-- Definition
inductive Nat where
  | zero : Nat
  | succ : Nat → Nat

open Nat
</code></pre>
<p>Using this definition, it is straightfoward to define addition and multiplication.</p>
<pre><code class="language-lean">def Nat.add (n m: Nat) : Nat := match m with
  | zero =&gt; n
  | succ k =&gt; succ (add n k)

-- def Nat.add (n m: Nat) : Nat := match n,m with
--   | a, Nat.zero   =&gt; a
--   | a, Nat.succ b =&gt; Nat.succ (Nat.add n m)

def Nat.mul (n m: Nat) : Nat := match n with
  | zero =&gt; zero
  | succ k =&gt; add (mul k m) m     -- (k+1)*m = k*m+m
</code></pre>
<h2 id="first-use-of-leans-classes"><a class="header" href="#first-use-of-leans-classes">First Use of Lean's Classes</a></h2>
<p>If you have a type for which things like zero, one, addition, and multiplication are defined, it would be nice to use the notation 0, 1, + and *. Although you could use Lean's <code>syntax</code> and <code>infix</code> operators to define such notation, it is better practice to <strong>instantiate</strong> the <strong>classes</strong> that group all types that have zero, one, addition and multiplication. To do this, we use the <code>instance</code> keyword and various classes, such as <code>Zero</code>, <code>One</code>, <code>Add</code> and <code>Mul</code> defined in Lean's standard library or in Mathlib.</p>
<p>Here are several examples:</p>
<pre><code class="language-lean">instance inst_zero : Zero Nat := ⟨ zero ⟩         -- Zero
instance inst_one : One Nat := ⟨ succ zero ⟩      -- One
instance inst_add : Add Nat := ⟨ add ⟩            -- Addition
instance inst_hadd : HAdd Nat Nat Nat := ⟨ add ⟩  -- Extra hints with addition
instance inst_mul : Mul Nat := ⟨ mul ⟩            -- Multiplication
</code></pre>
<p>Now we can do a few examples using the notation. Note that in these examples, we have to give Lean some hints that we are working with our <code>Temp.Nat</code> type. Otherwise it assumes numbers like <code>0</code> and <code>1</code> refer to the build in Nat type.  We do this by coercing one of the terms in our expressions, as in <code>(1:Nat)</code>.</p>
<pre><code class="language-lean">example : (1:Nat) + 0 = 1 := rfl
example : (1:Nat) * 0 = 0 := rfl
</code></pre>
<h2 id="properties-of-addition-and-multiplication"><a class="header" href="#properties-of-addition-and-multiplication">Properties of Addition and Multiplication</a></h2>
<p>With this notation, we can cleanly express some of the basic properties of the natural numbers and start working on proofs. These theorems may seem very basic, but together they form the basis of automated proof checking with the natural numbers, connecting results about, for example, cryptography, with the type-theoretic foundations of mathematics.</p>
<p>Most of these theorems can be found in Lean's standard library. But it is interesting to reproduce them here to understand how the theory is constructed.</p>
<pre><code class="language-lean">#check AddSemiconjBy.eq
#check congrArg

theorem succ_add (n m : Nat) : (succ n) + m = succ (n + m) := by
  induction m with
  | zero =&gt; rfl
  | succ k ih =&gt; apply congrArg succ ih

theorem succ_add_eq_add_succ (a b : Nat) : succ a + b = a + succ b := by
  apply succ_add

theorem add_zero_zero_add {x: Nat} : 0+x=x+0 := by
  induction x with
    | zero =&gt; rfl
    | succ j ih =&gt;
      apply congrArg succ ih

theorem zero_add {x : Nat} : 0+x = x := by
  induction x with
    | zero =&gt; rfl
    | succ j ih =&gt;
      apply congrArg succ ih

theorem add_comm (x y : Nat) : x+y = y+x := by
  induction x with
  | zero =&gt; exact add_zero_zero_add
  | succ k ih =&gt;
    have : y + k.succ = (y + k).succ := rfl
    rw[this,←ih]
    have : k + y.succ = (k+y).succ := rfl
    rw[←this]
    exact succ_add_eq_add_succ k y

theorem add_zero (x : Nat) : x+0 = x := by
  rw[add_comm,zero_add]

theorem succ_add_one (x : Nat) : x.succ = x + 1 := by
  induction x with
  | zero =&gt; rfl
  | succ k ih =&gt;
    conv =&gt; lhs; rw[ih]
    rfl

theorem add_assoc (x y z : Nat) : x+y+z = (x+y)+z := sorry
</code></pre>
<h2 id="ordering-properties-of-nat"><a class="header" href="#ordering-properties-of-nat">Ordering Properties of Nat</a></h2>
<pre><code class="language-lean">def Nat.leb (x y : Nat) : Bool := match x,y with
  | zero,zero =&gt; true
  | succ _,zero =&gt; false
  | zero,succ _ =&gt; true
  | succ k, succ j =&gt; leb k j

def Nat.le (x y : Nat) : Prop := leb x y = true

instance inst_dec_le : DecidableRel le := by
  intro x y
  match x with
  | zero =&gt;
    match y with
    | zero =&gt; exact isTrue rfl
    | succ k =&gt; exact isTrue rfl
  | succ k =&gt;
    match y with
    | zero =&gt;
      unfold le
      exact isFalse Bool.false_ne_true
    | succ j  =&gt;
      unfold le
      exact (k.succ.leb j.succ).decEq true

def Nat.lt (x y: Nat) : Prop := le x y ∧ x ≠ y

instance inst_le : LE Nat  := ⟨ le ⟩

instance inst_lt : LT Nat  := ⟨ lt ⟩

#eval le (1:Nat) 0

def Nat.min (x y: Nat) : Nat := if le x y then x else y

instance inst_min : Min Nat  := ⟨ min ⟩

instance inst_max : Max Nat  := ⟨ sorry ⟩

instance inst_ord : Ord Nat  := ⟨ sorry ⟩

instance inst_preo : Preorder Nat  := ⟨ sorry, sorry, sorry ⟩

instance inst_po : PartialOrder Nat  := ⟨ sorry ⟩

instance inst_lo : LinearOrder Nat := ⟨
  sorry,
  by exact inst_dec_le,
  sorry,
  sorry,
  sorry,
  sorry,
  sorry ⟩
</code></pre>
<div style='height=50px'>&nbsp;</div><hr>
Copyright © 2025 Eric Klavins
<div style="break-before: page; page-break-before: always;"></div><div style='display:none'>
--  Copyright (C) 2025  Eric Klavins
--
--  This program is free software: you can redistribute it and/or modify
--  it under the terms of the GNU General Public License as published by
--  the Free Software Foundation, either version 3 of the License, or
--  (at your option) any later version.   
</div>
<p><span style='color: orange'><em><strong>UNDER CONSTRUCTION</strong></em></span><br>
<span style='color: lightgray; font-size: 10pt'><a href='https://github.com/klavins/LeanBook/blob/main/main/../LeanBook/Chapters/Naturals/Properties.lean'>Code</a> for this chapter</span></p>
<div style='height=50px'>&nbsp;</div><hr>
Copyright © 2025 Eric Klavins
<div style="break-before: page; page-break-before: always;"></div><div style='display:none'>
--  Copyright (C) 2025  Eric Klavins
--
--  This program is free software: you can redistribute it and/or modify
--  it under the terms of the GNU General Public License as published by
--  the Free Software Foundation, either version 3 of the License, or
--  (at your option) any later version.   
</div>
<p><span style='color: orange'><em><strong>UNDER CONSTRUCTION</strong></em></span><br>
<span style='color: lightgray; font-size: 10pt'><a href='https://github.com/klavins/LeanBook/blob/main/main/../LeanBook/Chapters/Integers/Intro.lean'>Code</a> for this chapter</span></p>
<h1 id="integers-via-quotients"><a class="header" href="#integers-via-quotients">Integers via Quotients</a></h1>
<p>Now that we have defined the natural numbers <code>Nat</code>, the next obvious step is to define the integers <code>Int</code>, which included positive _and_negative whole numbers. This can be done in several ways. For example, the Lean 4 standard library defines integers inductively saying that (a) any natural number is an integer, and (b) the negative successor of an integer is an integer.</p>
<p>Here, mainly to synergystically illustrate the use of <strong>quotients</strong>, we take a different approach, which is standard in foundational mathematics, although perhaps not as idiomatically type theoretic. We define pairs of natural numbers <code>(p,q)</code> and use the convention that if <code>p&gt;q</code> then <code>(p,q)</code> represents the positive number <code>p-q</code>. Otherwise, it represents the non-positive number <code>q-p</code>.</p>
<p>This construction allows for multiple representatives of the same number. Therefore, we define an equivalence <code>≈</code> on pairs. We would like to write <code>(p,q) ≈ (r,s)</code> if and only if <code>p-q=r-s</code>, but since we are in the process of defining the integers, we do not yet have a notion of negative numbers. Some rearrangement leads to</p>
<pre><code>(p,q) ≈ (r,s)  ↔   p+s=q+r
</code></pre>
<p>instead.</p>
<p>With this equivalence in place, we define an integer to be the equivalence class corresponding to a given difference. For example,</p>
<pre><code>-2 ≡ { (0,2), (1,3), (2,4), ... }
</code></pre>
<p>Although we could define -2 to be the <em>set</em> of such pairs, Lean has a much more powerful tool for such constructions: the quotient. Taking the quotient of the set of pairs with respect to the equivalence relation we have defined allows us to use <em>definitional equality</em> on equivalence classes of pairs. This allows us, for example, to substitute an integer for an equivalent one in an algebreic expression.</p>
<div style='height=50px'>&nbsp;</div><hr>
Copyright © 2025 Eric Klavins
<div style="break-before: page; page-break-before: always;"></div><div style='display:none'>
--  Copyright (C) 2025  Eric Klavins
--
--  This program is free software: you can redistribute it and/or modify
--  it under the terms of the GNU General Public License as published by
--  the Free Software Foundation, either version 3 of the License, or
--  (at your option) any later version.   
</div>
<p><span style='color: orange'><em><strong>UNDER CONSTRUCTION</strong></em></span><br>
<span style='color: lightgray; font-size: 10pt'><a href='https://github.com/klavins/LeanBook/blob/main/main/../LeanBook/Chapters/Integers/Definition.lean'>Code</a> for this chapter</span></p>
<h1 id="from-pairs-to-integers"><a class="header" href="#from-pairs-to-integers">From Pairs to Integers</a></h1>
<p>As usual when defining a type with the same name as something in the standard library or in Mathlib, we open a namespace to avoid naming conflicts. The <code>Int</code> type we define in this section has the fully qualified name <code>LeanBook.Int</code>, and is a totally different type than Lean's <code>Int</code> type.</p>
<pre><code class="language-lean">namespace LeanBook
</code></pre>
<h2 id="pairs-of-natural-numbers"><a class="header" href="#pairs-of-natural-numbers">Pairs of Natural Numbers</a></h2>
<p>We first define pairs of natural numbers, recording the components of the pair in a simple structure. Then we define the notion of equivalence that will form the basis of the definition of an integer.</p>
<pre><code class="language-lean">@[ext]
structure Pair where
  p : Nat
  q : Nat

def eq (x y: Pair) : Prop := x.p + y.q = x.q + y.p
</code></pre>
<p>Here are a few test cases.</p>
<pre><code class="language-lean">example : eq ⟨1,2⟩ ⟨2,3⟩ := rfl
example : eq ⟨3,2⟩ ⟨20,19⟩ := rfl
example : ¬eq ⟨3,2⟩ ⟨20,23⟩ := by intro h; simp_all[eq]
</code></pre>
<h2 id="equivalence-relations"><a class="header" href="#equivalence-relations">Equivalence Relations</a></h2>
<p>An <strong>equivalence relation</strong> <code>≈</code> is a relation that is</p>
<ul>
<li>reflexive: x ≈ x for all x</li>
<li>symmetric: x ≈ y implies y ≈ x for all x and y</li>
<li>transitive: x ≈ y and y ≈ z implies x ≈ z for all x, y and z</li>
</ul>
<p>The relation <code>eq</code> defined above is such an equivalence relation. But we have to prove it. This is pretty easy, since it is just some basic arithmetic.</p>
<pre><code class="language-lean">theorem eq_refl (u : Pair) : eq u u := by
  simp[eq]
  linarith

theorem eq_symm {v w: Pair} : eq v w → eq w v := by
  intro h
  simp_all[eq]
  linarith

theorem eq_trans {u v w: Pair} : eq u v → eq v w → eq u w := by
  intro h1 h2
  simp_all[eq]
  linarith
</code></pre>
<p>With these properties in hand, we can register an instance of <code>Equivalence</code>, a Lean 4 standard library class that stores the properties of the equivalence relation in one object, and enables us to easily use any theorems requiring our <code>eq</code> relation to have them.</p>
<pre><code class="language-lean">instance eq_equiv : Equivalence eq := ⟨ eq_refl, eq_symm, eq_trans ⟩
</code></pre>
<p>We can also register <code>eq</code> with the <code>HasEquiv</code> class, which allows us to use the `≈' notation.</p>
<pre><code class="language-lean">@[simp]
instance pre_int_has_equiv : HasEquiv Pair := ⟨ eq ⟩
</code></pre>
<p>Here is an example using the new notation.</p>
<pre><code class="language-lean">def u : Pair := ⟨ 1,2 ⟩
def v : Pair := ⟨ 12,13 ⟩
#check u ≈ v
</code></pre>
<p>Finally, we register <code>Pair</code> and <code>eq</code> as a <code>Setoid</code>, which is a set and an equivalence relation on the set. It is needed for the definition of the quotient space later.</p>
<pre><code class="language-lean">instance pre_int_setoid : Setoid Pair :=
  ⟨ eq, eq_equiv ⟩
</code></pre>
<p>This exact process should be followed whenever defining a new equivalence class in Lean.</p>
<h2 id="quotients"><a class="header" href="#quotients">Quotients</a></h2>
<p>The <strong>equivalence class</strong> of <code>x</code> is defined to be the set of all pairs <code>y</code> such that <code>x≈y</code>. The set of all equivalence classes is called the <strong>quotient space</strong>, which we can form using Lean's <code>Quotient</code>:</p>
<pre><code class="language-lean">def Int := Quotient pre_int_setoid
</code></pre>
<p>We can then construct elements of <code>Int</code> using <code>Quotient.mk</code>.</p>
<pre><code class="language-lean">def mk (w : Pair) : Int := Quotient.mk pre_int_setoid w

#check mk ⟨ 1, 2 ⟩  -- 1
#check mk ⟨ 2, 1 ⟩  -- -1
</code></pre>
<p>A key aspect of the quotient space is that equality is extended to elements of the quotient space. Thus, we can write:</p>
<pre><code class="language-lean">#check mk ⟨ 1, 2 ⟩ = mk ⟨ 2, 3 ⟩
</code></pre>
<p>instead of using <code>≈</code>. As a result, we can us all the properties of equality we have become used to with basic types, such as definitional equality and substution.</p>
<p>We may now register a few more classes. The first defines zero, the second defines one, and the third defines a coercion from natural numbers to (non-negative) integers.</p>
<pre><code class="language-lean">instance int_zero : Zero Int := ⟨ mk ⟨ 0,0 ⟩ ⟩
instance int_one : One Int := ⟨ mk ⟨ 1,0 ⟩ ⟩
instance int_of_nat {n: ℕ} :OfNat Int n := ⟨ mk ⟨ n, 0 ⟩ ⟩

#check (0:Int)
#check (1:Int)
#check (123:Int)
</code></pre>
<p>You may also encounter the notation ⟦⬝⟧ for equivalence classes. Since the notation does not know which equivalence relation you might be talking about, it is only useful in a context where the Type can be inferred.</p>
<pre><code class="language-lean">-- Does not work:
#check_failure ⟦⟨1,2⟩⟧

-- Ok:
def my_int : Int := ⟦⟨1,2⟩⟧
</code></pre>
<h2 id="using-ints-in-proofs"><a class="header" href="#using-ints-in-proofs">Using Ints in Proofs</a></h2>
<p>To prove theorems about negation we need some fundamental tools for proving properties of quotients:</p>
<ul>
<li>
<p><code>Quotient.exists_rep</code>, which says <code>∃ a, ⟦a⟧ = q</code>. This operator allows you to assert the existence of a representative of an equivalence class. Then, if you are trying to prove a result about the equivalence class, it amounts to proving it about the representative.</p>
</li>
<li>
<p><code>Quotient.sound</code>, which says <code>a ≈ b → ⟦a⟧ = ⟦b⟧</code>. Applying this operator allows you to replace a goal involving proving two equivalence classes are equal, with one showing that representatives of the respective equivalence classes are equivalent under the associated Setoid relation. In other words, we <em>unlift</em> the equality back to the underlying space.</p>
</li>
</ul>
<p>Using these two operations, we do a simple proof in which, for illustrative purposes, we write out each step. It is instructive to open this proof in VS Code and examine the proof state before and after each step.</p>
<pre><code class="language-lean">example : ∀ x : Int, x = x := by
  intro x
  obtain ⟨ ⟨ a, b ⟩, hd ⟩ := Quotient.exists_rep x
  rewrite[←hd]
  apply Quotient.sound
  simp only [pre_int_setoid,HasEquiv.Equiv,eq]
  exact Nat.add_comm a b
</code></pre>
<p>The proof can be made much simpler in this example, because definitional equality is all you need in this case.</p>
<pre><code class="language-lean">example : ∀ x : Int, x = x := by
  intro x
  rfl
</code></pre>
<p>However, the use of <code>Quotient.exists_rep</code> and <code>Quotient.sound</code> in the more complicated proofs is often needed, and the above pattern will be applicable in many situations.</p>
<div style='height=50px'>&nbsp;</div><hr>
Copyright © 2025 Eric Klavins
<div style="break-before: page; page-break-before: always;"></div><div style='display:none'>
--  Copyright (C) 2025  Eric Klavins
--
--  This program is free software: you can redistribute it and/or modify
--  it under the terms of the GNU General Public License as published by
--  the Free Software Foundation, either version 3 of the License, or
--  (at your option) any later version.   
</div>
<p><span style='color: orange'><em><strong>UNDER CONSTRUCTION</strong></em></span><br>
<span style='color: lightgray; font-size: 10pt'><a href='https://github.com/klavins/LeanBook/blob/main/main/../LeanBook/Chapters/Integers/Operators.lean'>Code</a> for this chapter</span></p>
<h1 id="lifting-operators"><a class="header" href="#lifting-operators">Lifting Operators</a></h1>
<p>In this section we show how to <em>lift</em> an operation, such as negation or addition, from <code>Pair</code> to <code>Int</code>, and more generally from any type to a quotient on that type.</p>
<h2 id="lifting-negation"><a class="header" href="#lifting-negation">Lifting Negation</a></h2>
<p>First, we define the meaning of negation for pairs, which is simply to switch the order of the pair's elements.</p>
<pre><code class="language-lean">def pre_negate (x : Pair) : Pair := ⟨ x.q, x.p ⟩
</code></pre>
<p>We would like to <strong>lift</strong> the definition of negation to our new <code>Int</code> type. This means defining negation of an entire equivalence class, which would only work if our <code>pre_negate</code> function has the same result on all elements of an equivalence class, which fortunately it does! To capture this notion we define a <em>respects</em> theorem.</p>
<pre><code class="language-lean">theorem pre_negate_respects (x y : Pair) :
  x ≈ y → mk (pre_negate x) = mk (pre_negate y) := by
  intro h
  simp_all[pre_int_setoid,eq]
  apply Quot.sound
  simp[pre_int_setoid,eq,pre_negate,h]
</code></pre>
<p>With this theorem, we may use Lean's <code>Quotient.lift</code> to define <code>negate</code> on <code>Int</code>.</p>
<pre><code class="language-lean">def pre_negate' (x : Pair) : Int := mk (pre_negate x)

def negate (x : Int) : Int := Quotient.lift pre_negate' pre_negate_respects x
</code></pre>
<p>We may register our negation function wit the <code>Neg</code> class, allowing us to use the <code>-</code> notation for it, and to use any general theorems proved in Mathlib for types with negation.</p>
<pre><code class="language-lean">instance int_negate : Neg Int := ⟨ negate ⟩
</code></pre>
<p>Now we can use negative integers.</p>
<pre><code class="language-lean">#check -mk ⟨2,1⟩
#check -(1:Int)
</code></pre>
<p>Here is a simple theorem to test whether all of this is working.</p>
<pre><code class="language-lean">theorem negate_negate { x : Int } : -(-x) = x := by
  let ⟨ u, hu ⟩ := Quotient.exists_rep x
  rw[←hu]
  apply Quot.sound
  simp[pre_int_setoid,pre_negate,eq]
  linarith
</code></pre>
<h2 id="lifing-addition"><a class="header" href="#lifing-addition">Lifing Addition</a></h2>
<p>Just as we lifted negation, we can also define and lift addition. For pairs, addition is just componentwise addition.</p>
<pre><code class="language-lean">def pre_add (x y : Pair) : Pair := ⟨ x.p + y.p, x.q + y.q ⟩
</code></pre>
<p>To do the lift, we need another respects theorey. This time, the theorem assumes multiple equivalences.</p>
<pre><code class="language-lean">theorem pre_add_respects (w x y z : Pair)
  : w ≈ y → x ≈ z → mk (pre_add w x) = mk (pre_add y z) := by
  intro h1 h2
  apply Quot.sound
  simp_all[pre_int_setoid,eq,pre_add]
  linarith
</code></pre>
<p>With this theorem we can define addition on integers.</p>
<pre><code class="language-lean">def pre_add' (x y : Pair) : Int := mk (pre_add x y)

def add (x y : Int) : Int := Quotient.lift₂ pre_add' pre_add_respects x y
</code></pre>
<p>And while we are at it, we can register addition with Mathlib's Add class so we can use <code>+</code>.</p>
<pre><code class="language-lean">instance int_add : Add Int := ⟨ add ⟩
</code></pre>
<p>Here is an example. It is remarkable to see that the entire edifice we have built can interact so easily with <code>rfl</code>.</p>
<pre><code class="language-lean">example : (1:Int) + 17 = 18 := rfl
</code></pre>
<p>A slightly more complicated example with addition and negation requires <code>Quotient.sound</code> since we have not yet lifted any theorems from <code>Pair</code> to <code>Int</code>.</p>
<pre><code class="language-lean">example : (1:Int) + (-2) = -1 := by
  apply Quotient.sound
  rfl
</code></pre>
<div style='height=50px'>&nbsp;</div><hr>
Copyright © 2025 Eric Klavins
<div style="break-before: page; page-break-before: always;"></div><div style='display:none'>
--  Copyright (C) 2025  Eric Klavins
--
--  This program is free software: you can redistribute it and/or modify
--  it under the terms of the GNU General Public License as published by
--  the Free Software Foundation, either version 3 of the License, or
--  (at your option) any later version.   
</div>
<p><span style='color: orange'><em><strong>UNDER CONSTRUCTION</strong></em></span><br>
<span style='color: lightgray; font-size: 10pt'><a href='https://github.com/klavins/LeanBook/blob/main/main/../LeanBook/Chapters/Integers/Properties.lean'>Code</a> for this chapter</span></p>
<h1 id="lifting-properties"><a class="header" href="#lifting-properties">Lifting Properties</a></h1>
<p>In this section we show how to lift theorems from a type to a quotient on that type. Continuing with the <code>Int</code> example, we lift all the properties required to show that <code>Int</code> is an additive group. Then, using Lean's hierarchies, we formally instantiate <code>Int</code> as an additive group using these theorems and show how we can then use all of Mathlib's group infrastructure on our new <code>Int</code> type.</p>
<h2 id="lifting-theorems"><a class="header" href="#lifting-theorems">Lifting Theorems</a></h2>
<p>There is no direct operator for lifting theorems, but doing so is straightforward. One typically defines a theorem on the base space and then uses it to prove the corresponding theorem on the quotient space. For example, here are several theorems defined on pairs.</p>
<pre><code class="language-lean">theorem pre_add_com {x y: Pair} : eq (pre_add x y) (pre_add y x) := by
  simp[eq,pre_add]
  linarith

theorem pre_add_assoc {x y z: Pair}
  : eq (pre_add (pre_add x y) z) (pre_add x (pre_add y z))  := by
  simp[eq,pre_add]
  linarith

theorem pre_zero_add (x : Pair) : eq (pre_add ⟨0,0⟩ x) x := by
  simp[eq,pre_add]
  linarith

theorem pre_inv_add_cancel (x : Pair) : eq (pre_add (pre_negate x) x) ⟨0,0⟩ := by
  simp[eq,pre_negate,pre_add]
  linarith
</code></pre>
<p>To lift these theorems to Int, we apply essentially the same pattern to each. We assert the existence of <code>Pairs</code> that represent each of the intgers in the target theorem. We substitute those in for the integers. We use <code>Quot.sound</code> to restate the goal in terms of pairs. Finally we use the underlying theorem. Here are several examples:</p>
<pre><code class="language-lean">theorem add_comm (x y: Int) : x+y = y+x := by
  have ⟨ u, hu ⟩ := Quotient.exists_rep x
  have ⟨ v, hv ⟩ := Quotient.exists_rep y
  rw[←hu,←hv]
  apply Quot.sound
  apply pre_add_com

theorem add_assoc (x y z: Int) : x+y+z = x+(y+z) := by
  have ⟨ u, hu ⟩ := Quotient.exists_rep x
  have ⟨ v, hv ⟩ := Quotient.exists_rep y
  have ⟨ w, hw ⟩ := Quotient.exists_rep z
  rw[←hu,←hv,←hw]
  apply Quot.sound
  apply pre_add_assoc

theorem zero_add (x : Int) : 0 + x = x := by
  have ⟨ u, hu ⟩ := Quotient.exists_rep x
  rw[←hu]
  apply Quot.sound
  apply pre_zero_add

theorem inv_add_cancel (x : Int) : -x + x = 0 := by
  have ⟨ u, hu ⟩ := Quotient.exists_rep x
  rw[←hu]
  apply Quot.sound
  apply pre_inv_add_cancel
</code></pre>
<h2 id="instantiating-the-additive-group-structure-on-int"><a class="header" href="#instantiating-the-additive-group-structure-on-int">Instantiating the Additive Group Structure on Int</a></h2>
<p>The theorems above were chosen so that we could instantiate a everything we need to show that <code>Int</code> forms an additive, commutative group.</p>
<pre><code class="language-lean">instance int_add_comm_magma : AddCommMagma Int := ⟨ add_comm ⟩

instance int_add_semi : AddSemigroup Int := ⟨ add_assoc ⟩

instance int_add_comm_semi : AddCommSemigroup Int := ⟨ add_comm ⟩

instance int_group : AddGroup Int :=
  AddGroup.ofLeftAxioms add_assoc zero_add inv_add_cancel
</code></pre>
<p>Now we get all the theorems and tactics about additive groups from Mathlib to apply to our <code>Int</code> type! For example,</p>
<pre><code class="language-lean">example (x: Int) : x-x = 0 := by
  group

example (x y : Int) : x + y - y = x := by
  exact add_sub_cancel_right x y

example (x y z : Int) : x+y+z = x+z+y := by
  calc x+y+z
  _ = x+(y+z) := by rw[add_assoc]
  _ = x+(z+y) := by rw[add_comm y z]
  _ = x+z+y   := by rw[add_assoc]
</code></pre>
<h2 id="exercises-4"><a class="header" href="#exercises-4">Exercises</a></h2>
<h2 id="references-4"><a class="header" href="#references-4">References</a></h2>
<p>The construction here is defined in a number of Algebra textbooks. For an early example, see the Nicolas Bourbaki collective's book <em>Algebra Part I</em>, 1943. The English translation of that book from 1974 has the relevant material on page 20.</p>
<div style='height=50px'>&nbsp;</div><hr>
Copyright © 2025 Eric Klavins
<div style="break-before: page; page-break-before: always;"></div><div style='display:none'>
--  Copyright (C) 2025  Eric Klavins
--
--  This program is free software: you can redistribute it and/or modify
--  it under the terms of the GNU General Public License as published by
--  the Free Software Foundation, either version 3 of the License, or
--  (at your option) any later version.   
</div>
<p><span style='color: orange'><em><strong>UNDER CONSTRUCTION</strong></em></span><br>
<span style='color: lightgray; font-size: 10pt'><a href='https://github.com/klavins/LeanBook/blob/main/main/../LeanBook/Chapters/Numbers.lean'>Code</a> for this chapter</span></p>
<h1 id="the-rational-numbers"><a class="header" href="#the-rational-numbers">The Rational Numbers</a></h1>
<div style='background: yellow'>TODO: This chapter needs to be rewritten to follow the formal of the Integers chapter.</div>
<p>The (pre) rational numbers are just pairs of an <code>Int</code> and a <code>Nat</code>. But we also have to keep track of whether the denomenator is non-zero. We do that be including in the structure definion the rationals a proof of that property. Thus, every rational number in Lean "knows" it is well-formed.</p>
<pre><code class="language-lean">namespace LeanBook

structure PreRat where
  intro ::
  num : Int
  den : Nat
  dnz : den ≠ 0 := by decide -- works with constants

@[simp]
def eq (x y :PreRat) :=
  x.num * y.den = y.num * x.den
</code></pre>
<p>Pre-rational admits many representations of the same number.</p>
<pre><code class="language-lean">def p12 : PreRat := PreRat.intro 1 2
def p48 : PreRat := PreRat.intro 4 8

example : eq p12 p48 := rfl
</code></pre>
<p>Of course, Lean would define notation for all of this.</p>
<h2 id="defining-the-rationals"><a class="header" href="#defining-the-rationals">Defining the Rationals</a></h2>
<p>One way to define the Rationals from the Pre-Rationals is to form the set of all elements equivalent to a given Pre-Rational. Then that set <code>is</code> the rational.</p>
<p>For this to work, we have to show that the equality relation is an <code>equivalence relation</code>. This means it needs to be:</p>
<ul>
<li>reflexive: eq x x</li>
<li>symmetric: eq x y → eq y x</li>
<li>transitive: eq x y ∧ eq y z → eq x z</li>
</ul>
<p>We define the equivalence class of x to be</p>
<p>[x] = { y | x = y }</p>
<p>In this case, it is the set of all rationals that reduce to the same number.</p>
<p>The following are equivalent statements</p>
<p>eq x y
[x] = [y]
[x] ∩ [y] = ∅</p>
<h2 id="equality-is-reflexive-and-symmetric"><a class="header" href="#equality-is-reflexive-and-symmetric">Equality is Reflexive and Symmetric</a></h2>
<pre><code class="language-lean">theorem eq_refl {x : PreRat} : eq x x := by
  rfl

theorem eq_symm {x y : PreRat} : eq x y → eq y x := by
  intro h
  simp[eq]
  rw[eq] at h
  apply Eq.symm
  exact h
</code></pre>
<h2 id="transitivity-is-more-challenging"><a class="header" href="#transitivity-is-more-challenging">Transitivity is More Challenging.</a></h2>
<p>We want to show</p>
<p>x  =  y   and   y  =  z  →  x  =  z</p>
<p>Or</p>
<p>p     m         m     a      p     a
——— = ———  and  ——— = ——— →  ——— = ———
q     n         q     n      q     b</p>
<p>But we can't use fractions.</p>
<p>To show that x = z, which is equivalent to pb = aq.</p>
<p>We have</p>
<p>pbn = pnb = mqb = qmb = qan = aqn</p>
<p>Thus pb = aq since n ≠ 0</p>
<p>Source: https://math.stackexchange.com/questions/1316069/how-do-i-show-that-the-equivalence-relation-defining-the-rational-numbers-is-tra</p>
<h2 id="proof-of-transitivity"><a class="header" href="#proof-of-transitivity">Proof of Transitivity</a></h2>
<pre><code class="language-lean">theorem eq_trans {x y z : PreRat}
  : eq x y → eq y z → eq x z := by

  intro h1 h2
  let ⟨ p, q, _ ⟩   := x
  let ⟨ m, n, nnz ⟩ := y
  let ⟨ a, b, _ ⟩   := z

  have h : p * b * n = a * q * n := by
    calc p * b * n
    _  = p * ( b * n ) := by rw[Int.mul_assoc]
    _  = p * ( n * b ) := by simp[Int.mul_comm]
    _  = p * n * b     := by rw[Int.mul_assoc]
    _  = m * q * b     := by rw[h1]
    _  = q * m * b     := by simp[Int.mul_comm]
    _  = q * (m * b)   := by simp[Int.mul_assoc]
    _  = q * (a * n)   := by rw[h2]
    _  = q * a * n     := by simp[Int.mul_assoc]
    _  = a * q * n     := by simp[Int.mul_comm]

  simp at h
  apply Or.elim h
  . exact id
  . intro h
    exact False.elim (nnz h)
</code></pre>
<h2 id="building-the-rationals"><a class="header" href="#building-the-rationals">Building the Rationals</a></h2>
<pre><code class="language-lean">inductive Rat where
  | of_pre_rat : PreRat → Rat

open Rat

def P12 := of_pre_rat p12
def P48 := of_pre_rat p48
</code></pre>
<h2 id="lifting-equality-to-the-rationals"><a class="header" href="#lifting-equality-to-the-rationals">Lifting Equality to the Rationals</a></h2>
<pre><code class="language-lean">@[simp]
def LiftRel (r : PreRat → PreRat → Prop) (x y : Rat) : Prop :=
  match x, y with
  | of_pre_rat a, of_pre_rat b =&gt; r a b

@[simp]
def req := LiftRel eq

example : req P12 P48 := by
  simp[P12,P48,p12,p48]
</code></pre>
<h1 id="lifting-funtions"><a class="header" href="#lifting-funtions">Lifting Funtions</a></h1>
<pre><code class="language-lean">@[simp]
def pre_negate (x : PreRat) : PreRat := ⟨ -x.num, x.den, x.dnz ⟩

def Respects (f : PreRat → PreRat) := ∀ x y : PreRat, eq x y → eq (f x) (f y)

theorem negate_respects : Respects pre_negate := by
  intro h
  simp_all[pre_negate,eq]

@[simp]
def LiftFun (f : PreRat → PreRat) (x : Rat) : Rat := match x with
  | of_pre_rat a =&gt; of_pre_rat (f a)

@[simp]
def negate := LiftFun pre_negate

example : negate (negate P12) = P12 := by
  simp[P12]
</code></pre>
<div style='height=50px'>&nbsp;</div><hr>
Copyright © 2025 Eric Klavins
<div style="break-before: page; page-break-before: always;"></div><div style='display:none'>
--  Copyright (C) 2025  Eric Klavins
--
--  This program is free software: you can redistribute it and/or modify
--  it under the terms of the GNU General Public License as published by
--  the Free Software Foundation, either version 3 of the License, or
--  (at your option) any later version.   
</div>
<p><span style='color: orange'><em><strong>UNDER CONSTRUCTION</strong></em></span><br>
<span style='color: lightgray; font-size: 10pt'><a href='https://github.com/klavins/LeanBook/blob/main/main/../LeanBook/Chapters/Reals/Intro.lean'>Code</a> for this chapter</span></p>
<h1 id="real-numbers"><a class="header" href="#real-numbers">Real Numbers</a></h1>
<p>Having built ℕ inductively, then building ℤ from ℕ and ℚ from ℕ and ℤ, we now turn to the real numbers ℝ. The key distinction between ℚ and ℝ is that ℝ has the least upper bound property: every non-empty set of reals that is bounded from above has a least upper bound. The rationals ℚ do not have this property. For example, the set</p>
<pre><code class="language-hs">{ q ∈ ℚ | q² &lt; 2 }
</code></pre>
<p>has no least upper bound in ℚ, although in ℝ the least upper bound is <code>√2</code> (for a Lean proof that the square root of 2 is no rational, see <a href="https://leanprover-community.github.io/mathematics_in_lean/C05_Elementary_Number_Theory.html#irrational-roots">Chapter 5</a> of <em>MIL</em>.)</p>
<p>The usual way to construct ℝ, and the one taken by Mathlib, is to define <code>Cauchy Sequences</code> over <code>ℚ</code> that converge to irrational values. For example, the sequence</p>
<pre><code>  4/1
  4/1 - 4/3
  4/1 - 4/3 + 4/5
  4/1 - 4/3 + 4/5 - 4/7
  4/1 - 4/3 + 4/5 - 4/7 + 4/9
</code></pre>
<p>Converges to <code>π</code>.</p>
<p>In this chapter, mainly as an exercise in formalization, we instead construct ℝ from <em>Dedekind Cuts</em> in which every real number is equated to the set of rational numbers less than it. We roughly follow the decription of this approach presented in Rudin's book <em>Principles of Mathematical Analysis</em> (which also, by the way, describes the Cauchy Sequence approach.)</p>
<h2 id="axioms-of-the-reals"><a class="header" href="#axioms-of-the-reals">Axioms of the Reals</a></h2>
<p>To show that a set R is equivalent to the real numbers, we must define the following relations and operations:</p>
<ul>
<li>Ordering relations: &lt;, ≤, &gt; and ≥</li>
<li>Addition and subtraction: +, -</li>
<li>Multiplication: *</li>
<li>Division: /</li>
</ul>
<p>and then prove the following:</p>
<ul>
<li>R is totally ordered: ∀ x y ∈ R, x &lt; y ∨ y &lt; x ∨ x=y</li>
<li>R is a field
<ul>
<li>Addition properties
<ul>
<li>Addition is commutative: x+y=y+x</li>
<li>Addition is associative: x+(y+z) = (x+y)+z</li>
<li>There is an additive identity 0 and x+0 = 0+x = x.</li>
<li>Each element x has an additive inverse -x such that x+(-x) = 0.</li>
</ul>
</li>
<li>Multiplication properties
<ul>
<li>Multiplication is commutative: x<em>y=y</em>x</li>
<li>Multiplication is associative: x*(y<em>z) = (x</em>y)*z</li>
<li>There is a multiplicative identity 1 and x<em>1 = 1</em>x = x.</li>
<li>Each element x has a multiplicative inverse x⁻¹ such that x<em>x⁻¹ = x⁻¹</em>x = 1.</li>
</ul>
</li>
</ul>
</li>
<li>R has the least upper bound property</li>
</ul>
<p>Mathlib defines classes for all of these properties. Thus, as we prove them in Lean, we will register intances of these classes (and several others) so that our construction works with all of the theorems and tactics that Mathlib provides for notation, ordering, groups, rings, and fields.</p>
<p><span style='background: yellow'>TODO: List the relevant Mathlib classes or insert a tree diagram of them.</span></p>
<h2 id="references-5"><a class="header" href="#references-5">References</a></h2>
<p>A nice description of the Cauchy Completion: https://mathweb.ucsd.edu/~tkemp/140A/Construction.of.R.pdf</p>
<p>Rudin, W.: Principles of Mathematical Analysis. Third Edition. International Series in Pure and Applied Mathematics. McGraw-Hill Book Co., New York – Aukland – Dusseldorf, 1976.</p>
<p>A real analysis book in which ℝ is constructed from decimal expansions of the form f : ℕ → ℤ with f(0) being the integer part and f(n) ∈ {0, ..., 9} for n ≥ 1. <a href="https://docs.ufpr.br/%7Ehigidio/Ensino/Seminario/Davidson-Donsig-2010-Real%20Analysis%20and%20Aplications.pdf">Davidson and Donsig</a></p>
<div style='height=50px'>&nbsp;</div><hr>
Copyright © 2025 Eric Klavins
<div style="break-before: page; page-break-before: always;"></div><div style='display:none'>
--  Copyright (C) 2025  Eric Klavins
--
--  This program is free software: you can redistribute it and/or modify
--  it under the terms of the GNU General Public License as published by
--  the Free Software Foundation, either version 3 of the License, or
--  (at your option) any later version.   
</div>
<p><span style='color: orange'><em><strong>UNDER CONSTRUCTION</strong></em></span><br>
<span style='color: lightgray; font-size: 10pt'><a href='https://github.com/klavins/LeanBook/blob/main/main/../LeanBook/Chapters/Reals/Dedekind.lean'>Code</a> for this chapter</span></p>
<h1 id="the-dedekind-reals"><a class="header" href="#the-dedekind-reals">The Dedekind Reals</a></h1>
<p>Dedekind's representation of a real number <code>r</code> is as a pair <code>(A,B)</code> where <code>A ⊆ ℚ</code> is the set of all rational numbers less than <code>r</code> and <code>B = ℚ \ A</code>. The idea is that <code>A</code> approximates <code>r</code> from below and <code>B</code> approximates <code>r</code> from above. In the case that <code>r ∈ ℚ</code>, then <code>A = (∞,r)</code> and <code>B = [r,∞)</code>. Since <code>A</code> completely determines the cut, we work mainly with it, only occasionally referring to <code>B</code>.</p>
<p>That this definition satisfies the properties of the real numbers needs to be proved, which is what this chapter is about. Specifically, we will prove that</p>
<ul>
<li>The set of cuts is totally ordered</li>
<li>The set of cuts form a <em>field</em></li>
<li>Every bounded, non-empty set of cuts has a least upper bound</li>
</ul>
<p>The last property distinguishes the real numbers from the rationals.</p>
<p>A standard reference for Dedekind cuts is Rudin's Principles of Mathematics. In the 3rd edition, cuts are defined on pages 17-21.</p>
<h2 id="definition"><a class="header" href="#definition">Definition</a></h2>
<p>First, we define a structure to capture the precise definition of a cut <code>A ⊆ ℚ</code>. We require that A is nonempty, that it is not ℚ, that it is downward closed, and that is an open interval.</p>
<pre><code class="language-lean">@[ext]
structure DCut where
  A : Set ℚ
  ne : ∃ q, q ∈ A                   -- not empty
  nf : ∃ q, q ∉ A                   -- not ℚ
  dc : ∀ x y, x ≤ y ∧ y ∈ A → x ∈ A -- downward closed
  op : ∀ x ∈ A, ∃ y ∈ A, x &lt; y      -- open

open DCut
</code></pre>
<p>We have only defined the lower part, <code>A</code> of a cut. The upper part of the cut, <code>B</code> is defined simply:</p>
<pre><code class="language-lean">def DCut.B (c : DCut) : Set ℚ := Set.univ \ c.A
</code></pre>
<h2 id="making-rationals-into-reals"><a class="header" href="#making-rationals-into-reals">Making Rationals into Reals</a></h2>
<p>All rational numbers are also real numbers via the map that identifies a rational <code>q</code> with the interval <code>(∞,q)</code> of all rationals less than <code>q</code>. We call this set <code>odown q</code>, where <code>odown</code> is meant to abbreviate <code>open, downward closed</code>.</p>
<pre><code class="language-lean">def odown (q : ℚ) : Set ℚ := { y | y &lt; q }
</code></pre>
<p>To prove that <code>odown q</code> is a Dedekind cut requires we show it is nonempty, not <code>ℚ</code> itself, downward closed, and open. We will need to do this sort of proof over and over in this section, as we show various other ways of constructing sets of rationals are indeed Dedekind cuts.</p>
<p>For the first two theorems we use use the facts that <code>q-1 ∈ (∞,q)</code> and <code>q+1 ∉ (∞,q)</code>.</p>
<pre><code class="language-lean">theorem odown_ne {q : ℚ} : ∃ x, x ∈ odown q := by
  use q-1
  simp[odown]

theorem odown_nf {q : ℚ} : ∃ x, x ∉ odown q := by
  use q+1
  simp[odown]
</code></pre>
<p>That <code>odown</code> q is downward closed follows from the definitions.</p>
<pre><code class="language-lean">theorem odown_dc {q : ℚ} : ∀ x y, x ≤ y ∧ y ∈ odown q → x ∈ odown q := by
  intro x y ⟨ hx, hy ⟩
  simp_all[odown]
  linarith
</code></pre>
<p>To prove <code>odown q</code> is open, we are given <code>x ∈ odown</code> and need to supply <code>y ∈ odown q</code> with <code>x &lt; y</code>. Since <code>q</code> is the least upper bound of <code>odown q</code>, we choose <code>(x+q)/2</code>, which is less than <code>q</code> and greater than <code>x</code>.</p>
<pre><code class="language-lean">theorem odown_op {q : ℚ} : ∀ x ∈ odown q, ∃ y ∈ odown q, x &lt; y:= by
  intro x hx
  use (x+q)/2
  simp_all[odown]
  apply And.intro
  repeat linarith
</code></pre>
<p>With these theorems we define the map <code>ofRat : ℚ → DCut</code> that embeds the rationals into the Dedekind cuts.</p>
<pre><code class="language-lean">def ofRat (q : ℚ) : DCut :=
  ⟨ odown q, odown_ne, odown_nf, odown_dc, odown_op ⟩

instance rat_cast_inst : RatCast DCut := ⟨ λ x =&gt; ofRat x ⟩

instance nat_cast_inst : NatCast DCut := ⟨ λ x =&gt; ofRat x ⟩

instance int_cast_inst : IntCast DCut := ⟨ λ x =&gt; ofRat x ⟩
</code></pre>
<p>With this map we can define 0 and 1, as well as a couple of helper theorems we will later.</p>
<pre><code class="language-lean">instance zero_inst : Zero DCut := ⟨ ofRat 0 ⟩
instance one_inst : One DCut := ⟨ ofRat 1 ⟩
instance inhabited_inst : Inhabited DCut := ⟨ 0 ⟩

theorem zero_rw : A 0 = odown 0 := by rfl
theorem one_rw : A 1 = odown 1 := by rfl

theorem zero_ne_one : (0:DCut) ≠ 1 := by
  intro h
  simp[DCut.ext_iff,zero_rw,one_rw,odown,Set.ext_iff] at h
  have h0 := h (1/2)
  have h1 : (1:ℚ)/2 &lt; 1 := by linarith
  have h2 : ¬(1:ℚ)/2 &lt; 0 := by linarith
  exact h2 (h0.mpr h1)

instance non_triv_inst : Nontrivial DCut := ⟨ ⟨ 0, 1, zero_ne_one ⟩ ⟩
</code></pre>
<h2 id="simple-properties-of-cuts"><a class="header" href="#simple-properties-of-cuts">Simple Properties of Cuts</a></h2>
<p>Next we define a few basic properties that will be used in later proofs, but that are also good exercises here.</p>
<p>First, if <code>q</code> is not in <code>A</code> then <code>q</code> is in <code>B</code>, and vice verse, which together imply that <code>A</code> and <code>B</code> are a partition of <code>ℚ</code>.</p>
<pre><code class="language-lean">theorem not_in_a_in_b {c :DCut} {q : ℚ} : q ∉ c.A → q ∈ c.B := by
  simp[B]

theorem not_in_b_in_a {c :DCut} {q : ℚ} : q ∉ c.B → q ∈ c.A := by
  simp[B]
</code></pre>
<p>We also have two simple properties describing <code>A</code> as a downward closed set. The first simply uses the ordering property of <code>ℚ</code>, while the second follows from the fact that <code>A</code> is downward closed.</p>
<pre><code class="language-lean">theorem ub_to_notin {y:ℚ} {A : Set ℚ}
  : (∀ x ∈ A, x &lt; y) → y ∉ A := by
  intro h hy
  have := h y hy
  simp_all

theorem notin_to_ub {y:ℚ} {a : DCut}
  : y ∉ a.A → (∀ x ∈ a.A, x &lt; y)  := by
  intro hy x hx
  by_contra h
  have := a.dc y x ⟨ by linarith, hx ⟩
  exact hy this
</code></pre>
<p>The fact that <code>A</code> is open can be used to show a few simple properties as well. Since <code>A</code> is open, you can find an element in <code>A</code> bigger than any given element in <code>A</code>. Thus, you can find two values in <code>A</code> bigger than any given element. In fact, you can find an arbitary number of elements in <code>A</code> bigger than a given element (see exercises).</p>
<pre><code class="language-lean">theorem op2 {a : DCut} (q : ℚ) (hq : q ∈ a.A)
  : ∃ x, ∃ y, x ∈ a.A ∧ y ∈ a.A ∧ q &lt; x ∧ x &lt; y := by
  have ⟨s, ⟨ hs1, hs2 ⟩ ⟩ := a.op q hq
  have ⟨t, ⟨ ht1, ht2 ⟩ ⟩ := a.op s hs1
  use s, t
</code></pre>
<p>The following is a simple helper theorem that uses the fact that cuts are open. It is used to simplify a proof in the multiplication section.</p>
<pre><code class="language-lean">theorem op_from_two_vals {a : DCut} {x y : ℚ} (hx : x ∈ a.A) (hy : y ∈ a.A)
  : ∃ z ∈ a.A, x &lt; z ∧ y &lt; z := by
  by_cases h : x &lt; y
  . have ⟨ z, ⟨ hz1, hz2 ⟩ ⟩ := a.op y hy
    exact ⟨ z, ⟨ hz1, ⟨ by linarith, hz2 ⟩ ⟩ ⟩
  . have ⟨ z, ⟨ hz1, hz2 ⟩ ⟩ := a.op x hx
    exact ⟨ z, ⟨ hz1, ⟨ hz2, by linarith ⟩ ⟩ ⟩
</code></pre>
<p>Next, we show  <code>x in A</code> and <code>y in B</code>, that <code>x &lt; y</code>.</p>
<pre><code class="language-lean">theorem b_gt_a {c : DCut} {x y : ℚ} : x ∈ c.A → y ∈ c.B → x &lt; y := by
  intro hx hy
  simp[B] at hy
  by_contra h
  exact  hy (c.dc y x ⟨ Rat.not_lt.mp h, hx ⟩)
</code></pre>
<p>An alternative for of this same theorem, in which <code>B</code> is characterized as <code>ℚ \ A</code> is also useful.</p>
<pre><code class="language-lean">theorem a_lt_b {c : DCut} {x y : ℚ }: x ∈ c.A → y ∉ c.A → x &lt; y := by
  intro hx hy
  exact b_gt_a hx (not_in_a_in_b hy)
</code></pre>
<p>Next we show that since <code>A</code> is downward closed, one can easily show <code>B</code> is upward closed.</p>
<pre><code class="language-lean">theorem b_up_closed {c : DCut} {a b: ℚ} : a ∉ c.A → a ≤ b → b ∉ c.A := by
  intro h1 h2 h3
  exact h1 (c.dc a b ⟨ h2, h3 ⟩)
</code></pre>
<h2 id="ordering"><a class="header" href="#ordering">Ordering</a></h2>
<p>Next we show that cuts are totally ordered by the subset relation. First, we define and instantiate the less than and less than or equal relations on cuts.</p>
<pre><code class="language-lean">instance lt_inst : LT DCut := ⟨ λ x y =&gt; x ≠ y ∧ x.A ⊆ y.A ⟩
instance le_inst : LE DCut := ⟨ λ x y =&gt; x.A ⊆ y.A ⟩
</code></pre>
<p>To check these definitions make sense, we verify them with rational numbers.</p>
<pre><code class="language-lean">example {x y : ℚ} : x ≤ y → (ofRat x) ≤ (ofRat y) := by
  intro h q hq
  exact gt_of_ge_of_gt h hq
</code></pre>
<p>It is useful to be able to rewrite the less than relation <code>&lt;</code> in terms of inequality and <code>≤</code>, and to rewrite <code>≤</code> in terms of equality and <code>&lt;</code>.</p>
<pre><code class="language-lean">theorem DCut.lt_of_le {x y: DCut} : x &lt; y ↔ x ≠ y ∧ x ≤ y := by
  exact Eq.to_iff rfl

theorem DCut.le_of_lt {x y: DCut} : x ≤ y ↔ x = y ∨ x &lt; y := by
  simp_all[le_inst,lt_inst]
  constructor
  . intro h
    simp[h]
    exact Classical.em (x=y)
  . intro h
    cases h with
    | inl h1 =&gt; exact Eq.subset (congrArg A h1)
    | inr h1 =&gt; exact h1.right
</code></pre>
<p>We can easily prove that cuts form a partial order, which allows us to regiester <code>DCut</code> with Mathlib's PartialOrder class. <span style='background: yellow'>TODO: Can't you just used the fact that <code>⊆</code> is a partial order?</span></p>
<pre><code class="language-lean">theorem refl {a: DCut} : a ≤ a := by
  simp_all[le_inst,lt_inst]

theorem anti_symm {a b: DCut} : a ≤ b → b ≤ a → a = b := by
  intro hab hba
  ext q
  constructor
  . intro hq
    exact hab (hba (hab hq))
  . intro hq
    exact hba (hab (hba hq))

theorem trans {a b c: DCut} : a ≤ b → b ≤ c → a ≤ c := by
  intro hab hbc q hq
  exact hbc (hab hq)

theorem lt_iff_le_not_le {a b : DCut} : a &lt; b ↔ a ≤ b ∧ ¬b ≤ a := by
  constructor
  . intro h
    rw[lt_of_le] at h
    have ⟨ h1, h2 ⟩ := h
    constructor
    . exact h.right
    . intro h3
      exact h1 (anti_symm h.right h3)
  . intro ⟨ h1, h2 ⟩
    rw[le_of_lt] at h1
    apply Or.elim h1
    . intro h
      rw[h] at h2
      exact False.elim (h2 refl)
    . intro h
      exact h

instance pre_order_inst : Preorder DCut :=
  ⟨ @refl, @trans, @lt_iff_le_not_le ⟩

instance poset_inst : PartialOrder DCut :=
  ⟨ @anti_symm ⟩
</code></pre>
<p>Next we prove that cuts form a total order, and instantiate this fact with the TotalOrder class from Mathlib.</p>
<pre><code class="language-lean">theorem total {x y : DCut} : x ≤ y ∨ y ≤ x := by
  by_cases h : x ≤ y
  . exact Or.inl h
  . apply Or.inr
    simp_all[le_inst]
    intro b hb
    rw[Set.subset_def] at h
    simp at h
    obtain ⟨ a, ⟨ ha1, ha2 ⟩ ⟩ := h
    exact x.dc b a ⟨ le_of_lt (a_lt_b hb ha2), ha1 ⟩

instance total_inst : IsTotal DCut (· ≤ ·) := ⟨ @total ⟩
</code></pre>
<p>The total order property allows crisply define positive and negative numbers.</p>
<pre><code class="language-lean">def isPos (x : DCut) : Prop := 0 &lt; x
def isNeg (x : DCut) : Prop := x &lt; 0
</code></pre>
<p>We can also use the total order property to prove that <code>DCut</code> is <em>Trichotomous</em>, that is, that for all <code>x</code> and <code>y</code>, either <code>x ≤ y</code>, <code>y ≤ x</code>, or <code>x=y</code>.</p>
<pre><code class="language-lean">theorem trichotomy (x y: DCut) : x ≤ y ∨ x = y ∨ y ≤ x := by
  apply Or.elim (@total x y)
  . intro h
    exact Or.symm (Or.inr h)
  . intro h
    exact Or.inr (Or.inr h)

theorem trichotomy_lt (x y: DCut) : x &lt; y ∨ x = y ∨ y &lt; x := by
  have := trichotomy x y
  simp[le_of_lt] at this
  aesop

instance trichotomous_inst : IsTrichotomous DCut (· ≤ ·) := ⟨ trichotomy ⟩

instance trichotomous_inst' : IsTrichotomous DCut (· &lt; ·) := ⟨ trichotomy_lt ⟩
</code></pre>
<h2 id="theorems-about-zero-and-one"><a class="header" href="#theorems-about-zero-and-one">Theorems About Zero and One</a></h2>
<pre><code class="language-lean">theorem zero_in_pos {a : DCut} (ha : 0 &lt; a) : 0 ∈ a.A := by
  obtain ⟨ h1, h2 ⟩ := ha
  simp at h1
  rw[DCut.ext_iff] at h1
  have h21 := Set.ssubset_iff_subset_ne.mpr ⟨h2, h1⟩
  have ⟨ x, ⟨ hx1, hx2 ⟩ ⟩ := (Set.ssubset_iff_of_subset h2).mp h21
  simp[zero_rw,odown] at hx2
  exact a.dc 0 x ⟨ hx2, hx1 ⟩

theorem pos_has_zero {a : DCut} : 0 &lt; a ↔ 0 ∈ a.A := by
  constructor
  . intro h
    exact zero_in_pos h
  . simp[lt_inst,DCut.ext_iff]
    intro h
    constructor
    . intro h1
      rw[←h1] at h
      simp[zero_rw,odown] at h
    . intro q hq
      simp[zero_rw,odown] at hq
      apply a.dc q 0
      exact ⟨ by exact _root_.le_of_lt hq, h ⟩


theorem non_neg_in_pos {a : DCut} (ha : 0 &lt; a) : ∃ x ∈ a.A, 0 &lt; x := by
  have h0 := zero_in_pos ha
  exact a.op 0 h0

theorem zero_notin_neg {a : DCut} (ha : a &lt; 0) : 0 ∉ a.A := by
  intro h
  simp[lt_inst] at ha
  have ⟨ h1, h2 ⟩ := ha
  have : 0 ∈ A 0 := h2 h
  simp[zero_rw,odown] at this

@[simp]
theorem zero_lt_one : (0:DCut) &lt; 1 := by
  simp[lt_inst]
  apply And.intro
  . intro h
    simp[DCut.ext_iff,zero_rw,one_rw,odown,Set.ext_iff] at h
    have := h 0
    simp_all
  . intro q hq
    simp_all[zero_rw,one_rw,odown]
    linarith

@[simp]
theorem zero_le_one : (0:DCut) ≤ 1 := by
  simp[le_inst]
  intro q hq
  simp_all[zero_rw,one_rw,odown]
  linarith

instance zero_le_one_inst : ZeroLEOneClass DCut := ⟨ zero_le_one ⟩

theorem not_gt_to_le {a : DCut} : ¬ 0 &lt; a ↔ a ≤ 0 := by
  constructor
  . have := trichotomy_lt 0 a
    apply Or.elim this
    . intro h1 h2
      simp_all
    . intro h1 h2
      simp_all
      apply le_of_lt.mpr
      rw[Eq.comm]
      exact h1
  . intro h1 h2
    apply le_of_lt.mp at h1
    simp_all[DCut.ext_iff,lt_inst]
    have ⟨ h3, h4 ⟩ := h2
    simp_all
    apply Or.elim h1
    . intro h
      exact h3 (id (Eq.symm h))
    . intro ⟨ h5, h6 ⟩
      have : A 0 = a.A := by exact Set.Subset.antisymm h4 h6
      exact h3 this

theorem has_ub (a : DCut) : ∃ x, x ∉ a.A ∧ ∀ y ∈ a.A, y &lt; x := by
  obtain ⟨ x, hx ⟩ := a.nf
  use! x, hx
  intro y hy
  exact a_lt_b hy hx

theorem in_down {p q:ℚ} (h : p &lt; q) : p ∈ odown q := by
  simp[odown]
  exact h

theorem in_zero {q:ℚ} (h: q&lt;0) : q ∈ A 0 := by
  simp[zero_rw]
  exact in_down h

theorem in_one {q:ℚ} (h: q&lt;1) : q ∈ A 1 := by
  simp[one_rw]
  exact in_down h
</code></pre>
<h2 id="supporting-reasoning-by-cases"><a class="header" href="#supporting-reasoning-by-cases">Supporting Reasoning by Cases</a></h2>
<p>Later, in the chapter on multiplication, it will be useful to reason about combinations of non-negative and negative cuts. With one cut <code>a</code>, there are two possibilities: <code>0 ≤ a</code> and <code>a &lt; 0</code>. For two cuts there are four possibilities, and for three cuts, there are eight possibilities.</p>
<p>The following two definitions list all possible cases for two and three cuts respectively.</p>
<pre><code class="language-lean">def two_ineq_list (a b : DCut) :=
  (0 ≤ a ∧ 0 ≤ b) ∨
  (a &lt; 0 ∧ 0 ≤ b) ∨
  (0 ≤ a ∧ b &lt; 0) ∨
  (a &lt; 0 ∧ b &lt; 0)

def two_ineq_nn_list (a b: DCut) :=
  (0 &lt; a ∧ 0 &lt; b) ∨ a = 0 ∨ b = 0

def three_ineq_list (a b c : DCut) :=
  (0 ≤ a ∧ 0 ≤ b ∧ 0 ≤ c) ∨
  (a &lt; 0 ∧ 0 ≤ b ∧ 0 ≤ c) ∨
  (0 ≤ a ∧ b &lt; 0 ∧ 0 ≤ c) ∨
  (0 ≤ a ∧ 0 ≤ b ∧ c &lt; 0) ∨
  (a &lt; 0 ∧ b &lt; 0 ∧ 0 ≤ c) ∨
  (a &lt; 0 ∧ 0 ≤ b ∧ c &lt; 0) ∨
  (0 ≤ a ∧ b &lt; 0 ∧ c &lt; 0) ∨
  (a &lt; 0 ∧ b &lt; 0 ∧ c &lt; 0)

def three_ineq_nn_list (a b c : DCut) :=
  (0 &lt; a ∧ 0 &lt; b ∧ 0 &lt; c) ∨ a = 0 ∨ b = 0 ∨ c = 0
</code></pre>
<p>Next we show that these statements are tautologies. The goal is to be able to use the definitions in tactic mode, as in:</p>
<pre><code class="language-hs">rcases @two_ineqs a b with ⟨ ha, hb ⟩ | ⟨ ha, hb ⟩ | ⟨ ha, hb ⟩ | ⟨ ha, hb ⟩
repeat
simp
</code></pre>
<p>We start with a theorem that can be used to rewrite <code>x&lt;0</code> as <code>¬0≤x</code>.</p>
<pre><code class="language-lean">theorem neg_t {x : DCut} : x &lt; 0 ↔ ¬0 ≤ x := by
  have := trichotomy_lt 0 x
  simp_all[le_of_lt]
  constructor
  . intro h
    exact ⟨ ne_of_gt h, not_lt_of_gt h ⟩
  . tauto

theorem neg_t' {x : DCut} : 0 &lt; x ↔ ¬x ≤ 0 := by
  have := trichotomy_lt 0 x
  simp_all[le_of_lt]
  constructor
  . intro h
    exact ⟨ ne_of_gt h, not_lt_of_gt h ⟩
  . tauto
</code></pre>
<p>Then the proofs are straightforward. To see how these are used later, see the proofs of commutativity and associativity of multiplication.</p>
<pre><code class="language-lean">theorem lt_imp_le {x y : DCut} : x &lt; y → x ≤ y := by simp[lt_of_le]

theorem two_ineqs (a b : DCut) : two_ineq_list a b := by
  simp[two_ineq_list,neg_t]
  tauto

theorem three_ineqs (a b c : DCut) : three_ineq_list a b c := by
  simp[three_ineq_list,neg_t]
  tauto

theorem two_nn_ineqs {a b : DCut} (ha : 0 ≤ a) (hb : 0 ≤ b)
  : two_ineq_nn_list a b := by
  simp[two_ineq_nn_list,neg_t]
  simp[le_of_lt] at ha hb
  tauto

theorem three_nn_ineqs {a b c : DCut} (ha : 0 ≤ a) (hb : 0 ≤ b) (hc : 0 ≤ c)
  : three_ineq_nn_list a b c := by
  simp[three_ineq_nn_list,neg_t]
  simp[le_of_lt] at ha hb hc
  tauto
</code></pre>
<p><strong>Exercise</strong>:</p>
<ol>
<li>
<p>Show that <code>ofRat</code> is indeed an order embedding, that is <code>x ≤ y → ofRat x ≤ ofRat y</code> for all rational numbers <code>x</code> and <code>y</code>.</p>
</li>
<li>
<p>Let <code>(A,B)</code> be a cut. Show that for any <code>q ∈ A</code>, there exists a function <code>f : ℕ → A</code> such that<br>
a) <code>q i ∈ A</code><br>
b) <code>q &lt; f 0</code> and for all <code>i</code>, <code>f i &lt; f j</code></p>
</li>
</ol>
<div style='height=50px'>&nbsp;</div><hr>
Copyright © 2025 Eric Klavins
<div style="break-before: page; page-break-before: always;"></div><div style='display:none'>
--  Copyright (C) 2025  Eric Klavins
--
--  This program is free software: you can redistribute it and/or modify
--  it under the terms of the GNU General Public License as published by
--  the Free Software Foundation, either version 3 of the License, or
--  (at your option) any later version.   
</div>
<p><span style='color: orange'><em><strong>UNDER CONSTRUCTION</strong></em></span><br>
<span style='color: lightgray; font-size: 10pt'><a href='https://github.com/klavins/LeanBook/blob/main/main/../LeanBook/Chapters/Reals/Add.lean'>Code</a> for this chapter</span></p>
<h1 id="addition"><a class="header" href="#addition">Addition</a></h1>
<pre><code class="language-lean">def presum (a b : DCut) :=  { z | ∃ x ∈ a.A, ∃ y ∈ b.A, x+y=z }

theorem presum_ne {a b : DCut} :  ∃ q, q ∈ presum a b := by
  obtain ⟨ x, hx ⟩ := a.ne
  obtain ⟨ y, hy ⟩ := b.ne
  exact ⟨ x+y, ⟨ x, ⟨ hx, ⟨ y, ⟨ hy, by linarith ⟩ ⟩ ⟩ ⟩ ⟩

theorem presum_nf {a b : DCut} : ∃ q, q ∉ presum a b := by
    obtain ⟨ x, hx ⟩ := a.nf
    obtain ⟨ y, hy ⟩ := b.nf
    use x+y
    intro h
    obtain ⟨ s, ⟨ hs, ⟨ t, ⟨ ht, hst ⟩ ⟩ ⟩ ⟩ := h
    have hs' := b_gt_a hs (not_in_a_in_b hx)
    have ht' := b_gt_a ht (not_in_a_in_b hy)
    linarith

theorem presum_op {a b : DCut}
  : ∀ x ∈ presum a b, ∃ y ∈ presum a b, x &lt; y := by
  intro c hc
  simp_all[presum]
  obtain ⟨ x, ⟨ hx, ⟨ y, ⟨ hy, h ⟩ ⟩ ⟩ ⟩ := hc
  have hao := a.op
  have hbo := b.op
  obtain ⟨ x', hx', hxx' ⟩ := hao x hx
  obtain ⟨ y', hy', hyy' ⟩ := hbo y hy
  use x'
  apply And.intro
  . exact hx'
  . use y'
    apply And.intro
    . exact hy'
    . linarith

theorem presum_dc {a b : DCut }
  : ∀ (x y : ℚ), x ≤ y ∧ y ∈ presum a b → x ∈ presum a b := by
  intro s t ⟨ h1, h2 ⟩
  simp_all[presum]
  obtain ⟨ x, ⟨ hx, ⟨ y, ⟨ hy, h ⟩ ⟩ ⟩ ⟩ := h2

  have hyts : y - (t - s) ∈ b.A := by
    have h3 : 0 ≤ t-s := by linarith
    have h4 : y - (t-s) ≤ y := by linarith
    exact b.dc (y-(t-s)) y ⟨h4,hy⟩

  exact ⟨ x, ⟨ hx, ⟨ y - (t-s), ⟨ hyts, by linarith ⟩ ⟩ ⟩ ⟩

def sum (a b : DCut) : DCut :=
  ⟨ presum a b, presum_ne, presum_nf, presum_dc, presum_op ⟩

instance hadd_inst : HAdd DCut DCut DCut:= ⟨ sum ⟩

instance add_inst : Add DCut := ⟨ sum ⟩

theorem add_rats {x y: ℚ} : ofRat (x+y) = ofRat x + ofRat y := by

  simp[ofRat,hadd_inst,sum,presum,odown]
  ext q
  constructor

  . intro hq
    let ε := x+y - q
    have hε : q = x+y-ε := by
      simp[ε]
    simp_all
    exact ⟨ x-ε/2, ⟨ by linarith, ⟨ y-ε/2, ⟨ by linarith, by linarith ⟩ ⟩ ⟩ ⟩

  . intro ⟨ a, ⟨ ha, ⟨ b, ⟨ hb1, hb2 ⟩ ⟩ ⟩ ⟩
    simp_all
    linarith
</code></pre>
<h3 id="the-associative-property-of-addition"><a class="header" href="#the-associative-property-of-addition">The Associative Property Of Addition</a></h3>
<pre><code class="language-lean">theorem sum_assoc {a b c : DCut} : (a+b)+c = a + (b+c) := by
  simp[hadd_inst,sum]
  ext q
  constructor
  . intro hq
    simp_all[presum]
    obtain ⟨ x, ⟨ hx, ⟨ y, ⟨ hy, ⟨ z, ⟨ hz, hsum ⟩ ⟩ ⟩ ⟩ ⟩ ⟩ := hq
    exact ⟨ x, ⟨ hx, ⟨ y, ⟨ hy, ⟨ z, ⟨ hz, by linarith ⟩ ⟩ ⟩ ⟩ ⟩ ⟩
  . intro hq
    simp_all[presum]
    obtain ⟨ x, ⟨ hx, ⟨ y, ⟨ hy, ⟨ z, ⟨ hz, hsum ⟩ ⟩ ⟩ ⟩ ⟩ ⟩ := hq
    exact ⟨ x, ⟨ hx, ⟨ y, ⟨ hy, ⟨ z, ⟨ hz, by linarith ⟩ ⟩ ⟩ ⟩ ⟩ ⟩

instance addsemigroup_inst : AddSemigroup DCut := ⟨ @sum_assoc ⟩
</code></pre>
<h3 id="commutativity-of-addition"><a class="header" href="#commutativity-of-addition">Commutativity of Addition</a></h3>
<pre><code class="language-lean">theorem sum_comm {a b : DCut} : a + b = b + a := by
  simp[hadd_inst,sum]
  ext q
  constructor
  repeat
  . intro ⟨ x, ⟨ hx, ⟨ y, ⟨ hy, h ⟩ ⟩ ⟩ ⟩
    exact ⟨ y, ⟨ hy, ⟨ x, ⟨ hx, by linarith ⟩ ⟩ ⟩ ⟩

instance addcommsemigroup_inst : AddCommSemigroup DCut := ⟨ @sum_comm ⟩
</code></pre>
<h3 id="adding-zero"><a class="header" href="#adding-zero">Adding Zero</a></h3>
<pre><code class="language-lean">theorem sum_zero_left {a : DCut} : 0 + a = a := by
  ext c
  simp[hadd_inst,sum,zero_inst]
  constructor
  . intro ⟨ x, ⟨ hx, ⟨ y, ⟨ hy, h ⟩ ⟩ ⟩ ⟩
    have : x &lt; 0 := hx
    apply a.dc c y
    apply And.intro
    . linarith
    . exact hy
  . intro h
    obtain ⟨ x, ⟨ hx1, hx2 ⟩ ⟩ := a.op c h
    have h1 : c-x &lt; 0 := by linarith
    exact ⟨ c-x, ⟨ h1, ⟨ x, ⟨ hx1, by linarith ⟩ ⟩ ⟩ ⟩

theorem sum_zero_right {a : DCut} : a + 0 = a := by
  rw[sum_comm,sum_zero_left]

instance add_zero_inst : AddZeroClass DCut :=
  ⟨ @sum_zero_left, @sum_zero_right ⟩
</code></pre>
<h1 id="order-properties"><a class="header" href="#order-properties">Order Properties</a></h1>
<pre><code class="language-lean">theorem sum_pos_pos {a b : DCut} (ha : 0 &lt; a) (hb : 0 &lt; b) : 0 &lt; a + b := by
  constructor
  . intro h
    have ha0 := pos_has_zero.mp ha
    have hb0 := pos_has_zero.mp hb
    have : 0 ∈ (a+b).A := by
      exact ⟨ 0, ⟨ ha0, ⟨ 0, ⟨ hb0, by exact Rat.zero_add 0 ⟩ ⟩ ⟩ ⟩
    simp[←h,zero_rw,odown] at this
  . intro q hq
    have : q ∈ b.A := by
      simp[zero_rw,odown] at hq
      exact b.dc q 0 ⟨ by linarith, zero_in_pos hb ⟩
    exact ⟨ 0, ⟨ zero_in_pos ha, ⟨ q, ⟨ this, by linarith ⟩ ⟩ ⟩ ⟩

theorem sum_nneg_nneg {a b : DCut} (ha : 0 ≤ a) (hb : 0 ≤ b) : 0 ≤ a + b := by
  rcases two_nn_ineqs ha hb with ⟨ ha, hb ⟩ | h | h
  . apply lt_imp_le
    apply sum_pos_pos ha hb
  . simp[h,sum_zero_left,hb]
  . simp[h,sum_zero_right,ha]
</code></pre>
<div style='height=50px'>&nbsp;</div><hr>
Copyright © 2025 Eric Klavins
<div style="break-before: page; page-break-before: always;"></div><div style='display:none'>
--  Copyright (C) 2025  Eric Klavins
--
--  This program is free software: you can redistribute it and/or modify
--  it under the terms of the GNU General Public License as published by
--  the Free Software Foundation, either version 3 of the License, or
--  (at your option) any later version.   
</div>
<p><span style='color: orange'><em><strong>UNDER CONSTRUCTION</strong></em></span><br>
<span style='color: lightgray; font-size: 10pt'><a href='https://github.com/klavins/LeanBook/blob/main/main/../LeanBook/Chapters/Reals/Subtract.lean'>Code</a> for this chapter</span></p>
<h1 id="negation-1"><a class="header" href="#negation-1">Negation</a></h1>
<pre><code class="language-lean">def preneg (c : DCut) : Set ℚ := { x | ∃ a &lt; 0, ∃ b ∉ c.A, x = a-b }

theorem preneg_rat {p : ℚ} : preneg (ofRat p) = (ofRat (-p)).A := by
  simp[preneg,ofRat,odown]
  ext q
  constructor
  . simp_all
    intro a ha x hx hq
    linarith
  . simp_all
    intro hq
    exact ⟨ q+p, ⟨ by linarith, ⟨ p, ⟨ by linarith, by linarith ⟩ ⟩ ⟩ ⟩

theorem predeg_ne {c : DCut} : ∃ q, q ∈ preneg c := by
  simp[preneg]
  have ⟨ q, hq ⟩ := c.nf
  use -q-2
  have h1 : q + 1 ∉ c.A := by
    apply b_up_closed hq
    linarith
  exact  ⟨ -1, ⟨ by linarith, ⟨ q+1, ⟨ h1, by linarith ⟩ ⟩ ⟩ ⟩

theorem predeg_nf {c : DCut} : ∃ q, q ∉ preneg c := by
  simp[preneg]
  have ⟨ q, hq ⟩ := c.ne
  use -q
  intro x hx y hy h
  have h2 : y ≤ q := by linarith
  have h3 : q ∉ c.A := by
    intro h1
    exact b_up_closed hy h2 hq
  exact h3 hq

theorem predeg_dc {c : DCut}
  : ∀ (x y : ℚ), x ≤ y ∧ y ∈ preneg c → x ∈ preneg c := by
  intro x y ⟨ hxy, ⟨ a, ⟨ ha, ⟨ b, ⟨ hb, h ⟩ ⟩ ⟩ ⟩ ⟩
  exact ⟨ a - (y-x), ⟨ by linarith, ⟨ b, ⟨ hb, by linarith ⟩ ⟩ ⟩ ⟩

theorem predeg_op {c : DCut}
  : ∀ x ∈ preneg c, ∃ y ∈ preneg c, x &lt; y := by
  simp[preneg]
  intro q x hx y hy hxy
  have := c.op
  use q-x/2
  apply And.intro
  . simp[hxy]
    exact ⟨ x/2, ⟨ by linarith, ⟨ y, ⟨ hy, by linarith ⟩ ⟩ ⟩ ⟩
  . linarith

def neg (c : DCut) : DCut :=
  ⟨ preneg c, predeg_ne, predeg_nf, predeg_dc, predeg_op ⟩

instance neg_inst : Neg DCut := ⟨ neg ⟩

theorem neg_rat {p : ℚ} : -ofRat p = ofRat (-p) := by
  simp[neg_inst,neg]
  apply DCut.ext
  simp
  rw[preneg_rat]
</code></pre>
<h2 id="subtraction"><a class="header" href="#subtraction">Subtraction</a></h2>
<pre><code class="language-lean">def sub (a b : DCut) : DCut := a + (-b)

instance hsub_inst : HSub DCut DCut DCut := ⟨ sub ⟩

instance sub_inst : Sub DCut := ⟨ sub ⟩

theorem add_neg (a b : DCut) : a + -b = a - b := by
  simp[hsub_inst,sub]
</code></pre>
<p>Let's check this definition works for the simple example <code>1-1=0</code>. The forward direction is easy. For the reverse direction, we need to choose x and y so that</p>
<ul>
<li><code>x &lt; 1</code></li>
<li><code>y &lt; -1</code></li>
<li><code>x + y = q</code></li>
</ul>
<p>Since q &lt; 0, we know q-1 &lt; -1. For y, we take the point halfway between q-1 and -1, which is <code>y = (q-2)/2</code>.</p>
<pre><code class="language-lean">example : ofRat 1 - ofRat 1 = ofRat 0 := by
  simp[hsub_inst,sub,neg_rat]
  ext q
  simp[hadd_inst,sum,ofRat,presum,odown]
  constructor
  . intro ⟨ x, ⟨ hx, ⟨ y, ⟨ hy, h ⟩ ⟩ ⟩ ⟩
    linarith
  . intro hq
    exact ⟨ (q+2)/2, ⟨ by linarith, ⟨ (q-2)/2, ⟨ by linarith, by linarith ⟩ ⟩ ⟩ ⟩
</code></pre>
<p>More challenging is to show for any cut <code>c</code> that <code>c-c=0</code>. We are given <code>q&lt;0</code>. Since <code>c.A</code> is not <code>ℚ</code>, we can choose an element <code>t ∉ c.A</code>. We then want to find <code>a ∈ -c.A</code> and <code>b ∈ c.A</code> so that <code>a+b=q</code>. Using the Archimedean property of the rational numbers, we can find <code>n</code> such that <code>t + (n+1)q ∈ c.A</code> and <code>t + nq ∉ c.A</code>.</p>
<p>These values do not work directly because of the edge case where <code>c</code> is a principal cut (representing a rational number). For example, the situation could look like the diagram below.</p>
<pre><code>                -c.A                        b      c.A    -a
       -t - nq             q       0   t + (n+1)q       t + nq
  ←———————+———————)————————+———————+———————+————————)—————+————————————→
                 -2       -1             4-3=1      2   4-2=2
</code></pre>
<p>But because <code>c.A</code> is open, we can find <code>z</code> greater than <code>t + (n+1)q</code> and which is still in c.A.</p>
<pre><code>        -c.A                                              c.A
                      q          0    t + (n+1)q                  t + nq
  ←———————)———————————+——————————+————————+————————+———————)————————+————————————→
                                                   z
</code></pre>
<p>And then take ε = z - (t + (n+1)q) to get the following situation, where <code>a</code> is completly inside <code>-c.A</code>.</p>
<pre><code>          a    -c.A                        b          c.A
  ←———————+———————)———————+———————+————————+———————————)———————+————————————→
   -t - nq - ε            q       0    t + (n+1)q + ε       t + nq + ε
</code></pre>
<p>This proof outline takes some work to get done in Lean. First we need a result showing that given <code>t ∉ c.A</code> we can find an <code>n</code> so that <code>t + n s ∈ c.A</code>.</p>
<pre><code class="language-lean">theorem cut_element (c : DCut) (s t : ℚ) (hs : s &lt; 0)
  : ∃ n : ℕ, t + n * s ∈ c.A := by
  obtain ⟨q, hq⟩ := c.ne
  let n := ⌈(q-t)/s⌉₊
  use n
  have hdiv : (q-t)/s ≤ n := Nat.le_ceil ((q - t) / s)
  have hcalc : t + n * s ≤ q := by
    have : (q-t) ≥ n * s := (div_le_iff_of_neg hs).mp hdiv
    simp_all
    linarith
  exact c.dc _ q ⟨hcalc, hq⟩
</code></pre>
<p>We then define the set of all <code>n</code> such that t + ns ∈ c.A. For subsequent steps to work, we need to instantiate this set as decidable. This can be done using Classical logic, in which propositions are considered decidable by default.</p>
<pre><code class="language-lean">def Svals (c : DCut) (s t : ℚ) : Set ℕ := {n : ℕ | t + n * s ∈ c.A}

noncomputable
instance s_dec {c : DCut} {s t : ℚ}  : DecidablePred (· ∈ Svals c s t) := by
    intro n
    apply Classical.propDecidable
</code></pre>
<p>With <code>Svals</code> decidiable and nonempty, we can use <code>Nat.find</code> to show it has a minimal element. Note that <code>Nat.find</code> uses the Axiom of Choice.</p>
<pre><code class="language-lean">theorem min_element (S : Set ℕ) [DecidablePred (· ∈ S)] (h : ∃ x, x ∈ S)
  : ∃ m, m ∈ S ∧ (∀ k &lt; m, k ∉ S) := by
  have hsne : S.Nonempty := h
  let m := Nat.find hsne
  have hm : m ∈ S := Nat.find_spec hsne
  have hm_min : ∀ k &lt; m, k ∉ S := λ k =&gt; Nat.find_min hsne
  exact ⟨ m, hm, hm_min ⟩
</code></pre>
<p>We use the minimal element to find <code>n</code> so that  <code>t + (n+1)q ∈ c.A</code> and <code>t + nq ∉ c.A</code>. as desired.</p>
<pre><code class="language-lean">theorem archimedean {c : DCut} {s t : ℚ} (ht : t ∉ c.A) (hs : s &lt; 0)
  : ∃ n : ℤ, t+n*s ∉ c.A ∧ t+(n+1)*s ∈ c.A := by

  let S := Svals c s t
  have ⟨ m, hm, hm_min ⟩ := min_element S (cut_element c s t hs)

  by_cases h : m = 0

  · simp [h, S, Svals] at hm
    contradiction

  · use m - 1
    have hm' : m &gt; 0 := Nat.zero_lt_of_ne_zero h

    apply And.intro
    · have := hm_min (m-1) (Nat.sub_one_lt_of_lt hm')
      simp_all[S,Svals]
    · simp
      assumption
</code></pre>
<p>Finally, we prove the desired theorem.</p>
<pre><code class="language-lean">theorem neg_add_cancel_right {c : DCut} : c - c = 0 := by

  ext q
  constructor

  . simp[hsub_inst,neg_inst,neg,sub,hadd_inst,sum,preneg]
    intro ⟨ x, ⟨ hx, ⟨ y, ⟨ hy, hxy ⟩ ⟩ ⟩ ⟩
    obtain ⟨ a, ⟨ ha, ⟨ b, ⟨ hb, hab ⟩ ⟩ ⟩ ⟩ := hy
    have h1 : q ∈ A 0 ↔ q &lt; 0 := Set.mem_def
    simp[h1]
    have h2 := a_lt_b hx hb
    linarith

  . intro hq
    have hq : q &lt; 0 := hq
    obtain ⟨ t, ht ⟩ := c.nf
    obtain ⟨ n, ⟨ hn1, hn2 ⟩ ⟩ := archimedean ht hq

    let b' := t + (n+1)*q
    let a' := -n*q-t

    obtain ⟨ z, ⟨ hz, hbz ⟩ ⟩ := c.op b' hn2
    let ε := z - b'
    have hε : 0 &lt; ε := by simp[ε]; linarith

    let b := z
    let a := -n*q-t-ε

    have hab : z+a = q := by
      simp[a,a',b,b',ε]
      linarith

    have ha : a ∈ (-c).A := by
      use -ε
      apply And.intro
      . linarith
      . use -a-ε
        apply And.intro
        . simp[a]
          exact hn1
        . linarith

    exact ⟨ z, ⟨ hz, ⟨ a, ⟨ ha, hab ⟩ ⟩ ⟩ ⟩
</code></pre>
<p>And by commutativity:</p>
<pre><code class="language-lean">theorem neg_add_cancel_left {c : DCut} : -c + c = 0 := by
  rw[sum_comm,add_neg,neg_add_cancel_right]
</code></pre>
<h2 id="additive-group-structure"><a class="header" href="#additive-group-structure">Additive Group Structure</a></h2>
<pre><code class="language-lean">instance add_group_inst : AddGroup DCut :=
  AddGroup.ofLeftAxioms add_assoc @sum_zero_left @neg_add_cancel_left

instance add_comm_group_inst : AddCommGroup DCut := ⟨ @sum_comm ⟩

example (x y z : DCut) : x - y + z = z + x - y := by abel

instance add_monoid_wo_inst : AddMonoidWithOne DCut := ⟨
    by
      ext q
      exact ⟨ id, id ⟩,
    by
      intro n
      ext q
      constructor
      repeat
      . intro hq
        simp_all[add_rats,nat_cast_inst]
        exact hq
  ⟩
</code></pre>
<h2 id="useful-properties"><a class="header" href="#useful-properties">Useful properties</a></h2>
<pre><code class="language-lean">theorem add_preserves_le { a b: DCut} (c:DCut): a ≤ b → a + c ≤ b + c := by
  intro h q ⟨ x, ⟨ hx, ⟨ y, ⟨ hy, h' ⟩ ⟩ ⟩ ⟩
  exact ⟨ x, ⟨ h hx, y, ⟨ hy, h' ⟩ ⟩ ⟩

theorem negate_le { x : DCut } : 0 ≤ x ↔ -x ≤ 0 := by
  constructor
  . intro h
    have := add_preserves_le (-x) h
    simp at this
    exact this
  . intro h
    have := add_preserves_le x h
    simp at this
    exact this

theorem negate_le' { x : DCut } : 0 ≤ -x ↔ x ≤ 0 := by
  constructor
  . intro h
    have := add_preserves_le x h
    simp at this
    exact this
  . intro h
    have := add_preserves_le (-x) h
    simp at this
    exact this

theorem neg_sum_eq {a b c: DCut} : a = b+c ↔ -a = -b + -c := by
 constructor
 repeat
 intro h
 apply neg_inj.mp
 simp[h,add_comm]


theorem neg_of_rat {x : ℚ} : -ofRat x = ofRat (-x) := by
  simp[ofRat,neg_inst,neg,preneg,odown]
  ext q
  constructor
  . choose a ha b hb h
    simp_all
    linarith
  . intro hq
    simp_all
    use! q+x, (by linarith), x, (by linarith)
    linarith

theorem sub_rats {x y: ℚ} : ofRat (x-y) = ofRat x - ofRat y := by
  rw[←add_neg,neg_of_rat,Rat.sub_eq_add_neg,add_rats]
</code></pre>
<div style='height=50px'>&nbsp;</div><hr>
Copyright © 2025 Eric Klavins
<div style="break-before: page; page-break-before: always;"></div><div style='display:none'>
--  Copyright (C) 2025  Eric Klavins
--
--  This program is free software: you can redistribute it and/or modify
--  it under the terms of the GNU General Public License as published by
--  the Free Software Foundation, either version 3 of the License, or
--  (at your option) any later version.   
</div>
<p><span style='color: orange'><em><strong>UNDER CONSTRUCTION</strong></em></span><br>
<span style='color: lightgray; font-size: 10pt'><a href='https://github.com/klavins/LeanBook/blob/main/main/../LeanBook/Chapters/Reals/Max.lean'>Code</a> for this chapter</span></p>
<h1 id="the-maximum-operator"><a class="header" href="#the-maximum-operator">The Maximum Operator</a></h1>
<pre><code class="language-lean">theorem neg_gt_zero {a : DCut} (ha : a &lt; 0) : 0 &lt; -a := by

  simp[lt_inst]
  apply And.intro

  . intro h
    obtain ⟨ h1, h2 ⟩ := ha
    exact h1 h

  . intro q hq
    simp[zero_rw,odown] at hq
    simp[neg_inst,neg,preneg]
    obtain ⟨ b, hb ⟩ := a.nf
    exact ⟨ q, ⟨ hq, ⟨ 0, ⟨ zero_notin_neg ha, Eq.symm (sub_zero q) ⟩ ⟩ ⟩ ⟩

theorem maximum_ne {a b : DCut} : ∃ q, q ∈ a.A ∪ b.A := by
  obtain ⟨ x, hx ⟩ := a.ne
  use x
  exact Set.mem_union_left b.A hx

theorem maximum_nf {a b : DCut} : ∃ q, q ∉ a.A ∪ b.A := by
  obtain ⟨ x, hx ⟩ := a.nf
  obtain ⟨ y, hy ⟩ := b.nf
  apply Or.elim (trichotomy a b)
  . intro h
    simp_all
    use y
    apply And.intro
    . intro h1
      exact hy (h h1)
    . exact hy
  . intro h
    apply Or.elim h
    . intro h1
      simp[h1]
      use y
    . intro h1
      simp[h1]
      use x
      exact ⟨ hx, fun a ↦ hx (h1 a) ⟩

theorem maximum_dc {a b : DCut} : ∀ (x y : ℚ), x ≤ y ∧ y ∈ a.A ∪ b.A → x ∈ a.A ∪ b.A := by
  intro x y ⟨ hx, hy ⟩
  apply Or.elim hy
  . intro h
    simp[h]
    exact Or.inl (a.dc x y ⟨ hx, h ⟩)
  . intro h
    simp[h]
    exact Or.inr (b.dc x y ⟨ hx, h ⟩)

theorem maximum_op {a b : DCut} : ∀ x ∈ a.A ∪ b.A, ∃ y ∈ a.A ∪ b.A, x &lt; y:= by
  intro x hx
  apply Or.elim hx
  . intro h
    obtain ⟨ q, ⟨ hq1, hq2 ⟩ ⟩ := a.op x h
    exact ⟨ q, ⟨ Set.mem_union_left b.A hq1, hq2 ⟩ ⟩
  . intro h
    obtain ⟨ q, ⟨ hq1, hq2 ⟩ ⟩ := b.op x h
    exact ⟨ q, ⟨ Set.mem_union_right a.A hq1, hq2 ⟩ ⟩

def maximum (a b : DCut) : DCut :=
 ⟨ a.A ∪ b.A, maximum_ne, maximum_nf, maximum_dc, maximum_op ⟩

instance max_inst : Max DCut := ⟨ maximum ⟩

theorem max_gz (a: DCut) : 0 ≤ maximum 0 a := by
  simp_all[le_inst,zero_rw,odown,maximum]

theorem max_sym {a b : DCut} : maximum a b = maximum b a := by
  simp[maximum,Set.union_comm]

@[simp]
theorem max_pos {a : DCut} : 0 ≤ a → maximum 0 a = a := by
  simp[maximum,le_inst,DCut.ext_iff]

@[simp]
theorem max_neg {a : DCut} : a ≤ 0 → maximum 0 a = 0 := by
  simp[maximum,le_inst,DCut.ext_iff]

@[simp]
theorem max_pos_lt {a : DCut} : 0 &lt; a → maximum 0 a = a := by
   simp[maximum,lt_inst,DCut.ext_iff]

@[simp]
theorem max_neg_lt {a : DCut} : a &lt; 0 → maximum 0 a = 0 := by
   simp[maximum,lt_inst,DCut.ext_iff]

@[simp]
theorem max_self {a : DCut} : maximum a a = a := by
   simp[maximum,lt_inst,DCut.ext_iff]

@[simp]
theorem max_pos_to_neg {a: DCut} (ha : 0 &lt; a) : maximum 0 (-a) = 0 := by
  simp[maximum,lt_inst,DCut.ext_iff,neg_inst,neg,preneg,zero_rw,odown]
  intro x y hy z hz hxyz
  have ⟨ q, ⟨ hq1, hq2 ⟩ ⟩ := non_neg_in_pos ha
  have := a_lt_b hq1 hz
  linarith

theorem neg_lt {a : DCut}: 0 &lt; a ↔ -a &lt; 0 := by
  constructor
  . simp_all[lt_inst]
    intro h1 h2
    apply And.intro
    . intro h
      exact h1 (Eq.symm h)
    . intro x ⟨ q, ⟨ hq, ⟨ r, ⟨ hr, hqr ⟩ ⟩ ⟩ ⟩
      have h4 := a_lt_b (h2 hq) hr
      simp[zero_rw,odown]
      linarith
  . intro ⟨ h1, h2 ⟩
    apply And.intro
    . exact id (Ne.symm (neg_ne_zero.mp h1))
    . by_contra h
      have ⟨ z, ⟨ hz1, hz2 ⟩ ⟩ := Set.not_subset.mp h
      simp[neg_inst,neg,preneg,zero_rw,odown] at h2
      have := h2 0 z hz1 z hz2 (by linarith)
      simp at this

theorem neg_le {a : DCut} : 0 ≤ a ↔ -a ≤ 0 := by
  simp[le_of_lt,@neg_lt a,eq_comm]

theorem neg_lt' {a : DCut} : a &lt; 0 ↔ 0 &lt; -a := by

  constructor
  . intro ⟨ h1, h2 ⟩
    apply And.intro
    . simp[DCut.ext_iff] at h1 ⊢
      exact h1
    . intro q hq
      simp[neg_inst,neg,preneg]
      simp[zero_rw,odown] at hq
      have : 0 ∉ a.A := by
        intro h
        have := h2 h
        simp[zero_rw,odown] at this
      exact ⟨ q, ⟨ hq, ⟨ 0, ⟨ this, by linarith ⟩ ⟩ ⟩ ⟩
  . simp[lt_inst]
    intro ha h
    apply And.intro
    . exact ha
    . by_contra hnq
      have ⟨ z, ⟨ hz1, hz2 ⟩ ⟩ := Set.not_subset.mp hnq
      simp[neg_inst,neg,preneg,zero_rw,odown] at h hz2
      have ⟨ s, ⟨ hs1, hs2 ⟩ ⟩ := a.op z hz1
      have ⟨ q, ⟨ hq, ⟨ r, ⟨ hr1, hr2 ⟩ ⟩ ⟩ ⟩ := h (-s) (by linarith)
      have : s &lt; r := by exact a_lt_b hs1 hr1
      linarith

theorem neg_le' {a : DCut} : a ≤ 0 ↔ 0 ≤ -a := by
  simp[le_of_lt,@neg_lt' a,eq_comm]

theorem pos_neg_sum {a : DCut} : a = maximum 0 a - maximum 0 (-a) := by
  by_cases h : 0 &lt; a
  . rw[max_pos h.right]
    rw[max_neg (neg_le.mp h.right)]
    exact Eq.symm (sub_zero a)
  . have := trichotomy_lt 0 a
    simp[not_gt_to_le] at h
    apply Or.elim this
    . intro h'
      rw[max_pos_lt h']
      have := neg_lt.mp h'
      rw[max_neg_lt this]
      simp
    . intro h'
      rw[max_neg h]
      have := neg_le'.mp h
      rw[max_pos this]
      simp

@[simp]
theorem neg_max_zero_neg {a : DCut} (ha : a ≤ 0) : -maximum 0 (-a) = a := by
   have : 0 ≤ -a := by
     rw[neg_le'] at ha
     exact ha
   simp[max_pos,this]
</code></pre>
<div style='height=50px'>&nbsp;</div><hr>
Copyright © 2025 Eric Klavins
<div style="break-before: page; page-break-before: always;"></div><div style='display:none'>
--  Copyright (C) 2025  Eric Klavins
--
--  This program is free software: you can redistribute it and/or modify
--  it under the terms of the GNU General Public License as published by
--  the Free Software Foundation, either version 3 of the License, or
--  (at your option) any later version.   
</div>
<p><span style='color: orange'><em><strong>UNDER CONSTRUCTION</strong></em></span><br>
<span style='color: lightgray; font-size: 10pt'><a href='https://github.com/klavins/LeanBook/blob/main/main/../LeanBook/Chapters/Reals/Multiply.lean'>Code</a> for this chapter</span></p>
<h1 id="multiplication"><a class="header" href="#multiplication">Multiplication</a></h1>
<p>Multiplication of Dedekind cuts is straightfoward, but also fairly involved, or as Rudin says: "bothersome". The issue is dealing with both positive and negative cuts. Following Rudin, the development of the definitions proceeds as follows:</p>
<ul>
<li>Define multiplication on positive cuts.</li>
<li>Extend multiplciation on positive cuts to non-negative cuts, building on the previous step by handling the cases in which either or both of the cuts is zero.</li>
<li>Extend multiplication on non-negative cuts to all cuts.</li>
</ul>
<p>For each of the above definitions of multiplication, we also prove the properties required to show that multiplication forms a commutiative group on cuts:</p>
<ul>
<li>0 is an identity: <code>0*x = 0</code></li>
<li>Multiplication is commutative: <code>x*y = y*x</code></li>
<li>Associativity: <code>x*(y*z) = (x*y)*z</code>
The last property is particularly challenging, because to relate arbitary reals with positive reals, one has to deal with an abundance of cases, preferably gracefully. Thus, along the way we will prove several intermediate results which allow us to make the proof more concise.</li>
</ul>
<h2 id="definitions-1"><a class="header" href="#definitions-1">Definitions</a></h2>
<h3 id="multiplication-of-positive-cuts"><a class="header" href="#multiplication-of-positive-cuts">Multiplication of Positive Cuts</a></h3>
<p>Given two positive cuts <code>0 &lt; a</code> and <code>0 &lt; b</code>, their product is the set of points <code>z</code> such that for some <code>x ∈ a</code> and <code>y ∈ b</code>, <code>z &lt; x*y</code>. This basic definition underlies the entire framework for multiplication, after which we simply have to deal with various combinations of non-negative and negative numbers.</p>
<pre><code class="language-lean">def pre_mul (a b : DCut) :=
  { z | ∃ x ∈ a.A, ∃ y ∈ b.A, 0 &lt; x ∧ 0 &lt; y ∧ z &lt; x*y }
</code></pre>
<p>To make some proofs more readable, it is useful to characterize pre_mul the following sufficient condition.</p>
<pre><code class="language-lean">theorem pre_mul_suffice {a b : DCut} {x y z : ℚ}
  : x ∈ a.A → y ∈ b.A → 0 &lt; x → 0 &lt; y → z &lt; x*y → z ∈ pre_mul a b := by
  intro hx hy _ _ _
  use x, hx, y, hy
</code></pre>
<p>To prove that this definition results in a cut, we need to prove as usual that it is non-empty, not equal to ℚ, downward closed, and open.</p>
<p>First, we show <code>pre_mul a b</code> is non-empty, by showing that it contains <code>0</code>. Since <code>a</code> and <code>b</code> are positive, they contain <code>0</code>. By the <code>op</code> property, <code>a</code> and <code>b</code> must also contain values <code>x</code> and <code>y</code> larger than zero. Then 0 &lt; x*y as well, satisfying the definition.</p>
<pre><code class="language-lean">theorem pre_mul_ne {a b : DCut} (ha : 0 &lt; a) (hb : 0 &lt; b) : ∃ q, q ∈ pre_mul a b := by

  have ⟨ x, ⟨ hx1, hx2 ⟩ ⟩ : ∃ x ∈ a.A, 0 &lt; x := a.op 0 (zero_in_pos ha)
  have ⟨ y, ⟨ hy1, hy2 ⟩ ⟩ : ∃ y ∈ b.A, 0 &lt; y := b.op 0 (zero_in_pos hb)
  use 0
  apply pre_mul_suffice hx1 hy1 hx2 hy2
  nlinarith
</code></pre>
<p>To show <code>pre_mul a b</code> is not <code>ℚ</code>, we choose <code>x</code> and <code>y</code> not in <code>a</code> and <code>b</code> respectively and show that <code>x*y</code>is bigger than every value in in <code>pre_mul a b</code>. Although this proof does not require that <code>a</code> and <code>b</code> are positive, we include these conditions anyway for consistency.</p>
<pre><code class="language-lean">theorem pre_mul_nf {a b : DCut} (_ : 0 &lt; a) (_ : 0 &lt; b)
  : ∃ q, q ∉ pre_mul a b := by
  obtain ⟨ x, ⟨ hx, hx' ⟩ ⟩ := has_ub a
  obtain ⟨ y, ⟨ hy, hy' ⟩ ⟩ := has_ub b
  use x*y
  apply ub_to_notin
  intro q hq
  choose s hs t ht hs0 ht0 hqst using hq
  nlinarith[hx' s hs, hy' t ht]
</code></pre>
<p>That <code>pre_mul a b</code> is downward closed is results from a straightforward unpacking of the definitions.</p>
<pre><code class="language-lean">theorem pre_mul_dc {a b : DCut}
  : ∀ x y, x ≤ y ∧ y ∈ (pre_mul a b) → x ∈ (pre_mul a b) := by
  intro x y ⟨ hxy, hy ⟩
  obtain ⟨ s, ⟨ hs, ⟨ t, ⟨ ht, ⟨ hsp, ⟨ htp, hyst ⟩ ⟩ ⟩ ⟩ ⟩ ⟩ := hy
  exact pre_mul_suffice hs ht hsp htp (lt_of_le_of_lt hxy hyst)
</code></pre>
<p>To show <code>pre_mul a b</code> is open, we start with values <code>s</code> and <code>t</code> in <code>a</code> and <code>b</code> respectively. Since <code>a</code> and <code>b</code> are open, we obtain values <code>s'</code> and <code>t'</code> in that are greater that <code>s</code> and <code>t</code> and still in <code>a</code> and <code>b</code>. Then <code>s*t &lt; s'*t'</code> as required.</p>
<pre><code class="language-lean">theorem pre_mul_op {a b : DCut}
  : ∀ x ∈ (pre_mul a b), ∃ y ∈ (pre_mul a b), x &lt; y := by
  intro x ⟨ s, ⟨ hs, ⟨ t, ⟨ ht, ⟨ hsp, ⟨ htp, hyst ⟩ ⟩ ⟩ ⟩ ⟩ ⟩
  have ⟨ s', ⟨ hs', hss' ⟩ ⟩ := a.op s hs
  have ⟨ t', ⟨ ht', htt' ⟩ ⟩ := b.op t ht
  have h: s*t &lt; s'*t' := by nlinarith
  use! s*t, s', hs', t', ht'
  split_ands
  repeat
  linarith
</code></pre>
<p>Grouping these properties together we have a proof that this definition of multiplication results in a proper cut.</p>
<pre><code class="language-lean">def mul_pos (a b : DCut) (ha : 0 &lt; a) (hb : 0 &lt; b) : DCut :=
  ⟨ pre_mul a b, pre_mul_ne ha hb, pre_mul_nf ha hb, pre_mul_dc, pre_mul_op ⟩
</code></pre>
<p>We will need the following property to extend multiplication from positive numbers to non-negative numbers stating that the product of two positive numbers is again positive. Thus, the definition <code>pre_mul</code> operates exclusively on the positive reals.</p>
<pre><code class="language-lean">theorem zero_in_pre_mul  {a b : DCut} (ha : 0 &lt; a) (hb : 0 &lt; b)
  : 0 ∈ pre_mul a b  := by
  have ⟨ x, ⟨ hx1, hx2 ⟩ ⟩ := non_neg_in_pos ha
  have ⟨ y, ⟨ hy1, hy2 ⟩ ⟩ := non_neg_in_pos hb
  use! x, hx1, y, hy1, hx2, hy2
  nlinarith

theorem mul_is_pos {a b : DCut} (ha : 0 &lt; a) (hb : 0 &lt; b)
  : 0 &lt; mul_pos a b ha hb := by
  apply pos_has_zero.mpr
  exact zero_in_pre_mul ha hb
</code></pre>
<h3 id="multiplication-on-non-negative-cuts"><a class="header" href="#multiplication-on-non-negative-cuts">Multiplication on Non-negative Cuts</a></h3>
<p>We now extend the definition to non-negative reals, essentially dealing with the cases in which either cut is zero, in which case the resulting product is zero. Indeed, if one of <code>a</code> and <code>b</code> is zero, then <code>pre_mul a b = ∅</code>.</p>
<pre><code class="language-lean">example {A : Set ℕ}: A ⊆ ∅ ↔ A = ∅ := by exact Set.subset_empty_iff

@[simp]
theorem zero_mul_empty {a b : DCut} (h : 0 = a ∨ 0 = b) : pre_mul a b = ∅ := by
  rcases h with h | h
  repeat
  . simp[pre_mul,←h,zero_rw,odown]
    ext
    simp
    intros
    linarith
</code></pre>
<p>Since <code>∅</code> is not a valid cut, we use <code>pre_mul a b ∪ odown 0</code> to represent the product of two non-negative cuts. Of course, if <code>a</code> and <code>b</code> are positive cuts, then <code>pre_mul a b</code> is downward closed, so the union with <code>odown 0</code> is not needed.</p>
<pre><code class="language-lean">@[simp]
theorem non_zero_mul_subsume {a b : DCut} (ha : 0 &lt; a) (hb : 0 &lt; b)
  : pre_mul a b ∪ odown 0 = pre_mul a b := by
  simp_all[lt_inst]
  exact lt_imp_le (mul_is_pos ha hb)
</code></pre>
<p>The usual theorems are required to show that the product is a cut. We simply have to deal with the possible cases.</p>
<pre><code class="language-lean">theorem mul_nneg_ne {a b : DCut}
  : ∃ q, q ∈ pre_mul a b ∪ odown 0 := by
  use -1
  apply Or.inr
  simp[odown]

theorem mul_nneg_nf {a b : DCut} (ha : 0 ≤ a) (hb : 0 ≤ b)
  : ∃ q, q ∉ pre_mul a b ∪ odown 0 := by
  rcases two_nn_ineqs ha hb with ⟨ ha, hb ⟩ | h | h
  . simp[pre_mul_nf,ha,hb]
  repeat
  . simp[h,odown]
    exact ⟨ 1, rfl ⟩

theorem mul_nneg_dc {a b : DCut} {x y : ℚ}
  : x ≤ y ∧ y ∈ pre_mul a b ∪ odown 0 → x ∈ pre_mul a b ∪ odown 0 := by
  intro ⟨ h1, h2 ⟩
  apply Or.elim h2
  . intro hy
    apply Or.inl
    exact pre_mul_dc x y ⟨ h1, hy ⟩
  . intro hy
    apply Or.inr
    exact odown_dc x y ⟨ h1, hy ⟩

theorem mul_nneg_op {a b : DCut} (x : ℚ) :
  x ∈ pre_mul a b ∪ odown 0 → ∃ y ∈ pre_mul a b ∪ odown 0, x &lt; y := by
  intro h
  apply Or.elim h
  . intro hx
    have ⟨ q, ⟨ hq1, hq2 ⟩ ⟩ := pre_mul_op x hx
    use q
    exact ⟨ Or.inl hq1, hq2 ⟩
  . intro hx
    use x/2
    simp_all[odown]
    exact ⟨ Or.inr (by linarith), by linarith ⟩

def mul_nneg (a b : DCut) (ha : 0 ≤ a) (hb : 0 ≤ b) : DCut :=
  ⟨ pre_mul a b ∪ odown 0,
    mul_nneg_ne,
    mul_nneg_nf ha hb,
    @mul_nneg_dc a b,
    @mul_nneg_op a b ⟩
</code></pre>
<p>We note that when <code>a</code> and <code>b</code> are positive cuts, that <code>mul_nneg</code> agrees with <code>mul_pos</code>.</p>
<pre><code class="language-lean">theorem nneg_eq_pos {a b : DCut} (ha : 0 &lt; a) (hb : 0 &lt; b)
  : mul_nneg a b (lt_imp_le ha) (lt_imp_le hb) = mul_pos a b ha hb := by
  simp_all[mul_is_pos,ha,hb,mul_nneg,mul_pos]
</code></pre>
<h3 id="mulitiplication-on-arbitrary-cuts"><a class="header" href="#mulitiplication-on-arbitrary-cuts">Mulitiplication on Arbitrary Cuts</a></h3>
<p>Finally, we extend multiiplcation to arbitrary cuts. This step uses the fact that every cut <code>a</code> can be written as the difference <code>max 0 a - max 0 (-a)</code>. If <code>0 ≤ a</code> then</p>
<pre><code class="language-hs">max 0 a - max 0 (-a) = a + 0
</code></pre>
<p>and if <code>a &lt; 0</code> then</p>
<pre><code class="language-hs">max 0 a - max 0 (-a) = 0 + -a
</code></pre>
<p>both of which are non-negative, and we can therefore use the previous definition of multiplication on non-negative cuts.</p>
<pre><code class="language-lean">def mul (a b : DCut) : DCut :=
  let ap := maximum 0 a
  let an := maximum 0 (-a)
  let bp := maximum 0 b
  let bn := maximum 0 (-b)
  (mul_nneg ap bp (max_gz _) (max_gz _)) +
  (mul_nneg an bn (max_gz _) (max_gz _)) -
  (mul_nneg ap bn (max_gz _) (max_gz _)) -
  (mul_nneg an bp (max_gz _) (max_gz _))
</code></pre>
<p>We may now instantiate the notation classes for multiplcation.</p>
<pre><code class="language-lean">instance hmul_inst : HMul DCut DCut DCut := ⟨ mul ⟩
instance mul_inst : Mul DCut := ⟨ mul ⟩

example : (1:DCut) * 0 = 0 := by
  simp[hmul_inst,mul]
</code></pre>
<h2 id="multiplication-by-0"><a class="header" href="#multiplication-by-0">Multiplication by 0</a></h2>
<p>For non-negative cuts, it is useful to know that <code>0*a = 0</code> and <code>a*0 = 0</code>, as these properties allow us to reason about the zero cases in the non-negative commutativity proof. These properties also allow us to show that <code>0</code> is the multiplicative identity, which is needed for proving cuts with multiplication form a group.</p>
<pre><code class="language-lean">@[simp]
theorem mul_nneg_zero_left {a : DCut} (ha: 0 ≤ a)
  : mul_nneg 0 a (λ _ a =&gt; a) ha = 0 := by
  simp[mul_nneg,DCut.ext_iff,zero_rw]

@[simp]
theorem mul_nneg_zero_right {a : DCut} (ha: 0 ≤ a)
  : mul_nneg a 0 ha (λ _ a =&gt; a) = 0 := by
  simp[mul_nneg,DCut.ext_iff,zero_rw]
</code></pre>
<p>These two theorems allow us to prove that the multiple of two non-negative cuts is again non-negative.</p>
<pre><code class="language-lean">@[simp]
theorem mul_is_nneg {a b : DCut} (ha : 0 ≤ a) (hb : 0 ≤ b)
  : 0 ≤ mul_nneg a b ha hb := by
  rcases two_nn_ineqs ha hb with ⟨ ha, hb ⟩ | h | h
  . rw[nneg_eq_pos ha hb]
    exact lt_imp_le (mul_is_pos ha hb)
  repeat
  . simp[←h]
    simp_all[lt_of_le]
</code></pre>
<p>We can extend these properties to arbitrary cuts.</p>
<pre><code class="language-lean">@[simp]
theorem mul_zero_left {a : DCut} : 0 * a = 0 := by
  simp[hmul_inst,mul]

@[simp]
theorem mul_zero_right {a : DCut} : a * 0 = 0 := by
  simp[hmul_inst,mul]

instance mul_zero_inst : MulZeroClass DCut := ⟨
    @mul_zero_left,
    @mul_zero_right
  ⟩
</code></pre>
<h2 id="commutativity"><a class="header" href="#commutativity">Commutativity</a></h2>
<p>For positive cuts, commutativity is straightfoward, as it simply amounts to reordering x and y in the definition of <code>pre_mul</code>.</p>
<pre><code class="language-lean">theorem mul_pos_comm {a b : DCut} (ha : 0 &lt; a) (hb : 0 &lt; b)
  : mul_pos a b ha hb = mul_pos b a hb ha  := by
  ext q
  constructor
  repeat
  . intro ⟨ x, ⟨ hx, ⟨ y, ⟨ hy, ⟨ h1, ⟨ h2, h3 ⟩ ⟩ ⟩ ⟩ ⟩ ⟩
    exact ⟨ y, ⟨ hy, ⟨ x, ⟨ hx, ⟨ h2, ⟨ h1, by linarith ⟩ ⟩ ⟩ ⟩ ⟩ ⟩
</code></pre>
<p>Proving commutativity for non-negative cuts amounts to three cases, where <code>a</code> and <code>b</code> are both positive and where one or the other is negative.</p>
<pre><code class="language-lean">theorem mul_nneg_comm {a b : DCut} (ha : 0 ≤ a) (hb : 0 ≤ b)
  : mul_nneg a b ha hb = mul_nneg b a hb ha := by

  rcases two_nn_ineqs ha hb with ⟨ ha, hb ⟩ | h | h
  . simp[mul_nneg]
    have := mul_pos_comm ha hb
    simp_all[mul_pos]
  repeat
  . simp[h]
</code></pre>
<p>The proof of commutativity for arbitrary cuts requires us to reason about every possible combination of non-negative and negative cuts. We do this with the theorem <code>two_ineqs_true</code> which enuerates all four cases. For each case, the same simplificiation works.</p>
<pre><code class="language-lean">theorem mul_comm {a b : DCut}: a*b = b*a := by
  rcases two_ineqs a b with ⟨ ha, hb ⟩ | ⟨ ha, hb ⟩ | ⟨ ha, hb ⟩ | ⟨ ha, hb ⟩
  repeat
  simp[ha,hb,hmul_inst,mul,mul_nneg_comm,neg_le.mp]
</code></pre>
<h2 id="multiplication-by-1"><a class="header" href="#multiplication-by-1">Multiplication by 1</a></h2>
<p>The proof that <code>1*x=x</code> is split into three main steps for positive, non-negative, and arbitary cuts. For positive cuts, the proof is split into two parts that show <code>1*a ≤ a</code> and <code>a*1 ≤ 1</code> respectively. The first direction is straightforward, and uses the fact that <code>a</code> is downward closed.</p>
<pre><code class="language-lean">theorem mul_pos_id_left_1 {a : DCut} (ha: 0 &lt; a)
  : mul_pos 1 a zero_lt_one ha ≤ a := by
  intro q ⟨ x, ⟨ hx, ⟨ y, ⟨ hy, ⟨ hx0, ⟨ hy0, hqxy ⟩ ⟩ ⟩ ⟩ ⟩ ⟩
  apply a.dc q (x*y)
  split_ands
  . linarith
  . have hxy : x*y &lt; y := mul_lt_of_lt_one_left hy0 hx
    exact a.dc (x*y) y ⟨ by linarith, hy ⟩
</code></pre>
<p>For the other direction, we assume we have <code>q ∈ a.A</code> and need to show <code>q</code> is in <code>mul_pos 1 a</code>. This is done differently depending on whether <code>q</code> is positive or non-negative. For the first case, we use the fact that <code>a.A</code> is open to find <code>s</code> and <code>t</code> in <code>a.A</code> with <code>q &lt; s &lt; t</code>. Then <code>q &lt; s*t</code> as required. For <code>q</code> non-negative, we use the fact that <code>0 ∈ a.A</code> and find <code>s ∈ a.A</code> with <code>0&lt;s</code>. We also have <code>1/2 ∈ odown 1</code>. Then <code>q &lt; s*(1/2)</code> as required.</p>
<pre><code class="language-lean">theorem mul_pos_id_left_2 {a : DCut} (ha: 0 &lt; a)
  : a ≤ mul_pos 1 a zero_lt_one ha := by
  intro q hq
  simp[mul_pos]
  by_cases h : 0 &lt; q
  . have ⟨ s, ⟨ t, ⟨ hx, ⟨ ht1, ⟨ hsq, st ⟩ ⟩ ⟩ ⟩ ⟩ := op2 q hq
    have hs3 : 0 &lt; s := by linarith
    refine pre_mul_suffice ?_ ht1 (div_pos h hs3) ?_ ?_
    . apply in_one
      exact Bound.div_lt_one_of_pos_of_lt hs3 (by linarith)
    . linarith
    . have hts : t/s &gt; 1 := (one_lt_div hs3).mpr (by linarith)
      have hqts : q*(t/s) = q / s * t := Eq.symm (mul_comm_div q s t)
      nlinarith
  . have ⟨s, ⟨ hs1, hs2 ⟩ ⟩ := a.op 0 (zero_in_pos ha)
    refine pre_mul_suffice ?_ hs1 one_half_pos hs2 ?_
    . apply in_one
      linarith
    . linarith
</code></pre>
<p>Combining the above inequalities gives the main result for positive cuts.</p>
<pre><code class="language-lean">@[simp]
theorem mul_pos_id_left {a : DCut} (ha: 0 &lt; a)
  : mul_pos 1 a zero_lt_one ha = a := by
  apply PartialOrder.le_antisymm
  . exact mul_pos_id_left_1 ha
  . exact mul_pos_id_left_2 ha
</code></pre>
<p>For non-negative cuts, we consider the cases where <code>0 = a</code> and <code>0 &lt; a</code> separately.</p>
<pre><code class="language-lean">@[simp]
theorem mul_nneg_id_left {a : DCut} (ha: 0 ≤ a)
  : mul_nneg 1 a zero_le_one ha = a := by
    rw[le_of_lt] at ha
    rcases ha with h1 | h2
    . simp[←h1]
    . have := mul_pos_id_left h2
      simp_all[mul_pos,DCut.ext_iff,mul_nneg,DCut.ext_iff]
      exact ha
</code></pre>
<p>Commutativity makes it easy to prove similar versions of theorems for which one side has already been established. For example:</p>
<pre><code class="language-lean">@[simp]
theorem mul_nneg_id_right {a : DCut} (ha: 0 ≤ a)
  : mul_nneg a 1 ha zero_le_one = a := by
  rw[mul_nneg_comm,mul_nneg_id_left]
</code></pre>
<p>And similarly,</p>
<pre><code class="language-lean">@[simp]
theorem mul_id_right {a : DCut} : a * 1 = a := by
  simp only[hmul_inst,mul]
  by_cases ha : 0 &lt; a
  . simp[ha]
  . simp
    rw[not_gt_to_le] at ha
    simp[ha]

@[simp]
theorem mul_id_left {a : DCut} : 1 * a = a := by
  simp[mul_comm]
</code></pre>
<p>Mathlib includes a class that keeps track of these properties.</p>
<pre><code class="language-lean">instance mul_one_inst : MulOneClass DCut := ⟨
  @mul_id_left,
  @mul_id_right
⟩
</code></pre>
<h2 id="associativity"><a class="header" href="#associativity">Associativity</a></h2>
<p>The proof that <code>mul</code> is associatve amounts to a lot of book-keeping around some simple observations. We start with a proof that <code>mul_pos</code> is associatve, which has two directions to prove. Each uses the fact that the cuts are open.</p>
<pre><code class="language-lean">theorem mul_pos_assoc {a b c : DCut} (ha : 0 &lt; a) (hb : 0 &lt; b) (hc : 0 &lt; c)
  : mul_pos a (mul_pos b c hb hc) ha (mul_is_pos hb hc) =
    mul_pos (mul_pos a b ha hb) c (mul_is_pos ha hb) hc  := by

  ext q
  constructor

  . choose x hx yz h' hx0 hyz0 hq
    choose y hy z hz hy0 hz0 hyz' using h'
    obtain ⟨ x', ⟨ hx', hxx' ⟩ ⟩ : ∃ x' ∈ a.A, x &lt; x' := a.op x hx
    use x*y
    constructor
    . use! x', hx', y
      simp_all
      nlinarith
    . use z
      simp_all
      nlinarith

  . choose xy h' z hz hxy hx0 hq
    choose x hx y hy hz0 hy0 hxy' using h'
    have ⟨ z', ⟨ hz', hzz' ⟩ ⟩ : ∃ z' ∈ c.A, z &lt;z' := c.op z hz
    use! x, hx, y*z
    constructor
    . use y, hy, z'
      simp_all
      nlinarith
    . simp_all
      nlinarith
</code></pre>
<p>Extending this result to non-negative cuts requires reasoning about four cases, convenienly available through the <code>three_nn_ineqs</code> theorem.</p>
<pre><code class="language-lean">@[simp]
theorem mul_nneg_assoc {a b c : DCut} (ha : 0 ≤ a) (hb : 0 ≤ b) (hc : 0 ≤ c)
  : mul_nneg a (mul_nneg b c hb hc) ha (mul_is_nneg hb hc) =
    mul_nneg (mul_nneg a b ha hb) c (mul_is_nneg ha hb) hc := by

  rcases three_nn_ineqs ha hb hc with ⟨ ha', hb', hc' ⟩ | h | h | h

  . simp[mul_nneg]
    congr -- removes `∪ odown 0`
    simpa[mul_pos,ha',hb',hc'] using mul_pos_assoc ha' hb' hc'

  repeat
  . simp[h]
</code></pre>
<p>To prove associativity in general, it is tempting to look at 27 possible cases in which each of three cuts are positive, zero or negative. However, we can take advantage of some basic algebra to reduce the number of cases to eight. To proceed, note that when <code>a ≤ 0</code> while <code>0 ≤ b</code> and <code>0 ≤ c</code>, then</p>
<pre><code class="language-hs">(a*b)*c = a*(b*c)
</code></pre>
<p>becomes</p>
<pre><code class="language-hs">-((-a)*b)*c = -((-a)*(b*c))
</code></pre>
<p>and then use mul_assoc_all_nn. Similarly, we can do all the other cases this way.</p>
<pre><code class="language-lean">@[simp]
theorem mul_neg_dist_left {a b : DCut} : a*(-b) = -(a*b) := by
  simp[hmul_inst,mul]
  rcases two_ineqs a b with ⟨ ha, hb ⟩ | ⟨ ha, hb ⟩ | ⟨ ha, hb ⟩ | ⟨ ha, hb ⟩
  repeat
  simp[ha,hb,neg_le.mp]

@[simp]
theorem mul_neg_dist_right {a b : DCut} : (-a)*b = -(a*b) := by
  simp only[hmul_inst,mul]
  rcases two_ineqs a b with ⟨ ha, hb ⟩ | ⟨ ha, hb ⟩ | ⟨ ha, hb ⟩ | ⟨ ha, hb ⟩
  repeat
  simp[ha,hb,neg_le.mp]
</code></pre>
<p>To make the proof more readable, we rewrite the theorem for non-negative cuts in terms of arbitrary cuts.</p>
<pre><code class="language-lean">theorem mul_assoc_all_nn {a b c : DCut} (ha : 0 ≤ a) (hb : 0 ≤ b) (hc : 0 ≤ c)
  : a * (b * c) = (a * b) * c := by
  simp[hmul_inst,mul]
  simp[ha,hb,hc,neg_le.mp] -- uses mul_nneg_assoc
</code></pre>
<p>And we prove a simple theorem that allows us to flip the direction of an inequality involving a negative cut.</p>
<pre><code class="language-lean">theorem flip {a : DCut} (ha: a &lt; 0) : 0 ≤ -a := neg_le'.mp (lt_imp_le ha)
</code></pre>
<p>Finally, combining the above, we can use the simplifier, <code>flip</code> and  <code>mul_assoc_all_nn</code> to prove associativity for arbitrary cuts.</p>
<pre><code class="language-lean">theorem mul_assoc {a b c : DCut} : a * (b * c) = (a * b) * c := by
  rcases three_ineqs a b c with ⟨ ha, hb, hc ⟩ | ⟨ ha, hb, hc ⟩ |
                                ⟨ ha, hb, hc ⟩ | ⟨ ha, hb, hc ⟩ |
                                ⟨ ha, hb, hc ⟩ | ⟨ ha, hb, hc ⟩ |
                                ⟨ ha, hb, hc ⟩ | ⟨ ha, hb, hc ⟩
  . exact mul_assoc_all_nn ha hb hc
  . simpa using mul_assoc_all_nn (flip ha) hb hc
  . simpa using mul_assoc_all_nn ha (flip hb) hc
  . simpa using mul_assoc_all_nn ha hb (flip hc)
  . simpa using mul_assoc_all_nn (flip ha) (flip hb) hc
  . simpa using mul_assoc_all_nn (flip ha) hb (flip hc)
  . simpa using mul_assoc_all_nn ha (flip hb) (flip hc)
  . simpa using mul_assoc_all_nn (flip ha) (flip hb) (flip hc)
</code></pre>
<h2 id="instantiating-multiplication-classes"><a class="header" href="#instantiating-multiplication-classes">Instantiating Multiplication Classes</a></h2>
<p>With associatively and commutivity proved, we can show that multiplication forms a semigroup and a commutative magma.</p>
<pre><code class="language-lean">instance semigroup_inst : Semigroup DCut := ⟨
  λ x y z =&gt; Eq.symm (@mul_assoc x y z)
⟩

instance semigroup_w_zero_inst : SemigroupWithZero DCut := ⟨
  @mul_zero_left,
  @mul_zero_right
⟩

instance mul_zo_inst : MulZeroOneClass DCut := ⟨
  @mul_zero_left,
  @mul_zero_right
⟩

instance comm_magma_inst : CommMagma DCut := ⟨ @mul_comm ⟩

instance comm_semigroup_inst : CommSemigroup DCut := ⟨ @mul_comm ⟩
</code></pre>
<h2 id="natural-powers-and-monoid-instance"><a class="header" href="#natural-powers-and-monoid-instance">Natural Powers and Monoid Instance</a></h2>
<p>Mathlib's class structure that leads to instantiating a type as a field includes showing the type is a Monoid, which includes a method for raising a cut <code>x</code> to a natural numbered power, as in <code>x^n</code>. We define that method here.</p>
<pre><code class="language-lean">def npow (n: ℕ) (x : DCut) : DCut := match n with
  | Nat.zero =&gt; 1
  | Nat.succ k =&gt; x * (npow k x)
</code></pre>
<p>And show to obvious statements about such powers.</p>
<pre><code class="language-lean">theorem npow_zero {x : DCut} : npow 0 x = 1 := by rfl

theorem npow_succ {n : ℕ} {x : DCut} : npow (n+1) x = npow n x * x := by
  simp[npow,mul_comm]
</code></pre>
<p>Together these properties allow us to instante DCut as a Monoid, a Commutative Monoind, and a Commutative Monoid with zero.</p>
<pre><code class="language-lean">instance monoid_inst : Monoid DCut := ⟨
  @mul_id_left,
  @mul_id_right, -- why does this need to be here if this is already a MulOneClass?
  npow,
  @npow_zero,
  @npow_succ
⟩

instance com_monoid_inst : CommMonoid DCut := ⟨
  @mul_comm
⟩

instance monoid_wz_inst : MonoidWithZero DCut := ⟨
  @mul_zero_left,
  @mul_zero_right
⟩

instance comm_monoid_wz_inst : CommMonoidWithZero DCut := ⟨
  @mul_zero_left,
  @mul_zero_right
⟩
</code></pre>
<p>Here is a simple example that use a theorem about monoids from Mathlib.</p>
<pre><code class="language-lean">example (x : DCut) : x^2 = x*x := by
  exact pow_two x
</code></pre>
<h1 id="properties"><a class="header" href="#properties">Properties</a></h1>
<pre><code class="language-lean">theorem prod_in_pos_mul {a b : DCut} {x y: ℚ} (ha : 0 &lt; a) (hb : 0 &lt; b)
                        (hx : x ∈ a.A) (hy : y ∈ b.A) (hx0 : 0 &lt; x)
  : x*y ∈ (mul_pos a b ha hb).A := by
  obtain ⟨ x', ⟨ hx1', hx2' ⟩ ⟩ := a.op x hx
  obtain ⟨ y', ⟨ hy1', hy2' ⟩ ⟩ := op_from_two_vals hy (zero_in_pos hb)
  have hy' : 0 ≤ y' := by  linarith
  have hxy' : x * y &lt; x' * y' := by
    have h1 : 0 &lt; x' := by linarith
    have h2 : y ≤ y' := by linarith
    nlinarith
  exact ⟨ x', ⟨ hx1', ⟨ y', ⟨ hy1', ⟨ by linarith, ⟨ by linarith, hxy' ⟩ ⟩  ⟩ ⟩ ⟩ ⟩
</code></pre>
<div style='height=50px'>&nbsp;</div><hr>
Copyright © 2025 Eric Klavins
<div style="break-before: page; page-break-before: always;"></div><div style='display:none'>
--  Copyright (C) 2025  Eric Klavins
--
--  This program is free software: you can redistribute it and/or modify
--  it under the terms of the GNU General Public License as published by
--  the Free Software Foundation, either version 3 of the License, or
--  (at your option) any later version.   
</div>
<p><span style='color: orange'><em><strong>UNDER CONSTRUCTION</strong></em></span><br>
<span style='color: lightgray; font-size: 10pt'><a href='https://github.com/klavins/LeanBook/blob/main/main/../LeanBook/Chapters/Reals/Distributivity.lean'>Code</a> for this chapter</span></p>
<h1 id="the-distributive-property"><a class="header" href="#the-distributive-property">The Distributive Property</a></h1>
<pre><code class="language-lean">theorem pos_distrib {a b c : DCut} (ha : 0 &lt; a) (hb : 0 &lt; b) (hc : 0 &lt; c)
  : mul_pos a (sum b c) ha (sum_pos_pos hb hc) = sum (mul_pos a b ha hb) (mul_pos a c ha hc) := by

  ext q
  constructor

  . intro hq
    choose x hx yz hyz hx0 hyz0 hxyz using hq
    choose y hy z hz hyz using hyz
    rw[←hyz] at hxyz

    have hxy := prod_in_pos_mul ha hb hx hy hx0
    have hxz := prod_in_pos_mul ha hc hx hz hx0

    apply (sum (mul_pos a b ha hb) (mul_pos a c ha hc)).dc q (x*y + x*z)
    split_ands
    . linarith
    . simp[sum,presum]
      exact ⟨ x*y, ⟨ hxy, ⟨ x*z, ⟨ hxz, rfl⟩ ⟩ ⟩ ⟩

  . intro hq
    choose xy hxy xz hxz h using hq
    choose x₁ hx₁ y hy hx₁0 hy0 hx₁y using hxy
    choose x₂ hx₂ z hz hx₂0 hz0 hx₂z using hxz

    let x := max x₁ x₂
    have hx1 : x ∈ a.A := by
      by_cases g : x₁ ≤ x₂
      . have : x = x₂ := by exact max_eq_right g
        exact Set.mem_of_eq_of_mem this hx₂
      . have : x = x₁ := by exact max_eq_left (by linarith)
        exact Set.mem_of_eq_of_mem this hx₁
    have hx2 : 0 &lt; x := by exact lt_sup_of_lt_left hx₁0

    obtain ⟨ x', ⟨ hx1', hx2' ⟩ ⟩ := a.op x hx1

    have : y + z ∈ (sum b c).A := by
      exact ⟨ y, ⟨ hy, ⟨ z, ⟨ hz, rfl ⟩ ⟩ ⟩ ⟩

    have hxyz : x*(y+z) ∈ (mul_pos a (sum b c) ha (sum_pos_pos hb hc)).A := by
      use! x', hx1', y+z, this
      split_ands
      repeat
      nlinarith

    apply (mul_pos a (sum b c) ha (sum_pos_pos hb hc)).dc q (x*(y+z))

    split_ands
    . have h' : q &lt; x₁ * y + x₂ * z := by linarith
      have w1 : x₁ ≤ x := by exact le_max_left x₁ x₂
      have w2 : x₂ ≤ x := by exact le_max_right x₁ x₂
      nlinarith
    . exact hxyz

theorem nneg_distrib {a b c : DCut} (ha : 0 ≤ a) (hb : 0 ≤ b) (hc : 0 ≤ c)
  : mul_nneg a (b + c) ha (sum_nneg_nneg hb hc) =
    (mul_nneg a b ha hb) + (mul_nneg a c ha hc) := by
  rcases three_nn_ineqs ha hb hc with ⟨ ha', hb', hc' ⟩ | h | h | h
  . have h1 := nneg_eq_pos ha' (sum_pos_pos hb' hc')
    have h2 := nneg_eq_pos ha' hb'
    have h3 := nneg_eq_pos ha' hc'
    simp[hadd_inst] at h1
    simp[h1,h2,h3,hadd_inst]
    exact pos_distrib ha' hb' hc'
  repeat
  simp[h]

theorem nn_distrib {a b c : DCut} (ha : 0 ≤ a) (hb : 0 ≤ b) (hc : 0 ≤ c)
  : a * (b + c) = a*b + a*c := by
  simp[hmul_inst,mul]
  simp[ha,hb,hc,neg_le.mp,sum_nneg_nneg]
  have : -c + -b ≤ 0 := by
    have := sum_nneg_nneg hc hb
    rw[negate_le,neg_add_rev,add_comm] at this
    exact this
  simp[this,sum_nneg_nneg,nneg_distrib,ha,hb,hc]

theorem bn_distrib {a b c : DCut} (ha : 0 ≤ a) (hb : b &lt; 0) (hc : 0 ≤ c) :
  a * (b + c) = a * b + a * c := by
  by_cases h : 0 ≤ c+b
  . have h2 : a * ( (c+b) + (-b)) = a*(c+b) + a*(-b) := nn_distrib ha h (flip hb)
    simp at h2
    rw[h2]
    simp[add_comm]
  . apply neg_t.mpr at h
    apply lt_imp_le at h
    rw[←negate_le'] at h
    have h2 : a * ( -(c+b) + c ) = a*(-(c+b)) + a*c := nn_distrib ha h hc
    simp at h2
    apply neg_inj.mpr at h2
    rw[neg_neg] at h2
    rw[h2]
    simp
    rw[←neg_add,mul_neg_dist_left,neg_neg]

theorem distrib {a b c : DCut}
  : a*(b+c) = a*b+a*c := by
  rcases three_ineqs a b c with ⟨ ha, hb, hc ⟩ | ⟨ ha, hb, hc ⟩ |
                                ⟨ ha, hb, hc ⟩ | ⟨ ha, hb, hc ⟩ |
                                ⟨ ha, hb, hc ⟩ | ⟨ ha, hb, hc ⟩ |
                                ⟨ ha, hb, hc ⟩ | ⟨ ha, hb, hc ⟩

  . exact nn_distrib ha hb hc

  . have := nn_distrib (flip ha) hb hc
    rw[Iff.symm neg_inj,add_comm] at this
    simp_all[add_comm]

  . exact bn_distrib ha hb hc

  . have := bn_distrib ha hc hb
    simp[mul_neg_dist_right] at this
    rw[neg_sum_eq]
    rw[add_comm]
    rw[this]
    exact SubtractionMonoid.neg_add_rev (a * c) (a * b)

  . have := bn_distrib (flip ha) hb hc
    simp[mul_neg_dist_right] at this
    rw[neg_sum_eq]
    exact this

  . have := bn_distrib (flip ha) hc hb
    simp[mul_neg_dist_right] at this
    rw[neg_sum_eq]
    rw[add_comm]
    rw[this]
    exact sum_comm

  . have := nn_distrib ha (flip hb) (flip hc)
    simp only [←neg_add, mul_neg_dist_left, mul_neg_dist_right, neg_neg] at this
    rw[Iff.symm neg_inj]
    exact this

  . have := nn_distrib (flip ha) (flip hb) (flip hc)
    simp only [←neg_add, mul_neg_dist_left, mul_neg_dist_right, neg_neg] at this
    exact this

theorem distrib_right {a b c : DCut}
  : (a+b)*c = a*c+b*c := by
  have := @distrib c a b
  rw [mul_comm] at this
  simp[this,mul_comm,add_comm]
</code></pre>
<h2 id="cuts-form-a-commutative-ring"><a class="header" href="#cuts-form-a-commutative-ring">Cuts Form a Commutative Ring</a></h2>
<pre><code class="language-lean">instance nunasr_inst :  NonUnitalNonAssocSemiring DCut := ⟨
  @distrib,
  @distrib_right,
  @mul_zero_left,
  @mul_zero_right
⟩

instance nusr_inst : NonUnitalSemiring DCut := ⟨
  λ x y z =&gt; Eq.symm (@mul_assoc x y z)
⟩

instance semi_ring_inst : Semiring DCut := ⟨
  @mul_id_left,
  @mul_id_right,
  rfl,
  Nat.cast_add_one,
  npow,
  @npow_zero,
  @npow_succ
⟩

def smul (z : ℤ) (a : DCut) : DCut := (ofRat z) * a

theorem smul_zero_left {a : DCut} : smul 0 a = 0 := by
  have : ofRat 0 = 0 := rfl
  simp[smul,this,mul_zero_left]

theorem smul_succ {n : ℕ} {a : DCut}
  : smul (↑n.succ) a = smul (↑n) a + a := by
  simp[smul,add_rats,mul_comm,distrib]
  have : ofRat 1 = 1 := rfl
  simp[this]

theorem smul_neg_succ {n : ℕ} {a : DCut}
  : smul (Int.negSucc n) a = -smul (↑n.succ) a := by
  simp[smul,add_rats,mul_comm,distrib]
  simp[←neg_of_rat]

theorem int_cast_neg_succ (n : ℕ) :
    int_cast_inst.intCast (Int.negSucc n) = -↑(n + 1) := by
    simp[IntCast.intCast,Int.negSucc,add_rats,neg_inst]
    simp[←neg_of_rat]
    have : -ofRat 1 = -1 := rfl
    simp[this]
    rfl

instance ring_inst : Ring DCut := ⟨
  add_neg,
  smul,
  @smul_zero_left,
  @smul_succ,
  @smul_neg_succ,
  @neg_add_cancel_left,
  λ _ =&gt; rfl,
  int_cast_neg_succ
⟩

instance com_ring_inst : CommRing DCut := ⟨
  @mul_comm
⟩
</code></pre>
<p>With <code>CommRing</code> instantiated, we should be able to use the <code>ring</code> tactic on cuts.</p>
<pre><code class="language-lean">example {a b c : DCut} : a*(b+c) - c = a*c - c + a*b := by
  ring

example {a b : DCut} : (a-b)^2 = a^2 - 2*a*b + b^2 := by
  ring
</code></pre>
<div style='height=50px'>&nbsp;</div><hr>
Copyright © 2025 Eric Klavins
<div style="break-before: page; page-break-before: always;"></div><div style='display:none'>
--  Copyright (C) 2025  Eric Klavins
--
--  This program is free software: you can redistribute it and/or modify
--  it under the terms of the GNU General Public License as published by
--  the Free Software Foundation, either version 3 of the License, or
--  (at your option) any later version.   
</div>
<p><span style='color: orange'><em><strong>UNDER CONSTRUCTION</strong></em></span><br>
<span style='color: lightgray; font-size: 10pt'><a href='https://github.com/klavins/LeanBook/blob/main/main/../LeanBook/Chapters/Ordering/Definition.lean'>Code</a> for this chapter</span></p>
<h1 id="overview"><a class="header" href="#overview">Overview</a></h1>
<p>An <strong>order relation</strong> on a set <code>A</code> is a predicate <code>A → A → Prop</code> that captures some notion of order. A familiar example is the the <em>less than</em> relation on the natural numbers:</p>
<pre><code class="language-lean">#check 1 ≤ 2
</code></pre>
<p>where <code>&lt;</code> is shorthand for</p>
<pre><code class="language-lean">#check Nat.le       -- ℕ → ℕ → Prop
</code></pre>
<p><code>Nat.le</code> is an example of a <strong>total order</strong> on a set, meaning any two elements <code>x</code> and <code>y</code> are related (i.e. <code>x≤y</code> or <code>y≤x</code>). This need not be the case in general. For example, the subset relation <code>⊆</code> on sets is only a <strong>partial order</strong>, because one can find sets <code>A</code> and <code>B</code> for which neither <code>A ⊆ B</code> or <code>B ⊆ A</code>.</p>
<pre><code class="language-lean">namespace Temp

def A : Set ℕ := {1,2}
def B : Set ℕ := {3,4}

example : ¬A ⊆ B ∧ ¬B ⊆ A := by
  apply And.intro
  . intro h
    have h1a: 1 ∈ A := by simp[A]
    have h1b := h h1a
    simp[B] at h1b
  . intro h
    have h3b: 3 ∈ B := by simp[B]
    have h3a := h h3b
    simp[A] at h3a

end Temp
</code></pre>
<p>You will encounter many other examples of orderings besides these two, some of which we will get to in later sections. For now, we aim like to define a hierarchy of types of orders that capture their similarities and differences, defining a general theory of orders. A side goal here is to show how Lean's heirachy machinery works from the point of view of defining a <em>new</em> hierarchy instead of using someone else's hierarchy.</p>
<p>Most of this material comes from the book <em>Introduction to Lattices and Order</em> by Davey and Priestly.</p>
<h2 id="partial-orders"><a class="header" href="#partial-orders">Partial Orders</a></h2>
<p>A <strong>partially ordered set</strong> or <strong>poset</strong> is a set and a <em>less-than</em> ordering relation on the set that requires pretty much the minimum one might expect from a binary relation for it to be called an ordering: the relation needs to be reflexive, anti-symmetric, and transitive (see <a href="Ordering/../Relations.html">Relations</a>). Using a new Lean <code>class</code>, we define a class of types that have a less-than relation with these three properties.</p>
<pre><code class="language-lean">class Poset (α : Type u) where
  le : α → α → Prop
  refl : ∀ x, le x x
  anti_sym : ∀ x y, le x y → le y x → x = y
  trans : ∀ x y z, le x y → le y z → le x z
</code></pre>
<h3 id="example--the-natural-numbers"><a class="header" href="#example--the-natural-numbers">Example : The Natural Numbers</a></h3>
<p>Lean's standard library has all of these properties defined for natural numbers. Therefore, we can assert that <code>ℕ</code> is a <code>poset</code> by instantiating the <code>Poset</code> class as follows.</p>
<pre><code class="language-lean">instance : Poset ℕ := ⟨ Nat.le, @Nat.le.refl, @Nat.le_antisymm, @Nat.le_trans⟩
</code></pre>
<h3 id="example--sets"><a class="header" href="#example--sets">Example : Sets</a></h3>
<p>Lean's standard library also has all of these properties defined for sets.</p>
<pre><code class="language-lean">instance {A: Type u} : Poset (Set A) := ⟨
  Set.Subset,
  Set.Subset.refl,
  λ _ _ h1 h2 =&gt; Set.Subset.antisymm h1 h2,
  λ _ _ _ h1 h2 =&gt; Set.Subset.trans h1 h2
⟩
</code></pre>
<h2 id="poset-notation"><a class="header" href="#poset-notation">Poset Notation</a></h2>
<p>Simply having the <code>Poset</code> class defined does not give us much, however. Thus, the main goal of this section is to develop theorems that, for example, apply to any <code>Poset</code>, define specific kinds of <code>Poset</code>, or that relate <code>Posets</code> to each other.</p>
<p>To state these theorems cleaning, we first register some notation with Lean. Instantiating the <code>LE</code> and <code>LT</code> classes in Lean's standard library allow us to use <code>≤</code>, <code>≥</code>, <code>&lt;</code>, and <code>ge</code> on elements of our <code>Poset</code> type. Notice how these instances are declared. We have to supply a Type <code>A</code>, and require that it has been instantiated as a <code>Poset</code>.</p>
<pre><code class="language-lean">instance le_inst {A : Type u} [Poset A] : LE A := ⟨ Poset.le ⟩
instance lt_inst {A : Type u} [Poset A] : LT A := ⟨ λ x y =&gt; x ≤ y ∧ x ≠ y ⟩

example {A : Type u} [Poset A] (x:A) := x ≥ x
</code></pre>
<h2 id="total-orders"><a class="header" href="#total-orders">Total Orders</a></h2>
<p>A <strong>total order</strong> is a <code>Poset</code> with the added requirement that any two elements are comparable.</p>
<pre><code class="language-lean">def Comparable {P : Type u} [Poset P] (x y: P) := x ≤ y ∨ y ≤ x

class TotalOrder (T: Type u) extends Poset T where
  comp: ∀ x y : T, Comparable x y
</code></pre>
<p>The natural numbers are a total order, which is shown via a theorem in Lean's standard library. :</p>
<pre><code class="language-lean">instance nat_total_order : TotalOrder ℕ :=
  ⟨ Nat.le_total ⟩
</code></pre>
<p>Sets are not a total order, however.</p>
<pre><code class="language-lean">example : ∃ x y : Set ℕ, ¬Comparable x y := by
  apply Exists.intro {1}
  apply Exists.intro {2}
  simp[Comparable]
</code></pre>
<h2 id="meet-semilattices"><a class="header" href="#meet-semilattices">(Meet) Semilattices</a></h2>
<p>A <code>Semilattice</code> is a <code>Poset</code> for which there exists a greatest lower bound function, usually called <code>meet</code>, for every pair of points <code>x</code> and <code>y</code>. Then we extend the hierarchy with a new class of orders.</p>
<pre><code class="language-lean">class Semilattice (L : Type u) extends Poset L where
  meet : L → L → L
  lb : ∀ x y, meet x y ≤ x ∧ meet x y ≤ y
  greatest : ∀ x y w, w ≤ x → w ≤ y → w ≤ meet x y
</code></pre>
<p>For example, the natural numbers form a semilattice. So do sets.</p>
<pre><code class="language-lean">instance nat_semi_lattice : Semilattice ℕ :=
  ⟨
    Nat.min,
    by
      intro x y
      exact ⟨ Nat.min_le_left x y, Nat.min_le_right x y⟩,
    by
      intro x y _ h1 h2
      exact Nat.le_min_of_le_of_le h1 h2
  ⟩

instance set_semi_lattice {α : Type u}: Semilattice (Set α) :=
  ⟨
    Set.inter,
    by
      intro A B
      apply And.intro
      . intro x hx
        exact Set.mem_of_mem_inter_left hx
      . intro x hx
        exact Set.mem_of_mem_inter_right hx,
    by
      intro A B _ h1 h2 _ hc
      exact ⟨ h1 hc, h2 hc ⟩
  ⟩
</code></pre>
<h2 id="lattices"><a class="header" href="#lattices">Lattices</a></h2>
<p>If all pairs of elements also have a least upper bound, then the <code>Poset</code> is called a <code>Lattice</code>. The least upper bound function is called the <strong>join</strong>.</p>
<pre><code class="language-lean">class Lattice (L : Type u) extends Semilattice L where
  join : L → L → L
  ub : ∀ x y, (x ≤ join x y ∧ y ≤ join x y)
  least : ∀ x y w, x ≤ w → y ≤ w → join x y ≤ w
</code></pre>
<p>Both ℕ and Sets are Lattices as well. The joing for ℕ is <code>Nat.max</code> and the join for sets is <code>Set.union</code>.</p>
<pre><code class="language-lean">instance nat_lattice : Lattice ℕ :=
  ⟨
    Nat.max,
    by
      intro x y
      exact ⟨ Nat.le_max_left x y, Nat.le_max_right x y ⟩,
    by
      intro x y _ h1 h2
      exact Nat.max_le_of_le_of_le h1 h2
  ⟩

instance set_lattice {α : Type u}: Lattice (Set α) :=
  ⟨
    Set.union,
    by
      intro A B
      . exact Set.union_subset_iff.mp (λ  _ a =&gt; a),
    by
      intro A B C h1 h2 c hc
      apply Or.elim hc
      . exact λ h3 =&gt; h1 h3
      . exact λ h3 =&gt; h2 h3
  ⟩
</code></pre>
<p>As an example of a semilattice that is not a lattice is the so-called <a href="Ordering/./Information.html">information ordering</a> on partial functions, decribed in a separate chapter.</p>
<h2 id="notation-for-lattices"><a class="header" href="#notation-for-lattices">Notation for Lattices</a></h2>
<p>The meet and join of two elements <code>x</code> and <code>y</code> of a poset are denonted <code>x ⊓ y</code> and <code>x sup y</code>. The notation classes for these operations are called <code>Min</code> and <code>Max</code>, even though you do not have to use them for actual mins and maxes.</p>
<pre><code class="language-lean">instance Semilattice.and_inst {L : Type u} [Semilattice L] : Min L :=
  ⟨ meet ⟩

instance Lattice.or_inst {L : Type u} [Lattice L] : Max L :=
  ⟨ join ⟩
</code></pre>
<h2 id="meet-and-join-example-theorems"><a class="header" href="#meet-and-join-example-theorems">Meet and Join Example Theorems</a></h2>
<p>Here are two straightforward theorems about meets and joins that test out the definitions and notation. They follow from the definitions of greatest lower bound, least upper bound, anti-symmetry, and reflexivity.</p>
<pre><code class="language-lean">theorem Semilattice.meet_idempotent {L : Type u} [Semilattice L] (x : L) : x ⊓ x = x := by
  have ⟨ h1, h2 ⟩ := lb x x
  have h4 := greatest x x x (Poset.refl x) (Poset.refl x)
  exact Poset.anti_sym (x ⊓ x) x h1 h4

theorem Lattice.join_idempotent {L : Type u} [Lattice L] (x : L) : x ⊔ x = x := by
  have ⟨ h1, h2 ⟩ := ub x x
  have h4 := least x x x (Poset.refl x) (Poset.refl x)
  apply Poset.anti_sym (x ⊔ x) x h4 h1
</code></pre>
<h2 id="complete-lattices"><a class="header" href="#complete-lattices">Complete Lattices</a></h2>
<p>Lattices require that every pair of elements have a greatest lower bound and leaset upper bound. A Complete Lattice requires that every set have such bounds. An example of a Complete Lattice is <code>Set A</code>, which we show after defining Complete Lattices.</p>
<pre><code class="language-lean">def IsLB {P : Type u} [Poset P] (S : Set P) (lb : P) := ∀ x ∈ S, lb ≤ x

class CompleteSemilattice (L : Type u) extends Poset L where
  inf : Set L → L
  lb : ∀ S, IsLB S (inf S)
  greatest : ∀ S w, (IsLB S w) → w ≤ inf S

def IsUB {P : Type u} [Poset P] (S : Set P) (ub : P) := ∀ x, x ∈ S → x ≤ ub

class CompleteLattice (L : Type u) extends CompleteSemilattice L where
  sup : Set L → L
  ub : ∀ S, IsUB S (sup S)
  least : ∀ S, ∀ w, (IsUB S w) → sup S ≤ w
</code></pre>
<p>Example: The set of subsets of a given set <code>A</code> is a complete lattice, which we show in two steps using straighforward proofs.</p>
<pre><code class="language-lean">instance set_csl {A : Type u}: CompleteSemilattice (Set A) :=
  ⟨
    λ S =&gt; { x | ∀ T ∈ S, x ∈ T },
    by
      intro S T h x hx
      dsimp at hx
      exact hx T h,
    by
      intro S T h x hx R hR
      exact h R hR hx
  ⟩

instance set_cl {A : Type u}: CompleteLattice (Set A) :=
  ⟨
    λ S =&gt; { x | ∃ T ∈ S, x ∈ T },
    by
      intro S T h x hx
      apply Exists.intro T
      exact ⟨h, hx⟩,
    by
      intro S T h x hx
      dsimp at hx
      obtain ⟨ R, ⟨ h1, h2 ⟩ ⟩ := hx
      exact h R h1 h2
  ⟩
</code></pre>
<h2 id="complete-lattices-are-bounded"><a class="header" href="#complete-lattices-are-bounded">Complete Lattices are Bounded</a></h2>
<p>Notice that in the definition of <code>inf</code> the condition <code>(IsLB S w)</code> in  <code>(IsLB S w)→ w ≤ inf S</code> is trivially satisfied if <code>S = ∅</code>. Therefore, <code>w ≤ inf ∅</code> for all <code>w</code>, meaning that <code>inf ∅</code> is a top element. Similarly, <code>sup ∅</code> is a bottom element. We can conclude that every Complete Lattice is bounded, as shown by the next two theorems.</p>
<pre><code class="language-lean">@[simp]
def CompleteLattice.bot {L : Type u} [CompleteLattice L] : L :=
  sup (∅:Set L)

@[simp]
def CompleteLattice.top {L : Type u} [CompleteLattice L] : L :=
  CompleteSemilattice.inf (∅:Set L)

theorem CompleteLattice.is_bot {L : Type u} [CompleteLattice L]
  : ∀ x : L, bot ≤ x := by
  intro x
  apply CompleteLattice.least ∅ x
  simp[IsUB]

theorem CompleteLattice.is_top {L : Type u} [CompleteLattice L]
  : ∀ x : L, x ≤ top := by
  intro x
  apply CompleteSemilattice.greatest ∅ x
  simp[IsLB]
</code></pre>
<h2 id="complete-lattices-are-lattices"><a class="header" href="#complete-lattices-are-lattices">Complete Lattices are Lattices</a></h2>
<p>We can also show that a complete lattice is a lattice by restricting <code>inf</code> and <code>sup</code> to act on sets of size two.</p>
<pre><code class="language-lean">instance CompleteSemilattice.inst_sl {L : Type u} [CompleteSemilattice L]
  : Semilattice L := ⟨
    λ x y =&gt; inf {x,y},
    by
      intro x y
      apply And.intro &lt;;&gt;
      apply lb &lt;;&gt;
      simp,
    by
      intro x u z h1 h2
      apply greatest
      simp[IsLB, h1, h2]
  ⟩

instance CompleteLattice.inst_l {L : Type u} [CompleteLattice L]
  : Lattice L := ⟨
    λ x y =&gt; sup {x,y},
    by
      intro x y
      apply And.intro &lt;;&gt;
      apply ub &lt;;&gt;
      simp,
    by
      intro x u z h1 h2
      apply least
      simp[IsUB, h1, h2]
  ⟩
</code></pre>
<h2 id="hierarchy"><a class="header" href="#hierarchy">Hierarchy</a></h2>
<pre><code>     Lattice     CL
        |         |
    Semilattice  CSL   Total Order
             \    |    /
                Poset
</code></pre>
<div style='height=50px'>&nbsp;</div><hr>
Copyright © 2025 Eric Klavins
<div style="break-before: page; page-break-before: always;"></div><div style='display:none'>
--  Copyright (C) 2025  Eric Klavins
--
--  This program is free software: you can redistribute it and/or modify
--  it under the terms of the GNU General Public License as published by
--  the Free Software Foundation, either version 3 of the License, or
--  (at your option) any later version.   
</div>
<p><span style='color: orange'><em><strong>UNDER CONSTRUCTION</strong></em></span><br>
<span style='color: lightgray; font-size: 10pt'><a href='https://github.com/klavins/LeanBook/blob/main/main/../LeanBook/Chapters/Ordering/Properties.lean'>Code</a> for this chapter</span></p>
<h2 id="simple-properties"><a class="header" href="#simple-properties">Simple Properties</a></h2>
<pre><code class="language-lean">theorem eq_to_le {P : Type u} [Poset P] {x y : P} : x = y → x ≤ y := by
  intro h
  rw[h]
  exact refl y
</code></pre>
<h2 id="up-sets-and-down-sets"><a class="header" href="#up-sets-and-down-sets">Up Sets and Down Sets</a></h2>
<p>The set of all elements above (below) a given element <code>x:P</code> is called the up (down) set of <code>x</code>.</p>
<pre><code class="language-lean">def up {P : Type u} [Poset P] (x : P) : Set P := { y | x ≤ y }
def down {P : Type u} [Poset P] (x : P) : Set P := { y | y ≤ x }
</code></pre>
<p>A set that is upwardly (downwardly) closed is called an Up (Down) set. We define predicates on subsets of a Poset to capture these properties. These are a bit tricky to read. The first one says that if <code>x</code> is any element and there is a <code>y</code> in some upward closed set <code>S</code> that is less than or equal to it, then <code>x</code> must also be in <code>S</code>. The second statement about downward closed sets is similar.</p>
<pre><code class="language-lean">def UpSet {P : Type u} [Poset P] (S : Set P) := ∀ x, (∃ y ∈ S, y ≤ x) → x ∈ S
def DownSet {P : Type u} [Poset P] (S : Set P) := ∀ x, (∃ y ∈ S, x ≤ y) → x ∈ S
</code></pre>
<p>Simple theorems relating these definitions can now be proved. The next two, for example, show that up (down) sets are upwardly (downwardly) closed.</p>
<pre><code class="language-lean">theorem up_is_up {P : Type u} [Poset P] (x : P) : UpSet (up x) := by
  intro z ⟨ y, ⟨ h1, h2 ⟩  ⟩
  simp_all[Set.mem_def,up]
  exact trans x y z h1 h2

theorem down_is_down {P : Type u} [Poset P] (x : P) : DownSet (down x) := by
  intro z ⟨ y, ⟨ h1, h2 ⟩  ⟩
  simp_all[Set.mem_def,down]
  apply trans z y x h2 h1
</code></pre>
<p>Upward closed sets are not just those built from a single element. For example, the union of two upwardly closed sets is also upwardly closed.</p>
<pre><code class="language-lean">theorem up_union {P : Type u} [Poset P] (x y: P) : UpSet ((up x) ∪ (up y)) := by
  intro w ⟨ z, ⟨ h1, h2 ⟩ ⟩
  apply Or.elim h1
  . intro h3
    exact Or.inl (trans x z w h3 h2)
  . intro h3
    apply Or.inr (trans y z w h3 h2)
</code></pre>
<h2 id="lower-and-upper-sets"><a class="header" href="#lower-and-upper-sets">Lower and Upper Sets</a></h2>
<pre><code class="language-lean">def upper {P : Type u} [Poset P] (A : Set P) : Set P :=
 { x | ∀ a ∈ A, a ≤ x }

def lower {P : Type u} [Poset P] (A : Set P) : Set P :=
 { x | ∀ a ∈ A, x ≤ a }

-- 1
theorem sub_ul {P : Type u} [Poset P] (A : Set P)
  : A ⊆ upper (lower A) := by
  intro x hx a ha
  exact ha x hx

theorem sub_lu {P : Type u} [Poset P] (A : Set P)
  : A ⊆ lower (upper A) := by
  intro x hx a ha
  exact ha x hx

theorem eq_to_sub {P : Type u} [Poset P] (A : Set P)
  : lower (upper A) ⊆ A → lower (upper A) = A := by
  intro h
  exact Set.eq_of_subset_of_subset h (sub_lu A)

-- 2
theorem sub_up {P : Type u} [Poset P] {A B : Set P}
  : A ⊆ B → upper B ⊆ upper A := by
  intro h b hb a ha
  exact hb a (h ha)

-- 3
theorem sub_low {P : Type u} [Poset P] {A B : Set P}
  : A ⊆ B → lower B ⊆ lower A := by
  intro h b hb a ha
  exact hb a (h ha)

-- 4
theorem up_ulu {P : Type u} [Poset P] {A : Set P}
 : upper A = upper (lower (upper A)) := by
 apply Set.eq_of_subset_of_subset
 . intro a ha b hb
   exact hb a ha
 . intro a ha b hb
   exact ha b fun a a ↦ a b hb

-- 5
theorem low_lul {P : Type u} [Poset P] {A : Set P}
 : lower A = lower (upper (lower A)) := by
 apply Set.eq_of_subset_of_subset
 . intro a ha b hb
   exact hb a ha
 . intro a ha b hb
   exact ha b fun a a ↦ a b hb
</code></pre>
<h2 id="minimal-and-maximal-elements"><a class="header" href="#minimal-and-maximal-elements">Minimal and Maximal Elements</a></h2>
<p>A <strong>minimal</strong> element of a set <code>S ⊆ P</code> is one for which no other elements of <code>S</code> are smaller.</p>
<pre><code class="language-lean">def Minimal {P : Type u} [Poset P] (S : Set P) (m : P) := ∀ x ∈ S, x ≤ m → x = m
</code></pre>
<p>Minimal elements are not necessarily unique. The following example shows that when <code>x</code> and <code>y</code> are unrelated, either one of them is minimal.</p>
<pre><code class="language-lean">example {P : Type u} [Poset P] (x y: P) : (¬x≤y ∧ ¬y≤x) → Minimal {x,y} x := by
  intro ⟨h1, h2⟩ z h3 h4
  apply Or.elim h3
  . exact id
  . intro h5
    rw[h5] at h4
    exact False.elim (h2 h4)
</code></pre>
<p>On the other hand, a <strong>minimum</strong> element is a unique minimal element.</p>
<pre><code class="language-lean">def Minimum {P : Type u} [Poset P] (S : Set P) (m : P) := ∀ x ∈ S, m ≤ x
</code></pre>
<p>The most minimal element of a <code>Poset</code> is usually called <code>bot</code>.</p>
<pre><code class="language-lean">def is_bot {P : Type u} [Poset P] (x : P) := ∀ y, x ≤ y

theorem bot_minimum {P : Type u} [Poset P] (m : P) : is_bot m → Minimum Set.univ m := by
  intro hb x hm
  simp_all[is_bot]
</code></pre>
<p>These definitions apply to maxima as well.</p>
<pre><code class="language-lean">def Maximal {P : Type u} [Poset P] (S : Set P) (m : P) := ∀ x ∈ S , m ≤ x → x = m
def Maximum {P : Type u} [Poset P] (S : Set P) (m : P) := ∀ x ∈ S, x ≤ m
def is_top {P : Type u} [Poset P] (x : P) := ∀ y, y ≤ x
</code></pre>
<h2 id="chains-and-anti-chains"><a class="header" href="#chains-and-anti-chains">Chains and Anti-Chains</a></h2>
<p>A chain is a totally ordered subset of a poset.</p>
<pre><code class="language-lean">def Chain {P : Type u} [Poset P] (S : Set P) := ∀ x ∈ S, ∀ y ∈ S, x ≤ y ∨ y ≤ x
</code></pre>
<p>For example, the upset of any natural number is a chain.</p>
<pre><code class="language-lean">example {n : ℕ} : Chain (up n) := by
  intro x hx y hy
  exact Nat.le_total x y
</code></pre>
<p>An antichain is a set of uncomparable elements.</p>
<pre><code class="language-lean">def AntiChain {P : Type u} [Poset P] (S : Set P) := ∀ x ∈ S, ∀ y ∈ S, x ≠ y → (¬x ≤ y ∧ ¬y ≤ x)
</code></pre>
<p>For example, the set of singletons each containing a different natural number is an anti-chain.</p>
<pre><code class="language-lean">def my_anti_chain : Set (Set ℕ) := { {n} | n : ℕ }

example : AntiChain my_anti_chain := by
  simp[my_anti_chain]
  intro Sm ⟨ m, hsm ⟩ Sn ⟨ n, hsn ⟩ hmn
  simp[le_inst]
  apply And.intro
  . intro h
    rw[←hsm,←hsn] at h
    rw[←hsm,←hsn] at hmn
    exact hmn (congrArg singleton (h rfl))
  . intro h
    rw[←hsm,←hsn] at h
    rw[←hsm,←hsn] at hmn
    exact id (Ne.symm hmn) (congrArg singleton (h rfl))
</code></pre>
<h2 id="exercises-5"><a class="header" href="#exercises-5">Exercises</a></h2>
<ol>
<li>Show the rational numbers ℚ with the natural order ≤ form a Poset</li>
</ol>
<pre><code class="language-lean">instance : Poset ℚ := ⟨ λ x y =&gt; x ≤ y, sorry, sorry, sorry ⟩
</code></pre>
<ol start="2">
<li>Show the upper set (0,1) is [1,∞)</li>
</ol>
<pre><code class="language-lean">example : upper {x:ℚ | 0 &lt; x ∧ x &lt; 1} = { x | 1 ≤ x } := sorry
</code></pre>
<div style='height=50px'>&nbsp;</div><hr>
Copyright © 2025 Eric Klavins
<div style="break-before: page; page-break-before: always;"></div><div style='display:none'>
--  Copyright (C) 2025  Eric Klavins
--
--  This program is free software: you can redistribute it and/or modify
--  it under the terms of the GNU General Public License as published by
--  the Free Software Foundation, either version 3 of the License, or
--  (at your option) any later version.   
</div>
<p><span style='color: orange'><em><strong>UNDER CONSTRUCTION</strong></em></span><br>
<span style='color: lightgray; font-size: 10pt'><a href='https://github.com/klavins/LeanBook/blob/main/main/../LeanBook/Chapters/Ordering/Maps.lean'>Code</a> for this chapter</span></p>
<h2 id="maps-between-posets"><a class="header" href="#maps-between-posets">Maps Between Posets</a></h2>
<pre><code class="language-lean">def OrderPreserving {P Q : Type u} [Poset P] [Poset Q] (φ : P → Q) :=
  ∀ x y : P, x ≤ y → φ x ≤ φ y

def OrderEmbedding {P Q : Type u} [Poset P] [Poset Q] (φ : P → Q) :=
  ∀ x y : P, x ≤ y ↔ φ x ≤ φ y

def OneToOne {P Q : Type u} (φ : P → Q) :=
  ∀ x y , φ x = φ y → x = y

def Onto {P Q : Type u} (φ : P → Q) :=
  ∀ y , ∃ x , φ x = y

def OrderIsomorphism {P Q : Type u} [Poset P] [Poset Q] (φ : P → Q) :=
  Onto φ ∧ OrderEmbedding φ

theorem order_pres_comp {P Q R : Type u} [Poset P] [Poset Q] [Poset R] (φ : P → Q) (ψ : Q → R)
  : OrderPreserving φ → OrderPreserving ψ → OrderPreserving (ψ ∘ φ) := by
  intro h1 h2 x y hxy
  apply h2 (φ x) (φ y)
  apply h1 x y
  exact hxy

theorem order_embed_1to1 {P Q : Type u} [Poset P] [Poset Q] (φ : P → Q)
  : OrderEmbedding φ → OneToOne φ := by
  intro h x y hxy
  apply anti_sym
  . apply (h x y).mpr
    exact eq_to_le hxy
  . apply (h y x).mpr
    exact eq_to_le (Eq.symm hxy)

theorem order_iso_bijective {P Q : Type u} [Poset P] [Poset Q] (φ : P → Q)
  : OrderIsomorphism φ → (OneToOne φ ∧ Onto φ) := by
  intro ⟨ h1, h2 ⟩
  exact ⟨ order_embed_1to1 φ h2, h1 ⟩
</code></pre>
<h2 id="examples"><a class="header" href="#examples">Examples</a></h2>
<pre><code class="language-lean">example : OrderPreserving (λ _ : ℕ =&gt; 0) := by
  intro x y h
  dsimp
  rfl

def f (n:ℕ) : Set ℕ := { x | x ≤ n }

example : OrderEmbedding f := by
  intro x y
  constructor
  . intro h
    intro z hz
    exact trans z x y hz h
  . intro h
    simp[f] at h
    exact h x (Poset.refl x)

def g (x : ℕ) : ℕ := 2*x

example : OrderEmbedding g := by
  intro x y
  constructor
  . intro h
    simp[g]
    exact h
  . intro h
    simp[g] at h
    exact h
</code></pre>
<div style='height=50px'>&nbsp;</div><hr>
Copyright © 2025 Eric Klavins
<div style="break-before: page; page-break-before: always;"></div><div style='display:none'>
--  Copyright (C) 2025  Eric Klavins
--
--  This program is free software: you can redistribute it and/or modify
--  it under the terms of the GNU General Public License as published by
--  the Free Software Foundation, either version 3 of the License, or
--  (at your option) any later version.   
</div>
<p><span style='color: orange'><em><strong>UNDER CONSTRUCTION</strong></em></span><br>
<span style='color: lightgray; font-size: 10pt'><a href='https://github.com/klavins/LeanBook/blob/main/main/../LeanBook/Chapters/Ordering/Strings.lean'>Code</a> for this chapter</span></p>
<h1 id="strings"><a class="header" href="#strings">Strings</a></h1>
<pre><code class="language-lean">open List
</code></pre>
<p><strong>Note</strong> that List already have an ordering on them, but it is not the prefix ordering.
This creates issues because List.le and [LT (List A)] are already defined. We avoid this
here by just not using the ≤ notation.</p>
<pre><code class="language-lean">#check List.le
variable {A : Type u} (x : List A) [LT A]
#check [] ≤ x
#eval [1,2,3] ≤ [1,2,5]
example {A : Type u} [LT A] (x : List A) : [] ≤ x := by
  simp[List.instLE]
</code></pre>
<p><strong>End Note</strong></p>
<pre><code class="language-lean">instance list_poset {A : Type u} : Poset (List A) :=
  ⟨
    IsPrefix,
    List.prefix_refl,
    by
      intro s t ⟨ x, h1 ⟩ ⟨ y, h2 ⟩
      aesop,
    by
      intro s t u
      exact List.IsPrefix.trans
  ⟩

example {A : Type u} (x : List A) : [] &lt;+: x := by
  simp[list_poset]

def meet {A : Type u} [Poset (List A)] [DecidableEq A] (x y : List A) : List A :=
  match x,y with
  | [], [] =&gt; []
  | _, [] =&gt; []
  | [], _ =&gt; []
  | a::L, b::M =&gt; if a = b then a :: meet L M else []

theorem bot_le {A : Type u} [Poset (List A)] (x: List A) : [] &lt;+: x := by
  exact nil_prefix

theorem meet_le {A : Type u} [Poset (List A)] [DecidableEq A] (x y : List A)
  : (meet x y) &lt;+: x := by
  match x,y with
  | a::L, b::M =&gt;
    simp[meet]
    split_ifs
    . have : IsPrefix (meet L M) L := by apply meet_le -- structural recursion!
      simp[this]
    . apply bot_le
  | [], [] =&gt; simp[meet]
  | a::L, [] =&gt; simp[meet]
  | [], b::M =&gt; simp[meet]

theorem meet_le' {A : Type u} [Poset (List A)] [DecidableEq A] (x y : List A)
  : (meet x y) &lt;+: y := by
  match x,y with
  | a::L, b::M =&gt;
    simp[meet]
    split_ifs
    . have : IsPrefix (meet L M) M := by apply meet_le' -- structural recursion!
      simp[this]
      assumption
    . apply bot_le
  | [], [] =&gt; simp[meet]
  | a::L, [] =&gt; simp[meet]
  | [], b::M =&gt; simp[meet]

theorem meet_great {A : Type u} [Poset (List A)] [DecidableEq A] (x y : List A)
  : ∀ w, w &lt;+: x → w &lt;+: y → w &lt;+: (meet x y) := by
  intro w hwx hwy
  match x, y with
  | a::L, b::M =&gt;
    simp[meet]
    split_ifs
    . rename_i hab
      simp_all[hab]
      by_cases hw : w = []
      . simp[hw]
      . obtain ⟨ c, ⟨ N, hcN ⟩ ⟩ := ne_nil_iff_exists_cons.mp hw
        simp_all[hcN]
        apply meet_great -- structural recursion!
        . exact hwx.right
        . exact hwy
    . rename_i hab
      have : w = [] := by
        by_cases h : w = []
        . exact h
        . have ⟨ c, ⟨ N, hN ⟩ ⟩ : ∃ c, ∃ N, w = c :: N := ne_nil_iff_exists_cons.mp h
          have h1 : c = a := by simp_all[hN]
          have h2 : c = b := by simp_all[hN]
          simp_all
      simp[this]
  | [], [] =&gt; simp[meet,hwx]
  | a::L, [] =&gt; simp[meet,hwy]
  | [], b::M =&gt; simp[meet,hwx]

instance info_semilattice {A : Type u} [DecidableEq A] : Semilattice (List A) :=
  ⟨
    meet,
    λ L M =&gt; by
      constructor
      . constructor
        . apply meet_le
        . apply meet_le'
      . apply meet_great
  ⟩
</code></pre>
<div style='height=50px'>&nbsp;</div><hr>
Copyright © 2025 Eric Klavins
<div style="break-before: page; page-break-before: always;"></div><div style='display:none'>
--  Copyright (C) 2025  Eric Klavins
--
--  This program is free software: you can redistribute it and/or modify
--  it under the terms of the GNU General Public License as published by
--  the Free Software Foundation, either version 3 of the License, or
--  (at your option) any later version.   
</div>
<p><span style='color: orange'><em><strong>UNDER CONSTRUCTION</strong></em></span><br>
<span style='color: lightgray; font-size: 10pt'><a href='https://github.com/klavins/LeanBook/blob/main/main/../LeanBook/Chapters/Ordering/Information.lean'>Code</a> for this chapter</span></p>
<h1 id="information-ordering-on-values"><a class="header" href="#information-ordering-on-values">Information Ordering on Values</a></h1>
<pre><code class="language-lean">def PartialFunction (A : Type u) (B : Type v) := A → Option B

namespace PartialFunction

def val_le (B : Type u) (u v : Option B) := u = none ∨ u = v

theorem val_le_refl {B : Type u} : Refl (val_le B) := by
  simp[Refl,val_le]

theorem val_le_anti_sym {B : Type u} : AntiSym (val_le B) := by
  intro x y h1 h2
  simp_all[val_le]
  aesop

theorem val_le_trans {B : Type u} : Trans (val_le B) := by
  intro x y z h1 h2
  simp_all[val_le]
  aesop

@[simp]
instance poset_val_le {B : Type u} : Poset (Option B) :=
  ⟨ val_le B, val_le_refl, val_le_anti_sym, val_le_trans ⟩

theorem none_val_le {B : Type u} : ∀ x : Option B, none ≤ x := by
  intro x
  have : val_le B none x := by simp[val_le]
  simp[Poset.le_inst,val_le]

def Dom {A : Type u} {B : Type v} (f: PartialFunction A B) : Set A := λ a =&gt; f a ≠ none

def le {A : Type u} {B : Type v} : Relation (PartialFunction A B) (PartialFunction A B) :=
  λ f g =&gt; ∀ x, (f x) ≤ (g x)


def bot {A : Type u} {B : Type v} : PartialFunction A B := λ _ =&gt; none

theorem le_refl {A : Type u} {B : Type v} : Refl (@le A B) := by
  intro x h
  apply val_le_refl

theorem le_anti_sym {A : Type u} {B : Type v} : AntiSym (@le A B) := by
  simp[AntiSym]
  intro f g hf hg
  funext x
  apply val_le_anti_sym
  . exact hf x
  . exact hg x

theorem le_trans {A : Type u} {B : Type v} : Trans (@le A B) := by
  simp[Trans]
  intro f g h hf hg
  simp[le]
  intro x
  apply val_le_trans
  . exact hf x
  . exact hg x

instance poset_le (A : Type u) (B : Type v): Poset (PartialFunction A B) :=
  ⟨ le, le_refl, le_anti_sym, le_trans ⟩

theorem le_def {A : Type u} {B : Type v} (f g: PartialFunction A B)
  : f ≤ g ↔ ∀ x, f x ≤ g x := by
  simp[le_inst, Poset.le, le, val_le]

theorem le_total_def {A : Type u} {B : Type v} (f g: PartialFunction A B)
  : f ≤ g ↔ ∀ x, f x = none ∨ f x = g x := by
  simp[le_inst, Poset.le, le, val_le]

theorem bot_le_all {A : Type u} {B : Type v} (f: PartialFunction A B) : bot ≤ f := by
  intro x
  simp[val_le,bot,Poset.le_inst]

theorem le_dom {A : Type u} {B : Type v} {f g : PartialFunction A B} :
  f ≤ g ↔ (Dom f ⊆ Dom g ∧ ∀ x ∈ Dom f, f x = g x):= by
  constructor
  . intro h
    constructor
    . intro a ha
      have := h a
      simp_all[Set.mem_def,Dom,val_le,Poset.le_inst]
    . intro a ha
      have := h a
      simp_all[Set.mem_def,Dom,Poset.le,val_le,le,Poset.le_inst]
  . intro ⟨ h1, h2 ⟩
    intro a
    have := h2 a
    simp_all[Set.mem_def,Dom,Poset.le,val_le,le]
    by_cases h3 : f a = none
    . exact Or.inl h3
    . apply Or.inr
      exact this h3

example (A : Type u) (B : Type v) (f : PartialFunction A B) : f ≤ f := by apply Poset.refl
</code></pre>
<h1 id="total-information-elements"><a class="header" href="#total-information-elements">Total Information Elements</a></h1>
<pre><code class="language-lean">def Total {A : Type u} {B : Type v} (f : PartialFunction A B) := ∀ x, f x ≠ none

theorem total_le {A : Type u} {B : Type v} {f g : PartialFunction A B}
  : Total f → Poset.le f g → f = g := by
  simp[Total,Poset.le]
  intro h hfg
  funext x
  have h1 := h x
  have h2 := hfg x
  simp_all[val_le,Poset.le,Poset.le_inst]
</code></pre>
<h2 id="information-ordering-is-a-lattice"><a class="header" href="#information-ordering-is-a-lattice">Information Ordering is a Lattice</a></h2>
<pre><code class="language-lean">def meet {A : Type u} {B : Type v} [DecidableEq B] (f g : PartialFunction A B) :=
  λ a =&gt; if f a = g a then f a else none

theorem meet_symm {A : Type u} {B : Type v} [DecidableEq B] {f g : PartialFunction A B}
  : meet f g = meet g f := by
  unfold meet
  aesop

theorem pf_meet_le {A : Type u} {B : Type v} [DecidableEq B] {f g : PartialFunction A B} :
  (meet f g) ≤ f := by
  intro a
  simp[meet]
  split_ifs &lt;;&gt;
  simp[val_le,Poset.le_inst]

theorem pf_meet_le' {A : Type u} {B : Type v} [DecidableEq B] {f g : PartialFunction A B} :
  le (meet f g) g := by
  rw[meet_symm]
  exact pf_meet_le

theorem pf_meet_greater {A : Type u} {B : Type v} [DecidableEq B] {f g : PartialFunction A B} :
  ∀ w, le w f → le w g → le w (meet f g) := by
  intro w h1 h2 a
  simp[meet,val_le]
  split_ifs
  . exact h1 a
  . simp[Poset.le_inst,Poset.le,val_le,Poset.le_inst]
    apply Or.elim (h2 a)
    . exact id
    . intro h3
      cases h1 a with
      | inl h =&gt; simp_all
      | inr h =&gt; simp_all

instance info_semilattice {A : Type u} {B : Type v} [DecidableEq B] : Semilattice (PartialFunction A B) :=
  ⟨
    meet,
    λ _ _ =&gt; ⟨ ⟨ pf_meet_le, pf_meet_le' ⟩, pf_meet_greater ⟩
  ⟩

end PartialFunction
</code></pre>
<div style='height=50px'>&nbsp;</div><hr>
Copyright © 2025 Eric Klavins
<div style="break-before: page; page-break-before: always;"></div><div style='display:none'>
--  Copyright (C) 2025  Eric Klavins
--
--  This program is free software: you can redistribute it and/or modify
--  it under the terms of the GNU General Public License as published by
--  the Free Software Foundation, either version 3 of the License, or
--  (at your option) any later version.   
</div>
<p><span style='color: orange'><em><strong>UNDER CONSTRUCTION</strong></em></span><br>
<span style='color: lightgray; font-size: 10pt'><a href='https://github.com/klavins/LeanBook/blob/main/main/../LeanBook/Chapters/Ordering/Completions.lean'>Code</a> for this chapter</span></p>
<h1 id="the-dedekind-macneille-completion"><a class="header" href="#the-dedekind-macneille-completion">The Dedekind-MacNeille Completion</a></h1>
<p>A <strong>completion</strong> is an embedding of a partially ordered set into a complete lattice. It allows one to "fill in the gaps" in an ordered set so that, for example, limit points exist. The real numbers, for example, are the completion of the rational numbers.</p>
<p>In this chapter we describe the the Dedekind-MacNeille (DM) Completion, which is a generalization of the Dedekind cuts method of constructing the reals to the case of any ordered set. In particular, we define <code>DM P</code> for any poset <code>P</code>. If <code>P=ℚ</code>, the result is isomorphic to the reals with <code>-∞</code> and <code>∞</code>, but the approach works for any poset.</p>
<p>Formally, the Dedekind-MacNeille completion <code>DM P</code> is defined to be the family of subsets of <code>S ⊆ P</code> that are closed with respect to the closure operator <code>λ P ↦ lower (upper P)</code>.</p>
<pre><code class="language-lean">@[ext]
structure DM (P : Type u) [Poset P] where
  val : Set P
  h : lower (upper val) = val
</code></pre>
<p>Our goal is to show that <code>DM P</code> is a complete lattice for any <code>P</code>. We can easily show that <code>DM P</code> is a poset under the usual <code>⊆</code> ordering.</p>
<pre><code class="language-lean">instance DM.poset {P : Type u} [Poset P] : Poset (DM P) :=
  ⟨
    λ ⟨ A, hA ⟩ ⟨ B, hB ⟩ =&gt; A ⊆ B,
    by
      intro ⟨ A, _ ⟩
      exact Set.Subset.refl A,
    by
      intro ⟨ A, hA ⟩ ⟨ B, hB ⟩ h1 h2
      simp_all
      exact Set.Subset.antisymm h1 h2,
    by
      intro ⟨ A, hA ⟩ ⟨ B, hB ⟩ ⟨ C, hC ⟩ h1 h2
      exact Set.Subset.trans h1 h2
  ⟩
</code></pre>
<p>In fact, the <code>DM</code> structure forms what Davey and Priestly call a <em>topped intersection structure</em>, which we will show is a Complete Lattice with a particular definition for the meet and join that we define next.</p>
<h2 id="the-meet"><a class="header" href="#the-meet">The Meet</a></h2>
<p>We define a <em>meet</em> for <code>DM P</code>, which is just set-intersection taken over a subset of <code>DM P</code>.</p>
<p>$$
\mathrm{meet}(S) = \bigcap_{A ∈ S} A.
$$</p>
<p>To prove this definition of <em>meet</em> gives <code>DM P</code> a semilattice structure, we have to show the result of such an intersection satisfies the <code>upper-lower</code> condition. First we define the intersection of a subset of <code>DM P</code> (i.e. of a set of sets taken from <code>DM P</code>).</p>
<pre><code class="language-lean">def DM.inter {P : Type u} [Poset P] (S : Set (DM P)) := { x | ∀ T ∈ S, x ∈ T.val }
</code></pre>
<p>We will need to use the simple fact that the interection of a family ot sets is a subset of every member of the family.</p>
<pre><code class="language-lean">theorem DM.inter_sub {P : Type u} [Poset P] {S : Set (DM P)}
  : ∀ T ∈ S, inter S ⊆ T.val := by
  intro T hT x hx
  exact hx T hT
</code></pre>
<p>Using this fact, we can show the intersection preserves the <code>lower-upper</code> property required of elements of <code>DM P</code>.</p>
<pre><code class="language-lean">theorem DM.inter_in_dm {P : Type u} [Poset P] {S : Set (DM P)}
  : lower (upper (inter S)) = inter S := by
    apply Set.eq_of_subset_of_subset
    . intro x hx T hT
      rw[←T.h]
      exact sub_low (sub_up (inter_sub T hT)) hx
    . exact sub_lu (inter S)
</code></pre>
<p>And with this theorem we can finally define the <em>meet</em> as a function from <code>Set (DM P)</code> into <code>DM P</code>. Recall, that to do so we need to not only supply the operation <code>inter</code> on <code>S</code>, but also proof that <code>inter S</code> is in <code>DM P</code>.</p>
<pre><code class="language-lean">def DM.meet {P : Type u} [Poset P] (S : Set (DM P)) : DM P :=
  ⟨ inter S, inter_in_dm ⟩
</code></pre>
<p>To show that <code>DM P</code> is a Complete Semilattice, we need to show that this definition of <code>meet</code> is indeed a greatest lower bound. We do so in two steps, first showing the <code>meet S</code> is a lower bound of <code>S</code> and second showing it is a greatest lower bound of <code>S</code>.</p>
<pre><code class="language-lean">theorem DM.meet_lb {P : Type u} [Poset P] :
  ∀ S : Set (DM P), IsLB S (meet S) := by
  intro S T hT
  apply DM.inter_sub
  exact hT

theorem DM.meet_greatest {P : Type u} [Poset P]
  : ∀ S : Set (DM P), ∀ w, (IsLB S w) → w ≤ meet S := by
  intro S W h
  intro x hx T hT
  exact h T hT hx
</code></pre>
<p>Now we have everything we need to instantiate the Complete Semilattice class.</p>
<pre><code class="language-lean">instance DM.csl {P : Type u} [Poset P] : CompleteSemilattice (DM P) :=
  ⟨ meet, meet_lb, meet_greatest ⟩
</code></pre>
<h2 id="the-join"><a class="header" href="#the-join">The Join</a></h2>
<p>Next we define a join. It would be nice to simply define the join of <code>S</code> to be the union of all sets in <code>S</code>, but the result would in general not be closed with respect to the <code>lower-upper</code> operator used to define <code>DM P</code>. To get around this, the join for <code>DM P</code> is defined to be the intersection of sets containing the union.</p>
<p>$$
\mathrm{join}(S) = \bigcap \left \{ B \in DM(P) \;|\; \bigcup_{A ∈ S} A \subseteq B \right \}
$$</p>
<p>First we define the union.</p>
<pre><code class="language-lean">def DM.union {P : Type u} [Poset P] (S : Set (DM P)) := { x | ∃ T ∈ S, x ∈ T.val }
</code></pre>
<p>We will need an intermediate theorem analogous to the intersection theorem proved for the meet. This one shows that the intersection of a set of sets is contained in each set.</p>
<pre><code class="language-lean">theorem DM.inter_union_dm {P : Type u} [Poset P] {S : Set (DM P)}
  : ∀ C ∈ {C : DM P| union S ⊆ C.val}, inter {C | union S ⊆ C.val} ⊆ C.val := by
    intro C hC x hx
    exact hx C hC
</code></pre>
<p>We use this theorem to show the meet is closed.</p>
<pre><code class="language-lean">theorem DM.union_in_dm {P : Type u} [Poset P] {S : Set (DM P)}
  : lower (upper (inter {C | union S ⊆ C.val})) = inter {C | union S ⊆ C.val} := by
  apply Set.eq_of_subset_of_subset
  . intro x hx T hT
    rw[←T.h]
    exact sub_low (sub_up (inter_union_dm T hT)) hx
  . apply sub_lu
</code></pre>
<p>The join operator is then be defined as follows.</p>
<pre><code class="language-lean">def DM.join {P : Type u} [Poset P] (S : Set (DM P)) : DM P :=
  ⟨ inter { C | union S ⊆ C.val }, union_in_dm ⟩
</code></pre>
<p>To show <code>DM P</code> is a Complete Lattice, we need to show the join is a least upper bound, which we do in two steps.</p>
<pre><code class="language-lean">theorem DM.join_ub {P : Type u} [Poset P] :
  ∀ S : Set (DM P), IsUB S (join S) := by
  intro S T hT x hx W hW
  simp[union,Set.subset_def] at hW
  exact hW x T hT hx

theorem DM.join_least {P : Type u} [Poset P]
  : ∀ S : Set (DM P), ∀ W, (IsUB S W) → join S ≤ W := by
  intro S W h x hx
  apply hx W
  intro y ⟨ Q, ⟨ h1, h2 ⟩ ⟩
  exact h Q h1 h2
</code></pre>
<p>Now we have everything we need to show <code>DM P</code> is a Complete Lattice.</p>
<pre><code class="language-lean">instance DM.lattice {P : Type u} [Poset P] : CompleteLattice (DM P) :=
  ⟨ join, join_ub, join_least ⟩
</code></pre>
<h2 id="completion-map"><a class="header" href="#completion-map">Completion Map</a></h2>
<p>The mapping from <code>P</code> into <code>DM P</code> is defined implicitly in the construction of <code>DM P</code>. Explicitly, the embedding is definition by the <code>down</code> operator.  That is, the map <code>λ x ↦ down x</code> is the ordering embedding that wintesses the completion. To show this, we prove that <code>down x</code> is closed under the <code>lower-upper</code> closure operator.</p>
<pre><code class="language-lean">theorem DM.down_is_dm {P : Type u} [Poset P] {x : P}
  : lower (upper (down x)) = down x :=
  by
    apply Set.eq_of_subset_of_subset
    . intro y hy
      exact hy x fun a a ↦ a
    . intro a ha
      simp_all[upper,lower]
</code></pre>
<p>This theorem then allows us to formally define the embedded. We call it <code>make</code>, because it allows us to <em>make</em> an element of <code>DM P</code> out of any element <code>x ∈ P</code>.</p>
<pre><code class="language-lean">def DM.make {P : Type u} [Poset P] (x : P) : DM P := ⟨ down x, down_is_dm ⟩
</code></pre>
<p>Finally, we prove that <code>make</code> is an order embeddeding (as defined in <a href="Ordering/./Maps.html">Maps</a>).</p>
<pre><code class="language-lean">theorem DM.make_embed {P : Type u} [Poset P]
  : OrderEmbedding (make : P → DM P) := by
  intro x y
  constructor
  . intro h z hz
    exact Poset.trans z x y hz h
  . intro h
    simp[make,down,le_inst,Poset.le] at h
    exact h x (Poset.refl x)
</code></pre>
<h2 id="completion-of-a-total-order"><a class="header" href="#completion-of-a-total-order">Completion of a Total Order</a></h2>
<p>If <code>P</code> is a totally ordered set, then its completion ought to be totally ordered as well. We show that here. We start with a useful theorem stating the fact that all elements of <code>DM P</code> are downward closed.</p>
<pre><code class="language-lean">theorem dm_down_close {P : Type u} [Poset P] {X : DM P}
  : ∀ y, ∀ x ∈ X.val, y ≤ x → y ∈ X.val := by
  intro y x hx hyx
  rw[←X.h] at hx ⊢
  intro z hz
  apply Poset.trans y x z hyx (hx z hz)
</code></pre>
<p>Now we show the main result.</p>
<pre><code class="language-lean">theorem dm_total_order {P : Type u} [TotalOrder P]
  : ∀ (x y : DM P), Comparable x y := by

  intro X Y
  by_cases h : X.val ⊆ Y.val

  . exact Or.inl h

  . -- Obtain an x in X - Y
    obtain ⟨ x, ⟨ hx, hxny ⟩ ⟩ := Set.not_subset.mp h

    -- Show y ≤ x using the fact that Y is closed
    rw[←Y.h] at hxny
    simp[lower] at hxny
    obtain ⟨ y, ⟨ hy, hcomp ⟩ ⟩ := hxny
    have hyx : y ≤ x := by
      apply Or.elim (TotalOrder.comp x y)
      . intro h
        exact False.elim (hcomp h)
      . exact id

    -- Show Y ⊆ down x using transitivity of ≤ in P
    have hYdx : Y.val ⊆ down x := by
      intro b hb
      exact Poset.trans b y x (hy b hb) hyx

    -- Show down x ⊆ X using the helper theorem above
    have hdxX: down x ⊆ X.val := by
      intro b hb
      exact dm_down_close b x hx hb

    -- Show Y ⊆ X using transitivity of ⊆
    apply Or.inr
    intro q hq
    exact hdxX (hYdx hq)
</code></pre>
<p>Using this theorem, we can instantiate the total order class for <code>DM P</code> for any totally ordered <code>P</code>.</p>
<pre><code class="language-lean">instance {P : Type u} [TotalOrder P] : TotalOrder (DM P) := ⟨ dm_total_order ⟩
</code></pre>
<p>We can show a useful theorem stating that every element besides top has a principal upper bound.</p>
<pre><code class="language-lean">theorem DM.not_top_is_bounded {P : Type u} [Poset P] {x : DM P}
  : x ≠ CompleteLattice.top → ∃ q : P, x ≤ DM.make q := by
  intro h

  have h1 : x.val ≠ Set.univ := by
    by_contra h2
    simp[CompleteLattice.top,CompleteSemilattice.inf,DM.meet,DM.inter,DM.ext] at h
    apply h (DM.ext h2)

  have ⟨ q, hq ⟩ : ∃ q, q ∈ Set.univ \ x.val := by
    by_contra h
    simp at h
    exact h1 (Set.eq_univ_iff_forall.mpr h)

  have h2 : ¬q ∈ x.val := by exact Set.not_mem_of_mem_diff hq

  rw[←x.h] at h2
  simp[upper,lower] at h2
  obtain ⟨ r, ⟨ hr, hrq ⟩ ⟩ := h2

  use r
  simp[DM.make,down,le_inst,Poset.le]

  intro y hy
  simp
  exact hr y hy
</code></pre>
<p>We can also show that every element besides <code>bot</code> is non-empty.</p>
<pre><code class="language-lean">theorem DM.not_bot_to_exists {P : Type u} [Poset P] {x : DM P}
  : x ≠ CompleteLattice.bot → ∃ v, v ∈ x.val := by
  intro h
  apply Set.nonempty_iff_ne_empty.mpr
  intro hxb
  simp[CompleteLattice.bot,CompleteLattice.sup,DM.join,DM.inter,DM.union] at h
  have : {x | ∀ (T : DM P), x ∈ T.val} = ∅ := by
    ext q
    constructor
    . simp
      by_contra hn
      simp at hn
      have := hn x
      simp_all[Set.mem_empty_iff_false]
    . simp

  simp[this] at h
  exact h (DM.ext hxb)
</code></pre>
<h2 id="examples-1"><a class="header" href="#examples-1">Examples</a></h2>
<h3 id="a-finite-example"><a class="header" href="#a-finite-example">A Finite Example</a></h3>
<pre><code class="language-lean">namespace Temp

inductive MyPoset where
  | a : MyPoset
  | b : MyPoset

open MyPoset

def myle (x y : MyPoset) := x = y

instance : Poset MyPoset :=
  ⟨ myle, by simp[myle], by simp[myle], by simp[myle] ⟩

theorem my_poset_all {x : MyPoset} : x ∈ ({a, b}: Set MyPoset) := by
  match x with
  | a =&gt; exact Set.mem_insert a {b}
  | b =&gt; exact Set.mem_insert_of_mem a rfl

def top : DM MyPoset := ⟨
  { a, b },
  by
    apply Set.eq_of_subset_of_subset
    . intro x h
      exact my_poset_all
    . intro x hx
      simp[lower,upper]
      intro y h1 h2
      match x with
      | a =&gt; exact h1
      | b =&gt; exact h2
  ⟩

def bot : DM MyPoset := ⟨
  ∅,
  by
    apply Set.eq_of_subset_of_subset
    . intro x hx
      simp[lower,upper] at hx
      have h1 := hx a
      have h2 := hx b
      rw[h1] at h2
      apply noConfusion h2
    . exact Set.empty_subset (lower (upper ∅))
⟩

example : ∃ b : DM MyPoset, ∀ x, b ≤ x := by
  use bot
  intro S y hy
  exact False.elim hy

end Temp
</code></pre>
<h2 id="exercises-6"><a class="header" href="#exercises-6">Exercises</a></h2>
<ol>
<li>Show <code>DM ℕ</code> is isomorphic to <code>ℕ ∪ {∞}</code> where <code>x ≤ ∞</code> for all <code>x</code>.</li>
</ol>
<div style='height=50px'>&nbsp;</div><hr>
Copyright © 2025 Eric Klavins
<div style="break-before: page; page-break-before: always;"></div><div style='display:none'>
--  Copyright (C) 2025  Eric Klavins
--
--  This program is free software: you can redistribute it and/or modify
--  it under the terms of the GNU General Public License as published by
--  the Free Software Foundation, either version 3 of the License, or
--  (at your option) any later version.   
</div>
<p><span style='color: orange'><em><strong>UNDER CONSTRUCTION</strong></em></span><br>
<span style='color: lightgray; font-size: 10pt'><a href='https://github.com/klavins/LeanBook/blob/main/main/../LeanBook/Chapters/Appendix.lean'>Code</a> for this chapter</span></p>
<h1 id="useful-theorems"><a class="header" href="#useful-theorems">Useful Theorems</a></h1>
<pre><code class="language-lean">theorem not_empty_to_exists {A : Type u} {S : Set A} : S ≠ ∅ → ∃ x, x ∈ S := by
   intro h
   by_contra h'
   simp at h'
   exact h (Set.eq_empty_iff_forall_not_mem.mpr h')

theorem not_full_to_not_exists {A : Type u} {S : Set A}
  : S ≠ Set.univ → ∃ x, x ∉ S := by
  intro h
  exact (Set.ne_univ_iff_exists_not_mem S).mp h

theorem not_empty_set_diff {A : Type u} {X Y : Set A} (h : ¬X ⊆ Y)
  : X \ Y ≠ ∅ := by
  simp[Set.instSDiff,Set.diff]
  by_contra hx
  simp at hx
  exact h hx

theorem remove_set_notation {T : Type*} (A : Set T) (f : T → Prop)
  : { x | f x } = A ↔ ∀ x, x ∈ A ↔ f x := by
  constructor
  . exact fun a x ↦ Iff.symm (Eq.to_iff (congrFun a x))
  . exact fun a ↦ Eq.symm (Set.ext a)
</code></pre>
<div style='height=50px'>&nbsp;</div><hr>
Copyright © 2025 Eric Klavins

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>

        <!-- Livereload script (if served using the cli tool) -->
        <script>
            const wsProtocol = location.protocol === 'https:' ? 'wss:' : 'ws:';
            const wsAddress = wsProtocol + "//" + location.host + "/" + "__livereload";
            const socket = new WebSocket(wsAddress);
            socket.onmessage = function (event) {
                if (event.data === "reload") {
                    socket.close();
                    location.reload();
                }
            };

            window.onbeforeunload = function() {
                socket.close();
            }
        </script>



        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->
        <script src="highlight.js"></script>
        <script src="lean-book.js"></script>

        <script>
        window.addEventListener('load', function() {
            MathJax.Hub.Register.StartupHook('End', function() {
                window.setTimeout(window.print, 100);
            });
        });
        </script>

    </div>
    </body>
</html>
